{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c6faa3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJ_PATH=/home/hoang/github/TS-IDS\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, re, datetime, random, gzip, json, copy\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from itertools import accumulate\n",
    "import argparse\n",
    "from time import time\n",
    "from math import ceil\n",
    "from collections import Counter\n",
    "import socket,struct\n",
    "import timeit\n",
    "import math\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score, accuracy_score, top_k_accuracy_score, roc_auc_score\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import category_encoders as ce\n",
    "\n",
    "from dgl import from_networkx\n",
    "import dgl.function as fn\n",
    "import networkx as nx\n",
    "\n",
    "PROJ_PATH = Path(os.path.join(re.sub(\"/TS-IDS.*$\", '', os.getcwd()), 'TS-IDS'))\n",
    "print(f'PROJ_PATH={PROJ_PATH}')\n",
    "sys.path.insert(1, str(PROJ_PATH))\n",
    "sys.path.insert(1, str(PROJ_PATH/'src'))\n",
    "import utils\n",
    "from utils import *\n",
    "from dataset import build_datamodule\n",
    "from trainer import build_trainer\n",
    "from model import TSIDS\n",
    "from pipeline import TSIDSPipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4df0b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/waimorris/Anomal-E/blob/main/Anomal_E_cicids2017.ipynb\n",
    "class SAGELayer(nn.Module):\n",
    "    def __init__(self, ndim_in, edims, ndim_out, activation):\n",
    "        super(SAGELayer, self).__init__()\n",
    "        self.W_apply = nn.Linear(ndim_in + edims , ndim_out)\n",
    "        self.activation = F.relu\n",
    "        self.W_edge = nn.Linear(128 * 2, 128)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_uniform_(self.W_apply.weight, gain=gain)\n",
    "\n",
    "    def message_func(self, edges):\n",
    "        return {'m':  edges.data['h']}\n",
    "\n",
    "    def forward(self, g_dgl, nfeats, efeats):\n",
    "        with g_dgl.local_scope():\n",
    "            g = g_dgl\n",
    "            g.ndata['h'] = nfeats\n",
    "            g.edata['h'] = efeats\n",
    "            g.update_all(self.message_func, fn.mean('m', 'h_neigh'))\n",
    "            g.ndata['h'] = F.relu(self.W_apply(torch.cat([g.ndata['h'], g.ndata['h_neigh']], 2)))\n",
    "\n",
    "            # Compute edge embeddings\n",
    "            u, v = g.edges()\n",
    "            edge = self.W_edge(torch.cat((g.srcdata['h'][u], g.dstdata['h'][v]), 2))\n",
    "        return g.ndata['h'], edge\n",
    "\n",
    "\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim,  activation):\n",
    "        super(SAGE, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(SAGELayer(ndim_in, edim, 128, F.relu))\n",
    "\n",
    "    def forward(self, g, nfeats, efeats, corrupt=False):\n",
    "        if corrupt:\n",
    "            e_perm = torch.randperm(g.number_of_edges())\n",
    "            #n_perm = torch.randperm(g.number_of_nodes())\n",
    "            efeats = efeats[e_perm]\n",
    "            #nfeats = nfeats[n_perm]\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            #nfeats = layer(g, nfeats, efeats)\n",
    "            nfeats, e_feats = layer(g, nfeats, efeats)\n",
    "            #return nfeats.sum(1)\n",
    "        return nfeats.sum(1), e_feats.sum(1)\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.Tensor(n_hidden, n_hidden))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def uniform(self, size, tensor):\n",
    "        bound = 1.0 / math.sqrt(size)\n",
    "        if tensor is not None:\n",
    "            tensor.data.uniform_(-bound, bound)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        size = self.weight.size(0)\n",
    "        self.uniform(size, self.weight)\n",
    "\n",
    "    def forward(self, features, summary):\n",
    "        features = torch.matmul(features, torch.matmul(self.weight, summary))\n",
    "        return features\n",
    "\n",
    "class DGI(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim, activation):\n",
    "        super(DGI, self).__init__()\n",
    "        self.encoder = SAGE(ndim_in, ndim_out, edim,  F.relu)\n",
    "        self.discriminator = Discriminator(128)\n",
    "        # self.discriminator = Discriminator(256)\n",
    "        self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, g, n_features, e_features):\n",
    "        positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
    "        negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
    "        self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, g, n_features, e_features):\n",
    "        positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
    "        negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
    "\n",
    "        positive = positive[1]\n",
    "        negative = negative[1]\n",
    "\n",
    "        summary = torch.sigmoid(positive.mean(dim=0))\n",
    "\n",
    "        positive = self.discriminator(positive, summary)\n",
    "        negative = self.discriminator(negative, summary)\n",
    "\n",
    "        l1 = self.loss(positive, torch.ones_like(positive))\n",
    "        l2 = self.loss(negative, torch.zeros_like(negative))\n",
    "\n",
    "        return l1 + l2\n",
    "    \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim, activation, dropout):\n",
    "        super().__init__()\n",
    "        self.dgi = DGI(ndim_in, ndim_out, edim, activation)\n",
    "    def forward(self, g, nfeats, efeats):\n",
    "        loss = self.dgi(g, nfeats, efeats)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6856176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(scaler, encoder, X, y, cols_to_norm, cname_label):\n",
    "    X = encoder.transform(X)\n",
    "    print('Number of samples:', X.shape, y.shape)\n",
    "    print(cols_to_norm)\n",
    "    X[cols_to_norm] = scaler.transform(X[cols_to_norm])\n",
    "    X['h'] = X[cols_to_norm].values.tolist()\n",
    "    X['h'] = X['h'].apply(lambda x: torch.tensor(x))\n",
    "    G_nx = nx.from_pandas_edgelist(\n",
    "        X, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", ['h', cname_label], create_using=nx.MultiDiGraph())\n",
    "#     G_nx = nx.from_pandas_edgelist(\n",
    "#         X, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", ['h', cname_label], create_using=nx.MultiGraph())\n",
    "#     G_nx = G_nx.to_directed()\n",
    "    print('Convert NX graph to DGL')\n",
    "    G = from_networkx(G_nx, edge_attrs=['h', cname_label])\n",
    "    # Eq1\n",
    "    G.ndata['h'] = torch.ones(G.num_nodes(), G.edata['h'].shape[1])\n",
    "    G.edata['train_mask'] = torch.ones(len(G.edata['h']), dtype=torch.bool)\n",
    "    \n",
    "    G.ndata['h'] = torch.reshape(G.ndata['h'], (G.ndata['h'].shape[0], 1,G.ndata['h'].shape[1]))\n",
    "    G.edata['h'] = torch.reshape(G.edata['h'], (G.edata['h'].shape[0], 1,G.edata['h'].shape[1]))\n",
    "    \n",
    "    return G\n",
    "\n",
    "def create_embd_df(\n",
    "    tvt_str,\n",
    "    embs,\n",
    "    cname_label,\n",
    "    actual\n",
    "):\n",
    "    df = pd.DataFrame(embs, columns=[str(i) for i in range(embs.shape[1])])\n",
    "    df[cname_label] = actual\n",
    "    df[f\"{cname_label}_tvt\"] = tvt_str\n",
    "    return df\n",
    "\n",
    "def create_prob_df(\n",
    "    tvt_str,\n",
    "    model,\n",
    "    G,\n",
    "    node_features, \n",
    "    edge_features,\n",
    "    actual\n",
    "):\n",
    "#     probs_0,probs_1,probs_2,probs_3,probs_4,gts,tvt\n",
    "    pred_prop = model(G, node_features, edge_features)\n",
    "    norm_pred_prop = torch.softmax(pred_prop, dim=1)\n",
    "    data_array = [pred_prop_ + [actual_, tvt_str] for pred_prop_, actual_ in zip(norm_pred_prop.tolist(), actual.tolist())]\n",
    "    cnames = [f'probs_{i}' for i in range(norm_pred_prop.shape[1])]\n",
    "    prob_df = pd.DataFrame(data_array, columns=cnames+['gts', 'tvt'])\n",
    "    return prob_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8ce5988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_baseline(\n",
    "    ds_name,\n",
    "    g_name,\n",
    "    cname_label,\n",
    "    cname_tvt,\n",
    "    n_epochs\n",
    "):\n",
    "    \n",
    "    data = pd.read_csv(f'../datasets/{ds_name}.csv')\n",
    "    label2idx = pd.read_pickle(f'../datasets/{g_name}.pkl')['label2idx']\n",
    "    if cname_label == 'Attack':\n",
    "        data['Attack'] = data['Attack'].map(label2idx)\n",
    "        \n",
    "    ####\n",
    "    data['IPV4_SRC_ADDR'] = data.IPV4_SRC_ADDR.apply(\n",
    "        lambda x: socket.inet_ntoa(struct.pack('>I', random.randint(0xac100001, 0xac1f0001))))\n",
    "    data['IPV4_SRC_ADDR'] = data.IPV4_SRC_ADDR.apply(str)\n",
    "    data['L4_SRC_PORT'] = data.L4_SRC_PORT.apply(str)\n",
    "    data['IPV4_DST_ADDR'] = data.IPV4_DST_ADDR.apply(str)\n",
    "    data['L4_DST_PORT'] = data.L4_DST_PORT.apply(str)\n",
    "\n",
    "    data['IPV4_SRC_ADDR'] = data['IPV4_SRC_ADDR'] + ':' + data['L4_SRC_PORT']\n",
    "    data['IPV4_DST_ADDR'] = data['IPV4_DST_ADDR'] + ':' + data['L4_DST_PORT']\n",
    "\n",
    "    data.drop(columns=['L4_SRC_PORT','L4_DST_PORT'], inplace=True)\n",
    "    \n",
    "    ####\n",
    "    X_cnames = [c for c in data.columns if not c.startswith('Label_tvt') and not c.startswith('Attack_tvt')]\n",
    "    X_train, X_test, y_train, y_test = (data[data[cname_tvt]!='test'][X_cnames], \n",
    "                                        data[data[cname_tvt]=='test'][X_cnames], \n",
    "                                        data[data[cname_tvt]!='test'][cname_label], \n",
    "                                        data[data[cname_tvt]=='test'][cname_label])\n",
    "    \n",
    "    ####\n",
    "    cols_to_norm = list(set(X_train.columns) - set(['Label', 'Attack', 'IPV4_SRC_ADDR', 'IPV4_DST_ADDR']))\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train[cols_to_norm])\n",
    "    encoder = ce.TargetEncoder(cols=['TCP_FLAGS','L7_PROTO','PROTOCOL'])\n",
    "    encoder.fit(X_train, y_train)\n",
    "\n",
    "    G_train = build_graph(scaler, encoder, X_train, y_train, cols_to_norm, cname_label)\n",
    "    G_test = build_graph(scaler, encoder, X_test, y_test, cols_to_norm, cname_label)\n",
    "    \n",
    "    print('To device')\n",
    "    G_train = G_train.to(torch.device(device))\n",
    "    G_test = G_test.to(torch.device(device))\n",
    "    \n",
    "    node_features = G_train.ndata['h']\n",
    "    edge_features = G_train.edata['h']\n",
    "\n",
    "    node_features_test = G_test.ndata['h']\n",
    "    edge_features_test = G_test.edata['h']\n",
    "    \n",
    "    assert edge_features.shape[0] == X_train.shape[0], \"Incorrect number of edges\"\n",
    "    assert edge_features_test.shape[0] == X_test.shape[0], \"Incorrect number of edges\"\n",
    "    \n",
    "    ####\n",
    "    ndim_in = G_train.ndata['h'].shape[2]\n",
    "    ndim_out = 128 \n",
    "    edim = G_train.ndata['h'].shape[2]\n",
    "    activation = F.relu\n",
    "    dropout = 0.2\n",
    "    n_classes = data[cname_label].nunique()\n",
    "    \n",
    "    ####\n",
    "    model = Model(ndim_in, ndim_out, edim, activation, dropout).to(device)\n",
    "    opt = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    t_G_train = copy.deepcopy(G_train)\n",
    "    ####\n",
    "    print('Start training')\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        loss = model(t_G_train, node_features, edge_features).to(device)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'{epoch:04d} - Loss:', loss.item())\n",
    "\n",
    "    #### create embs df\n",
    "    training_emb = model.dgi.encoder(G_train, G_train.ndata['h'], G_train.edata['h'])[1]\n",
    "    training_emb = training_emb.detach().cpu().numpy()\n",
    "\n",
    "    testing_emb = model.dgi.encoder(G_test, G_test.ndata['h'], G_test.edata['h'])[1]\n",
    "    testing_emb = testing_emb.detach().cpu().numpy()\n",
    "    \n",
    "    train_actual = G_train.edata[cname_label].detach().cpu().numpy()\n",
    "    test_actual = G_test.edata[cname_label].detach().cpu().numpy()\n",
    "    \n",
    "    train_tvt_str = data[data[cname_tvt]!='test'][cname_tvt].values\n",
    "    \n",
    "    train_embd_df = create_embd_df(\n",
    "        train_tvt_str,\n",
    "        training_emb,\n",
    "        cname_label,\n",
    "        train_actual\n",
    "    )\n",
    "    test_embd_df = create_embd_df(\n",
    "        'test',\n",
    "        testing_emb,\n",
    "        cname_label,\n",
    "        test_actual\n",
    "    )\n",
    "    pdXY = pd.concat([train_embd_df, test_embd_df], axis=0).reset_index(drop=True)\n",
    "    return pdXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b36bd921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_evaluation_metrics(model, best_ntree, x_train, y_train, x_val, y_val, x_test, y_test, is_binary):\n",
    "    train_score = model.predict_proba(x_train, ntree_limit=best_ntree)\n",
    "    train_pred = model.predict(x_train, ntree_limit=best_ntree)\n",
    "    val_score = model.predict_proba(x_val, ntree_limit=best_ntree)\n",
    "    val_pred = model.predict(x_val, ntree_limit=best_ntree)\n",
    "    test_score = model.predict_proba(x_test, ntree_limit=best_ntree)\n",
    "    test_pred = model.predict(x_test, ntree_limit=best_ntree)\n",
    "    \n",
    "    if is_binary:\n",
    "        train_auc = roc_auc_score(y_true=y_train, y_score=train_score[:, 1])\n",
    "        val_auc = roc_auc_score(y_true=y_val, y_score=val_score[:, 1])\n",
    "        test_auc = roc_auc_score(y_true=y_test, y_score=test_score[:, 1])\n",
    "    else:\n",
    "        train_auc = roc_auc_score(y_true=y_train, y_score=train_score, multi_class='ovo')\n",
    "        val_auc = roc_auc_score(y_true=y_val, y_score=val_score, multi_class='ovo')\n",
    "        test_auc = roc_auc_score(y_true=y_test, y_score=test_score, multi_class='ovo')\n",
    "    \n",
    "    train_acc = accuracy_score(y_true=y_train, y_pred=train_pred)\n",
    "    val_acc = accuracy_score(y_true=y_val, y_pred=val_pred)\n",
    "    test_acc = accuracy_score(y_true=y_test, y_pred=test_pred)\n",
    "    return train_auc, train_acc, val_auc, val_acc, test_auc, test_acc\n",
    "\n",
    "def train_xgb(dfXY, cname_feats, cname_target='Label', cname_tvt='Label_tvt', option_init={}, option_fit={}):\n",
    "    default_option_fit = {\n",
    "        'eval_metric': 'auc',\n",
    "        'verbose': False,\n",
    "        'early_stopping_rounds': 20,\n",
    "    }\n",
    "    default_option_init = {\n",
    "        'use_label_encoder': False,\n",
    "        'objective': 'binary:logistic',\n",
    "        'random_state': 0,\n",
    "        'n_jobs': 32\n",
    "    }\n",
    "    default_option_fit.update(option_fit)\n",
    "    default_option_init.update(option_init)\n",
    "    option_fit = default_option_fit\n",
    "    option_init = default_option_init\n",
    "    \n",
    "    if dfXY[cname_target].nunique() == 2:\n",
    "        is_binary = True\n",
    "    else:\n",
    "        is_binary = False\n",
    "        \n",
    "    # train/test\n",
    "    x_train = dfXY[dfXY[cname_tvt]=='train'][cname_feats].values\n",
    "    y_train = dfXY[dfXY[cname_tvt]=='train'][cname_target].values.astype(\"i4\")\n",
    "    x_val = dfXY[dfXY[cname_tvt]=='val'][cname_feats].values\n",
    "    y_val = dfXY[dfXY[cname_tvt]=='val'][cname_target].values.astype(\"i4\")\n",
    "    x_test = dfXY[dfXY[cname_tvt]=='test'][cname_feats].values\n",
    "    y_test = dfXY[dfXY[cname_tvt]=='test'][cname_target].values.astype(\"i4\")\n",
    "    \n",
    "    # classify\n",
    "    eval_set = [\n",
    "        (x_train, y_train),\n",
    "        (x_val, y_val),\n",
    "    ]\n",
    "    \n",
    "    model = xgb.XGBClassifier(**option_init)\n",
    "    model.fit(x_train, y_train, eval_set=eval_set, **option_fit)\n",
    "    best_ntree = model.get_booster().best_ntree_limit  \n",
    "    \n",
    "    train_auc, train_acc, val_auc, val_acc, test_auc, test_acc = compute_evaluation_metrics(\n",
    "        model, best_ntree, x_train, y_train, x_val, y_val, x_test, y_test, is_binary)\n",
    "    \n",
    "    pd_res = pd.DataFrame({\n",
    "        'n_features': [len(cname_feats)],\n",
    "        'n_train': [x_train.shape[0]],\n",
    "        'n_val': [x_val.shape[0]],\n",
    "        'n_test': [x_test.shape[0]],\n",
    "        'n_tree': [best_ntree],\n",
    "        'train_auc': [train_auc],\n",
    "        'train_acc': [train_acc],\n",
    "        'val_auc': [val_auc],\n",
    "        'val_acc': [val_acc],\n",
    "        'test_auc': [test_auc],\n",
    "        'test_acc': [test_acc],  \n",
    "    })\n",
    "    \n",
    "    display(pd_res)\n",
    "    \n",
    "    # track\n",
    "    fmodel = {\n",
    "        'model': model,\n",
    "        'cname_target': cname_target,\n",
    "        'cname_tvt': cname_tvt,\n",
    "        'cname_feats': cname_feats,  \n",
    "    }\n",
    "    return fmodel\n",
    "\n",
    "def predict(f_model, dfXY):\n",
    "    probs = f_model['model'].predict_proba(dfXY[f_model['cname_feats']])\n",
    "    df = pd.DataFrame(probs)\n",
    "    df.columns = [f'probs_{i}' for i in range(df.shape[1])]\n",
    "    df['gts'] = dfXY[f_model['cname_target']]\n",
    "    df['tvt'] = dfXY[f_model['cname_tvt']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a091ae",
   "metadata": {},
   "source": [
    "# CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43ce6c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyod.models.cblof import CBLOF\n",
    "\n",
    "# benign_train_samples = df_train[df_train.Label == 0].drop(columns=[\"Label\"])\n",
    "# normal_train_samples = df_train.drop(columns=[\"Label\"])\n",
    "\n",
    "# train_labels = df_train[\"Label\"]\n",
    "# test_labels = df_test[\"Label\"]\n",
    "\n",
    "# test_samples = df_test.drop(columns=[\"Label\"])\n",
    "# from sklearn.metrics import classification_report, f1_score\n",
    "# n_est = 2\n",
    "# con = 0.04\n",
    "# score = -1\n",
    "# bs = None\n",
    "# clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
    "# clf_if.fit(benign_train_samples)\n",
    "# y_pred = clf_if.predict(test_samples)\n",
    "# test_pred = y_pred\n",
    "\n",
    "# f1 = f1_score(test_labels, test_pred, average='macro')\n",
    "# print(f1)\n",
    "# print(classification_report(test_labels, test_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf8e074",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe0dab7c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "n_folds = 5\n",
    "flag_save = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc1b3d0",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "884cf377",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/category_encoders/target_encoder.py:92: FutureWarning: Default parameter min_samples_leaf will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter min_samples_leaf will change in version 2.6.\"\n",
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/category_encoders/target_encoder.py:97: FutureWarning: Default parameter smoothing will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter smoothing will change in version 2.6.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: (480080, 12) (480080,)\n",
      "['IN_PKTS', 'OUT_PKTS', 'PROTOCOL', 'L7_PROTO', 'FLOW_DURATION_MILLISECONDS', 'TCP_FLAGS', 'OUT_BYTES', 'IN_BYTES']\n",
      "Convert NX graph to DGL\n",
      "Number of samples: (120020, 12) (120020,)\n",
      "['IN_PKTS', 'OUT_PKTS', 'PROTOCOL', 'L7_PROTO', 'FLOW_DURATION_MILLISECONDS', 'TCP_FLAGS', 'OUT_BYTES', 'IN_BYTES']\n",
      "Convert NX graph to DGL\n",
      "To device\n",
      "Start training\n",
      "0010 - Loss: 1.6431936025619507\n",
      "0020 - Loss: 1.3319742679595947\n",
      "0030 - Loss: 1.278975486755371\n",
      "0040 - Loss: 1.125908613204956\n",
      "0050 - Loss: 0.892997145652771\n",
      "0060 - Loss: 0.6590012907981873\n",
      "0070 - Loss: 0.5716143846511841\n",
      "0080 - Loss: 0.550341010093689\n",
      "0090 - Loss: 0.5414172410964966\n",
      "0100 - Loss: 0.5403742790222168\n",
      "0110 - Loss: 0.529935896396637\n",
      "0120 - Loss: 0.5306460857391357\n",
      "0130 - Loss: 0.5148089528083801\n",
      "0140 - Loss: 0.5103889107704163\n",
      "0150 - Loss: 0.5072812438011169\n",
      "0160 - Loss: 0.5001993179321289\n",
      "0170 - Loss: 0.49119848012924194\n",
      "0180 - Loss: 0.4974181652069092\n",
      "0190 - Loss: 0.4888855516910553\n",
      "0200 - Loss: 0.48463407158851624\n",
      "0210 - Loss: 0.4771044850349426\n",
      "0220 - Loss: 0.4783092141151428\n",
      "0230 - Loss: 0.48074567317962646\n",
      "0240 - Loss: 0.47023946046829224\n",
      "0250 - Loss: 0.4785376787185669\n",
      "0260 - Loss: 0.4719931185245514\n",
      "0270 - Loss: 0.46765244007110596\n",
      "0280 - Loss: 0.46744900941848755\n",
      "0290 - Loss: 0.46012479066848755\n",
      "0300 - Loss: 0.45500966906547546\n",
      "0310 - Loss: 0.458310067653656\n",
      "0320 - Loss: 0.4712317883968353\n",
      "0330 - Loss: 0.4573005139827728\n",
      "0340 - Loss: 0.46537160873413086\n",
      "0350 - Loss: 0.4578856825828552\n",
      "0360 - Loss: 0.45402973890304565\n",
      "0370 - Loss: 0.45224636793136597\n",
      "0380 - Loss: 0.4512321949005127\n",
      "0390 - Loss: 0.4517294764518738\n",
      "0400 - Loss: 0.4816843271255493\n",
      "0410 - Loss: 0.45477980375289917\n",
      "0420 - Loss: 0.45056164264678955\n",
      "0430 - Loss: 0.451116681098938\n",
      "0440 - Loss: 0.4510406255722046\n",
      "0450 - Loss: 0.43857380747795105\n",
      "0460 - Loss: 0.43117475509643555\n",
      "0470 - Loss: 0.4386536478996277\n",
      "0480 - Loss: 0.4622981548309326\n",
      "0490 - Loss: 0.43328773975372314\n",
      "0500 - Loss: 0.43940943479537964\n",
      "0510 - Loss: 0.42904043197631836\n",
      "0520 - Loss: 0.4323863089084625\n",
      "0530 - Loss: 0.42526569962501526\n",
      "0540 - Loss: 0.49791219830513\n",
      "0550 - Loss: 0.4578372836112976\n",
      "0560 - Loss: 0.42512452602386475\n",
      "0570 - Loss: 0.4185941815376282\n",
      "0580 - Loss: 0.4170568585395813\n",
      "0590 - Loss: 0.414181649684906\n",
      "0600 - Loss: 0.41425275802612305\n",
      "0610 - Loss: 0.4106079339981079\n",
      "0620 - Loss: 0.41422951221466064\n",
      "0630 - Loss: 0.4517049193382263\n",
      "0640 - Loss: 0.48732519149780273\n",
      "0650 - Loss: 0.4683034121990204\n",
      "0660 - Loss: 0.4422500729560852\n",
      "0670 - Loss: 0.42122024297714233\n",
      "0680 - Loss: 0.40616393089294434\n",
      "0690 - Loss: 0.41407036781311035\n",
      "0700 - Loss: 0.40633952617645264\n",
      "0710 - Loss: 0.40330269932746887\n",
      "0720 - Loss: 0.40188318490982056\n",
      "0730 - Loss: 0.3999664783477783\n",
      "0740 - Loss: 0.3968743681907654\n",
      "0750 - Loss: 0.3979046046733856\n",
      "0760 - Loss: 0.3989114761352539\n",
      "0770 - Loss: 0.46253180503845215\n",
      "0780 - Loss: 0.4476384222507477\n",
      "0790 - Loss: 0.4128081202507019\n",
      "0800 - Loss: 0.39133912324905396\n",
      "0810 - Loss: 0.3908226490020752\n",
      "0820 - Loss: 0.3894743323326111\n",
      "0830 - Loss: 0.39564716815948486\n",
      "0840 - Loss: 0.37667348980903625\n",
      "0850 - Loss: 0.40556585788726807\n",
      "0860 - Loss: 0.395122230052948\n",
      "0870 - Loss: 0.43862247467041016\n",
      "0880 - Loss: 0.4412805736064911\n",
      "0890 - Loss: 0.3878850042819977\n",
      "0900 - Loss: 0.37256789207458496\n",
      "0910 - Loss: 0.37958061695098877\n",
      "0920 - Loss: 0.3706645369529724\n",
      "0930 - Loss: 0.3717402219772339\n",
      "0940 - Loss: 0.3666369616985321\n",
      "0950 - Loss: 0.36885443329811096\n",
      "0960 - Loss: 0.3924768567085266\n",
      "0970 - Loss: 0.3889903426170349\n",
      "0980 - Loss: 0.4787513017654419\n",
      "0990 - Loss: 0.5685665011405945\n",
      "1000 - Loss: 0.4150071144104004\n",
      "1010 - Loss: 0.4072267413139343\n",
      "1020 - Loss: 0.3887804448604584\n",
      "1030 - Loss: 0.36608779430389404\n",
      "1040 - Loss: 0.3576505780220032\n",
      "1050 - Loss: 0.3553396761417389\n",
      "1060 - Loss: 0.3565494418144226\n",
      "1070 - Loss: 0.3528805375099182\n",
      "1080 - Loss: 0.3451063632965088\n",
      "1090 - Loss: 0.3416222333908081\n",
      "1100 - Loss: 0.334392249584198\n",
      "1110 - Loss: 0.33659684658050537\n",
      "1120 - Loss: 0.3578084707260132\n",
      "1130 - Loss: 0.3919580578804016\n",
      "1140 - Loss: 0.35031211376190186\n",
      "1150 - Loss: 0.3383011221885681\n",
      "1160 - Loss: 0.35080963373184204\n",
      "1170 - Loss: 0.38503721356391907\n",
      "1180 - Loss: 0.46987468004226685\n",
      "1190 - Loss: 0.38731491565704346\n",
      "1200 - Loss: 0.41919171810150146\n",
      "1210 - Loss: 0.34504422545433044\n",
      "1220 - Loss: 0.3350973427295685\n",
      "1230 - Loss: 0.32329827547073364\n",
      "1240 - Loss: 0.31863027811050415\n",
      "1250 - Loss: 0.3199571967124939\n",
      "1260 - Loss: 0.3114433288574219\n",
      "1270 - Loss: 0.30798593163490295\n",
      "1280 - Loss: 0.3124169707298279\n",
      "1290 - Loss: 0.33002862334251404\n",
      "1300 - Loss: 0.3702313303947449\n",
      "1310 - Loss: 0.3393169641494751\n",
      "1320 - Loss: 0.3676721751689911\n",
      "1330 - Loss: 0.3317730724811554\n",
      "1340 - Loss: 0.41981470584869385\n",
      "1350 - Loss: 0.3294709324836731\n",
      "1360 - Loss: 0.30803054571151733\n",
      "1370 - Loss: 0.30480092763900757\n",
      "1380 - Loss: 0.2935425341129303\n",
      "1390 - Loss: 0.2848190665245056\n",
      "1400 - Loss: 0.28151583671569824\n",
      "1410 - Loss: 0.3322942852973938\n",
      "1420 - Loss: 0.2966170907020569\n",
      "1430 - Loss: 0.8704786896705627\n",
      "1440 - Loss: 0.4526311457157135\n",
      "1450 - Loss: 0.4888913631439209\n",
      "1460 - Loss: 0.3963429927825928\n",
      "1470 - Loss: 0.3512570261955261\n",
      "1480 - Loss: 0.3341970443725586\n",
      "1490 - Loss: 0.3398483991622925\n",
      "1500 - Loss: 0.32897692918777466\n",
      "1510 - Loss: 0.32891106605529785\n",
      "1520 - Loss: 0.3231564462184906\n",
      "1530 - Loss: 0.32182103395462036\n",
      "1540 - Loss: 0.31066399812698364\n",
      "1550 - Loss: 0.3209409713745117\n",
      "1560 - Loss: 0.3355129659175873\n",
      "1570 - Loss: 0.3110664486885071\n",
      "1580 - Loss: 0.28600138425827026\n",
      "1590 - Loss: 0.30955302715301514\n",
      "1600 - Loss: 0.2706857919692993\n",
      "1610 - Loss: 0.2901418209075928\n",
      "1620 - Loss: 0.34607863426208496\n",
      "1630 - Loss: 0.36504456400871277\n",
      "1640 - Loss: 0.3077152967453003\n",
      "1650 - Loss: 0.340696781873703\n",
      "1660 - Loss: 0.2974330186843872\n",
      "1670 - Loss: 0.2707684338092804\n",
      "1680 - Loss: 0.26491793990135193\n",
      "1690 - Loss: 0.25577312707901\n",
      "1700 - Loss: 0.25706857442855835\n",
      "1710 - Loss: 0.24719709157943726\n",
      "1720 - Loss: 0.24645711481571198\n",
      "1730 - Loss: 0.24871987104415894\n",
      "1740 - Loss: 0.2442314624786377\n",
      "1750 - Loss: 0.25420427322387695\n",
      "1760 - Loss: 0.6854984164237976\n",
      "1770 - Loss: 0.5746334195137024\n",
      "1780 - Loss: 0.5435014367103577\n",
      "1790 - Loss: 0.35860446095466614\n",
      "1800 - Loss: 0.3265957534313202\n",
      "1810 - Loss: 0.3166847229003906\n",
      "1820 - Loss: 0.307794988155365\n",
      "1830 - Loss: 0.30386605858802795\n",
      "1840 - Loss: 0.30856695771217346\n",
      "1850 - Loss: 0.29643481969833374\n",
      "1860 - Loss: 0.297664999961853\n",
      "1870 - Loss: 0.27864935994148254\n",
      "1880 - Loss: 0.26073917746543884\n",
      "1890 - Loss: 0.23870228230953217\n",
      "1900 - Loss: 0.2328719198703766\n",
      "1910 - Loss: 0.23915022611618042\n",
      "1920 - Loss: 0.23715144395828247\n",
      "1930 - Loss: 0.22488805651664734\n",
      "1940 - Loss: 0.27899280190467834\n",
      "1950 - Loss: 0.3696554899215698\n",
      "1960 - Loss: 0.3012295365333557\n",
      "1970 - Loss: 0.28199154138565063\n",
      "1980 - Loss: 0.24351882934570312\n",
      "1990 - Loss: 0.23381325602531433\n",
      "2000 - Loss: 0.2196441888809204\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>Label</th>\n",
       "      <th>Label_tvt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.927340</td>\n",
       "      <td>0.025692</td>\n",
       "      <td>10.381227</td>\n",
       "      <td>10.819204</td>\n",
       "      <td>-2.646116</td>\n",
       "      <td>10.050588</td>\n",
       "      <td>2.068347</td>\n",
       "      <td>1.361880</td>\n",
       "      <td>3.793991</td>\n",
       "      <td>7.038360</td>\n",
       "      <td>...</td>\n",
       "      <td>3.072030</td>\n",
       "      <td>2.181427</td>\n",
       "      <td>13.270711</td>\n",
       "      <td>-2.382159</td>\n",
       "      <td>7.830200</td>\n",
       "      <td>16.638126</td>\n",
       "      <td>2.985399</td>\n",
       "      <td>16.608747</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.747934</td>\n",
       "      <td>-1.707039</td>\n",
       "      <td>2.313488</td>\n",
       "      <td>2.285820</td>\n",
       "      <td>-2.911323</td>\n",
       "      <td>3.171084</td>\n",
       "      <td>0.940423</td>\n",
       "      <td>1.615129</td>\n",
       "      <td>-1.178686</td>\n",
       "      <td>0.808631</td>\n",
       "      <td>...</td>\n",
       "      <td>4.006696</td>\n",
       "      <td>2.036296</td>\n",
       "      <td>4.449018</td>\n",
       "      <td>1.640095</td>\n",
       "      <td>2.654618</td>\n",
       "      <td>6.597771</td>\n",
       "      <td>3.565621</td>\n",
       "      <td>4.684122</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.632139</td>\n",
       "      <td>-0.860037</td>\n",
       "      <td>1.891119</td>\n",
       "      <td>1.313892</td>\n",
       "      <td>-0.241508</td>\n",
       "      <td>1.345683</td>\n",
       "      <td>0.611589</td>\n",
       "      <td>-0.546503</td>\n",
       "      <td>0.458764</td>\n",
       "      <td>0.295978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977973</td>\n",
       "      <td>0.483716</td>\n",
       "      <td>1.752334</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>1.088345</td>\n",
       "      <td>2.714722</td>\n",
       "      <td>0.647017</td>\n",
       "      <td>2.893874</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.039994</td>\n",
       "      <td>-1.228239</td>\n",
       "      <td>2.487728</td>\n",
       "      <td>2.177692</td>\n",
       "      <td>-1.462019</td>\n",
       "      <td>2.827553</td>\n",
       "      <td>0.334752</td>\n",
       "      <td>0.315581</td>\n",
       "      <td>0.128015</td>\n",
       "      <td>1.125941</td>\n",
       "      <td>...</td>\n",
       "      <td>2.449733</td>\n",
       "      <td>1.551589</td>\n",
       "      <td>3.805914</td>\n",
       "      <td>-0.038243</td>\n",
       "      <td>1.797948</td>\n",
       "      <td>5.328384</td>\n",
       "      <td>2.165499</td>\n",
       "      <td>4.384638</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062730</td>\n",
       "      <td>-0.186216</td>\n",
       "      <td>0.104770</td>\n",
       "      <td>0.238044</td>\n",
       "      <td>0.020658</td>\n",
       "      <td>0.178592</td>\n",
       "      <td>0.041246</td>\n",
       "      <td>0.010073</td>\n",
       "      <td>-0.043814</td>\n",
       "      <td>-0.054500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021537</td>\n",
       "      <td>0.136695</td>\n",
       "      <td>0.131291</td>\n",
       "      <td>0.018041</td>\n",
       "      <td>0.205625</td>\n",
       "      <td>0.194706</td>\n",
       "      <td>0.037719</td>\n",
       "      <td>0.132037</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1          2          3         4          5         6  \\\n",
       "0 -1.927340  0.025692  10.381227  10.819204 -2.646116  10.050588  2.068347   \n",
       "1 -0.747934 -1.707039   2.313488   2.285820 -2.911323   3.171084  0.940423   \n",
       "2 -0.632139 -0.860037   1.891119   1.313892 -0.241508   1.345683  0.611589   \n",
       "3 -1.039994 -1.228239   2.487728   2.177692 -1.462019   2.827553  0.334752   \n",
       "4  0.062730 -0.186216   0.104770   0.238044  0.020658   0.178592  0.041246   \n",
       "\n",
       "          7         8         9  ...       120       121        122       123  \\\n",
       "0  1.361880  3.793991  7.038360  ...  3.072030  2.181427  13.270711 -2.382159   \n",
       "1  1.615129 -1.178686  0.808631  ...  4.006696  2.036296   4.449018  1.640095   \n",
       "2 -0.546503  0.458764  0.295978  ...  0.977973  0.483716   1.752334  0.001217   \n",
       "3  0.315581  0.128015  1.125941  ...  2.449733  1.551589   3.805914 -0.038243   \n",
       "4  0.010073 -0.043814 -0.054500  ... -0.021537  0.136695   0.131291  0.018041   \n",
       "\n",
       "        124        125       126        127  Label  Label_tvt  \n",
       "0  7.830200  16.638126  2.985399  16.608747      1      train  \n",
       "1  2.654618   6.597771  3.565621   4.684122      0        val  \n",
       "2  1.088345   2.714722  0.647017   2.893874      0        val  \n",
       "3  1.797948   5.328384  2.165499   4.384638      0      train  \n",
       "4  0.205625   0.194706  0.037719   0.132037      0        val  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save: ../output_emb/AnomalE_nf_bot_binary_cv1.pkl\n",
      "Fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/category_encoders/target_encoder.py:92: FutureWarning: Default parameter min_samples_leaf will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter min_samples_leaf will change in version 2.6.\"\n",
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/category_encoders/target_encoder.py:97: FutureWarning: Default parameter smoothing will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter smoothing will change in version 2.6.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: (480080, 12) (480080,)\n",
      "['IN_PKTS', 'OUT_PKTS', 'PROTOCOL', 'L7_PROTO', 'FLOW_DURATION_MILLISECONDS', 'TCP_FLAGS', 'OUT_BYTES', 'IN_BYTES']\n",
      "Convert NX graph to DGL\n",
      "Number of samples: (120020, 12) (120020,)\n",
      "['IN_PKTS', 'OUT_PKTS', 'PROTOCOL', 'L7_PROTO', 'FLOW_DURATION_MILLISECONDS', 'TCP_FLAGS', 'OUT_BYTES', 'IN_BYTES']\n",
      "Convert NX graph to DGL\n",
      "To device\n",
      "Start training\n",
      "0010 - Loss: 1.7004342079162598\n",
      "0020 - Loss: 1.3201208114624023\n",
      "0030 - Loss: 1.2696839570999146\n",
      "0040 - Loss: 1.1343052387237549\n",
      "0050 - Loss: 0.9337615966796875\n",
      "0060 - Loss: 0.7000356912612915\n",
      "0070 - Loss: 0.5724088549613953\n",
      "0080 - Loss: 0.5476571321487427\n",
      "0090 - Loss: 0.5333722829818726\n",
      "0100 - Loss: 0.5273695588111877\n",
      "0110 - Loss: 0.513565182685852\n",
      "0120 - Loss: 0.5073208808898926\n",
      "0130 - Loss: 0.5003672242164612\n",
      "0140 - Loss: 0.4980427622795105\n",
      "0150 - Loss: 0.4877215623855591\n",
      "0160 - Loss: 0.4822026491165161\n",
      "0170 - Loss: 0.4804658889770508\n",
      "0180 - Loss: 0.4905295968055725\n",
      "0190 - Loss: 0.4627456068992615\n",
      "0200 - Loss: 0.46441131830215454\n",
      "0210 - Loss: 0.46418771147727966\n",
      "0220 - Loss: 0.4580826759338379\n",
      "0230 - Loss: 0.45731550455093384\n",
      "0240 - Loss: 0.4606195390224457\n",
      "0250 - Loss: 0.47031599283218384\n",
      "0260 - Loss: 0.4634923040866852\n",
      "0270 - Loss: 0.44689756631851196\n",
      "0280 - Loss: 0.4520490765571594\n",
      "0290 - Loss: 0.4478423595428467\n",
      "0300 - Loss: 0.4419506788253784\n",
      "0310 - Loss: 0.4431184232234955\n",
      "0320 - Loss: 0.4429267644882202\n",
      "0330 - Loss: 0.4371331036090851\n",
      "0340 - Loss: 0.45167455077171326\n",
      "0350 - Loss: 0.4497472643852234\n",
      "0360 - Loss: 0.4409435987472534\n",
      "0370 - Loss: 0.4491135776042938\n",
      "0380 - Loss: 0.44185763597488403\n",
      "0390 - Loss: 0.42423200607299805\n",
      "0400 - Loss: 0.4302752614021301\n",
      "0410 - Loss: 0.42792630195617676\n",
      "0420 - Loss: 0.4225044250488281\n",
      "0430 - Loss: 0.4238895773887634\n",
      "0440 - Loss: 0.4354590177536011\n",
      "0450 - Loss: 0.4429455101490021\n",
      "0460 - Loss: 0.44027167558670044\n",
      "0470 - Loss: 0.42883533239364624\n",
      "0480 - Loss: 0.4291364848613739\n",
      "0490 - Loss: 0.41791510581970215\n",
      "0500 - Loss: 0.4136044979095459\n",
      "0510 - Loss: 0.41690802574157715\n",
      "0520 - Loss: 0.41310858726501465\n",
      "0530 - Loss: 0.4362952411174774\n",
      "0540 - Loss: 0.4508146047592163\n",
      "0550 - Loss: 0.424206018447876\n",
      "0560 - Loss: 0.41673946380615234\n",
      "0570 - Loss: 0.43490028381347656\n",
      "0580 - Loss: 0.42778781056404114\n",
      "0590 - Loss: 0.42035508155822754\n",
      "0600 - Loss: 0.40234094858169556\n",
      "0610 - Loss: 0.411898672580719\n",
      "0620 - Loss: 0.4397905766963959\n",
      "0630 - Loss: 0.4133448004722595\n",
      "0640 - Loss: 0.40857651829719543\n",
      "0650 - Loss: 0.41195735335350037\n",
      "0660 - Loss: 0.4406970739364624\n",
      "0670 - Loss: 0.4056927263736725\n",
      "0680 - Loss: 0.4132721424102783\n",
      "0690 - Loss: 0.39376792311668396\n",
      "0700 - Loss: 0.3983640670776367\n",
      "0710 - Loss: 0.39810818433761597\n",
      "0720 - Loss: 0.6101400852203369\n",
      "0730 - Loss: 0.5183727741241455\n",
      "0740 - Loss: 0.4448092579841614\n",
      "0750 - Loss: 0.4168994426727295\n",
      "0760 - Loss: 0.4000322222709656\n",
      "0770 - Loss: 0.39458948373794556\n",
      "0780 - Loss: 0.39628341794013977\n",
      "0790 - Loss: 0.3899425268173218\n",
      "0800 - Loss: 0.3868027925491333\n",
      "0810 - Loss: 0.3829771876335144\n",
      "0820 - Loss: 0.3873979449272156\n",
      "0830 - Loss: 0.38633865118026733\n",
      "0840 - Loss: 0.3813815116882324\n",
      "0850 - Loss: 0.37935328483581543\n",
      "0860 - Loss: 0.3788830637931824\n",
      "0870 - Loss: 0.5106245279312134\n",
      "0880 - Loss: 0.5304381251335144\n",
      "0890 - Loss: 0.44995275139808655\n",
      "0900 - Loss: 0.39776110649108887\n",
      "0910 - Loss: 0.3908902406692505\n",
      "0920 - Loss: 0.3830178678035736\n",
      "0930 - Loss: 0.37468957901000977\n",
      "0940 - Loss: 0.3746005892753601\n",
      "0950 - Loss: 0.3722416162490845\n",
      "0960 - Loss: 0.370170533657074\n",
      "0970 - Loss: 0.36735039949417114\n",
      "0980 - Loss: 0.36886391043663025\n",
      "0990 - Loss: 0.3770081102848053\n",
      "1000 - Loss: 0.3661078214645386\n",
      "1010 - Loss: 0.4285687804222107\n",
      "1020 - Loss: 0.5412253737449646\n",
      "1030 - Loss: 0.6697573661804199\n",
      "1040 - Loss: 0.5027876496315002\n",
      "1050 - Loss: 0.4392234981060028\n",
      "1060 - Loss: 0.40750592947006226\n",
      "1070 - Loss: 0.4012491703033447\n",
      "1080 - Loss: 0.391874760389328\n",
      "1090 - Loss: 0.38664692640304565\n",
      "1100 - Loss: 0.3796885013580322\n",
      "1110 - Loss: 0.37674516439437866\n",
      "1120 - Loss: 0.3741481900215149\n",
      "1130 - Loss: 0.37385132908821106\n",
      "1140 - Loss: 0.3772982954978943\n",
      "1150 - Loss: 0.37606051564216614\n",
      "1160 - Loss: 0.3692993223667145\n",
      "1170 - Loss: 0.370521605014801\n",
      "1180 - Loss: 0.36164382100105286\n",
      "1190 - Loss: 0.3684921860694885\n",
      "1200 - Loss: 0.37710392475128174\n",
      "1210 - Loss: 0.3685644268989563\n",
      "1220 - Loss: 0.3942981958389282\n",
      "1230 - Loss: 0.3617554008960724\n",
      "1240 - Loss: 0.357845664024353\n",
      "1250 - Loss: 0.3925137519836426\n",
      "1260 - Loss: 0.464432954788208\n",
      "1270 - Loss: 0.3834346830844879\n",
      "1280 - Loss: 0.371650755405426\n",
      "1290 - Loss: 0.362039715051651\n",
      "1300 - Loss: 0.3531356453895569\n",
      "1310 - Loss: 0.3510831296443939\n",
      "1320 - Loss: 0.3435678482055664\n",
      "1330 - Loss: 0.3418400287628174\n",
      "1340 - Loss: 0.3588528633117676\n",
      "1350 - Loss: 0.3438570499420166\n",
      "1360 - Loss: 0.3500754237174988\n",
      "1370 - Loss: 0.387641042470932\n",
      "1380 - Loss: 0.3568893074989319\n",
      "1390 - Loss: 0.36504846811294556\n",
      "1400 - Loss: 0.3432099223136902\n",
      "1410 - Loss: 0.3374652862548828\n",
      "1420 - Loss: 0.34048938751220703\n",
      "1430 - Loss: 0.32769572734832764\n",
      "1440 - Loss: 0.32460710406303406\n",
      "1450 - Loss: 0.33380424976348877\n",
      "1460 - Loss: 0.5394511222839355\n",
      "1470 - Loss: 0.5570059418678284\n",
      "1480 - Loss: 0.37848150730133057\n",
      "1490 - Loss: 0.3411210775375366\n",
      "1500 - Loss: 0.32924848794937134\n",
      "1510 - Loss: 0.3227730989456177\n",
      "1520 - Loss: 0.32071638107299805\n",
      "1530 - Loss: 0.31546878814697266\n",
      "1540 - Loss: 0.3125615119934082\n",
      "1550 - Loss: 0.3063223958015442\n",
      "1560 - Loss: 0.3059980571269989\n",
      "1570 - Loss: 0.34753793478012085\n",
      "1580 - Loss: 0.3880009055137634\n",
      "1590 - Loss: 0.3147812485694885\n",
      "1600 - Loss: 0.3028160333633423\n",
      "1610 - Loss: 0.29658564925193787\n",
      "1620 - Loss: 0.29028064012527466\n",
      "1630 - Loss: 0.34217962622642517\n",
      "1640 - Loss: 0.3362404704093933\n",
      "1650 - Loss: 0.46657875180244446\n",
      "1660 - Loss: 0.3788185119628906\n",
      "1670 - Loss: 0.36484646797180176\n",
      "1680 - Loss: 0.31858181953430176\n",
      "1690 - Loss: 0.2982329726219177\n",
      "1700 - Loss: 0.29670071601867676\n",
      "1710 - Loss: 0.2842492163181305\n",
      "1720 - Loss: 0.28222817182540894\n",
      "1730 - Loss: 0.28440624475479126\n",
      "1740 - Loss: 0.2762390375137329\n",
      "1750 - Loss: 0.2718837857246399\n",
      "1760 - Loss: 0.3087660074234009\n",
      "1770 - Loss: 0.3237522840499878\n",
      "1780 - Loss: 0.3181651532649994\n",
      "1790 - Loss: 0.2959716022014618\n",
      "1800 - Loss: 0.3512684106826782\n",
      "1810 - Loss: 0.28063344955444336\n",
      "1820 - Loss: 0.2943418025970459\n",
      "1830 - Loss: 0.2834775447845459\n",
      "1840 - Loss: 0.27074703574180603\n",
      "1850 - Loss: 0.2617475390434265\n",
      "1860 - Loss: 0.25950485467910767\n",
      "1870 - Loss: 0.2466278374195099\n",
      "1880 - Loss: 0.24696268141269684\n",
      "1890 - Loss: 0.25307580828666687\n",
      "1900 - Loss: 0.2692323625087738\n",
      "1910 - Loss: 0.2982807159423828\n",
      "1920 - Loss: 0.2630390226840973\n",
      "1930 - Loss: 1.866331934928894\n",
      "1940 - Loss: 0.9154367446899414\n",
      "1950 - Loss: 0.4210439622402191\n",
      "1960 - Loss: 0.4006848931312561\n",
      "1970 - Loss: 0.36755916476249695\n",
      "1980 - Loss: 0.3512394428253174\n",
      "1990 - Loss: 0.3490034341812134\n",
      "2000 - Loss: 0.34627482295036316\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>Label</th>\n",
       "      <th>Label_tvt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.063792</td>\n",
       "      <td>0.007712</td>\n",
       "      <td>0.022217</td>\n",
       "      <td>0.022801</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.018710</td>\n",
       "      <td>0.031559</td>\n",
       "      <td>0.037245</td>\n",
       "      <td>0.068138</td>\n",
       "      <td>0.213498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165189</td>\n",
       "      <td>0.032222</td>\n",
       "      <td>0.020239</td>\n",
       "      <td>0.123050</td>\n",
       "      <td>0.123098</td>\n",
       "      <td>0.075037</td>\n",
       "      <td>0.096202</td>\n",
       "      <td>0.103357</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.948688</td>\n",
       "      <td>4.275068</td>\n",
       "      <td>-2.250632</td>\n",
       "      <td>3.175306</td>\n",
       "      <td>13.463216</td>\n",
       "      <td>-5.055490</td>\n",
       "      <td>12.772231</td>\n",
       "      <td>8.006457</td>\n",
       "      <td>-7.266319</td>\n",
       "      <td>19.052296</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.565771</td>\n",
       "      <td>-5.166986</td>\n",
       "      <td>3.802348</td>\n",
       "      <td>7.912642</td>\n",
       "      <td>-9.257119</td>\n",
       "      <td>1.993399</td>\n",
       "      <td>-9.402494</td>\n",
       "      <td>5.726709</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.454095</td>\n",
       "      <td>-0.453376</td>\n",
       "      <td>-1.316782</td>\n",
       "      <td>0.235356</td>\n",
       "      <td>3.803620</td>\n",
       "      <td>0.569729</td>\n",
       "      <td>1.210547</td>\n",
       "      <td>2.025203</td>\n",
       "      <td>0.323354</td>\n",
       "      <td>5.421437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699955</td>\n",
       "      <td>-0.012781</td>\n",
       "      <td>2.781260</td>\n",
       "      <td>1.785366</td>\n",
       "      <td>-0.241204</td>\n",
       "      <td>1.845124</td>\n",
       "      <td>-0.774581</td>\n",
       "      <td>0.642625</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.805194</td>\n",
       "      <td>0.476372</td>\n",
       "      <td>-1.578392</td>\n",
       "      <td>0.065712</td>\n",
       "      <td>4.736784</td>\n",
       "      <td>0.898649</td>\n",
       "      <td>1.407388</td>\n",
       "      <td>2.719790</td>\n",
       "      <td>-0.438241</td>\n",
       "      <td>7.218850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.770349</td>\n",
       "      <td>-1.443472</td>\n",
       "      <td>4.988320</td>\n",
       "      <td>3.583281</td>\n",
       "      <td>-0.978328</td>\n",
       "      <td>1.701169</td>\n",
       "      <td>-1.778465</td>\n",
       "      <td>2.113579</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.454095</td>\n",
       "      <td>-0.453376</td>\n",
       "      <td>-1.316782</td>\n",
       "      <td>0.235356</td>\n",
       "      <td>3.803620</td>\n",
       "      <td>0.569729</td>\n",
       "      <td>1.210547</td>\n",
       "      <td>2.025203</td>\n",
       "      <td>0.323354</td>\n",
       "      <td>5.421437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699955</td>\n",
       "      <td>-0.012781</td>\n",
       "      <td>2.781260</td>\n",
       "      <td>1.785366</td>\n",
       "      <td>-0.241204</td>\n",
       "      <td>1.845124</td>\n",
       "      <td>-0.774581</td>\n",
       "      <td>0.642625</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3          4         5          6  \\\n",
       "0   0.063792  0.007712  0.022217  0.022801   0.006228  0.018710   0.031559   \n",
       "1  15.948688  4.275068 -2.250632  3.175306  13.463216 -5.055490  12.772231   \n",
       "2   1.454095 -0.453376 -1.316782  0.235356   3.803620  0.569729   1.210547   \n",
       "3   2.805194  0.476372 -1.578392  0.065712   4.736784  0.898649   1.407388   \n",
       "4   1.454095 -0.453376 -1.316782  0.235356   3.803620  0.569729   1.210547   \n",
       "\n",
       "          7         8          9  ...       120       121       122       123  \\\n",
       "0  0.037245  0.068138   0.213498  ...  0.165189  0.032222  0.020239  0.123050   \n",
       "1  8.006457 -7.266319  19.052296  ... -0.565771 -5.166986  3.802348  7.912642   \n",
       "2  2.025203  0.323354   5.421437  ...  0.699955 -0.012781  2.781260  1.785366   \n",
       "3  2.719790 -0.438241   7.218850  ...  0.770349 -1.443472  4.988320  3.583281   \n",
       "4  2.025203  0.323354   5.421437  ...  0.699955 -0.012781  2.781260  1.785366   \n",
       "\n",
       "        124       125       126       127  Label  Label_tvt  \n",
       "0  0.123098  0.075037  0.096202  0.103357      0      train  \n",
       "1 -9.257119  1.993399 -9.402494  5.726709      1      train  \n",
       "2 -0.241204  1.845124 -0.774581  0.642625      0      train  \n",
       "3 -0.978328  1.701169 -1.778465  2.113579      0      train  \n",
       "4 -0.241204  1.845124 -0.774581  0.642625      0      train  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save: ../output_emb/AnomalE_nf_bot_binary_cv2.pkl\n",
      "Fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/category_encoders/target_encoder.py:92: FutureWarning: Default parameter min_samples_leaf will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter min_samples_leaf will change in version 2.6.\"\n",
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/category_encoders/target_encoder.py:97: FutureWarning: Default parameter smoothing will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter smoothing will change in version 2.6.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: (480080, 12) (480080,)\n",
      "['IN_PKTS', 'OUT_PKTS', 'PROTOCOL', 'L7_PROTO', 'FLOW_DURATION_MILLISECONDS', 'TCP_FLAGS', 'OUT_BYTES', 'IN_BYTES']\n",
      "Convert NX graph to DGL\n",
      "Number of samples: (120020, 12) (120020,)\n",
      "['IN_PKTS', 'OUT_PKTS', 'PROTOCOL', 'L7_PROTO', 'FLOW_DURATION_MILLISECONDS', 'TCP_FLAGS', 'OUT_BYTES', 'IN_BYTES']\n",
      "Convert NX graph to DGL\n",
      "To device\n",
      "Start training\n",
      "0010 - Loss: 1.58842933177948\n",
      "0020 - Loss: 1.3294333219528198\n",
      "0030 - Loss: 1.2921520471572876\n",
      "0040 - Loss: 1.148543119430542\n",
      "0050 - Loss: 0.9244838953018188\n",
      "0060 - Loss: 0.6839194297790527\n",
      "0070 - Loss: 0.5707769989967346\n",
      "0080 - Loss: 0.5503889322280884\n",
      "0090 - Loss: 0.542603611946106\n",
      "0100 - Loss: 0.5281205177307129\n",
      "0110 - Loss: 0.5292831659317017\n",
      "0120 - Loss: 0.5190469622612\n",
      "0130 - Loss: 0.5143947005271912\n",
      "0140 - Loss: 0.5125987529754639\n",
      "0150 - Loss: 0.5054950714111328\n",
      "0160 - Loss: 0.49992746114730835\n",
      "0170 - Loss: 0.49067962169647217\n",
      "0180 - Loss: 0.48999154567718506\n",
      "0190 - Loss: 0.48442015051841736\n",
      "0200 - Loss: 0.4789704978466034\n",
      "0210 - Loss: 0.5250223875045776\n",
      "0220 - Loss: 0.4759415090084076\n",
      "0230 - Loss: 0.4734206199645996\n",
      "0240 - Loss: 0.47020795941352844\n",
      "0250 - Loss: 0.46589434146881104\n",
      "0260 - Loss: 0.46801522374153137\n",
      "0270 - Loss: 0.46693235635757446\n",
      "0280 - Loss: 0.4652036428451538\n",
      "0290 - Loss: 0.46132850646972656\n",
      "0300 - Loss: 0.46445930004119873\n",
      "0310 - Loss: 0.47024714946746826\n",
      "0320 - Loss: 0.4694902300834656\n",
      "0330 - Loss: 0.4538257122039795\n",
      "0340 - Loss: 0.45059776306152344\n",
      "0350 - Loss: 0.450666606426239\n",
      "0360 - Loss: 0.467650830745697\n",
      "0370 - Loss: 0.4477989673614502\n",
      "0380 - Loss: 0.4458771347999573\n",
      "0390 - Loss: 0.46448245644569397\n",
      "0400 - Loss: 0.44463932514190674\n",
      "0410 - Loss: 0.4452836513519287\n",
      "0420 - Loss: 0.4417308270931244\n",
      "0430 - Loss: 0.442752480506897\n",
      "0440 - Loss: 0.4431423544883728\n",
      "0450 - Loss: 0.44511592388153076\n",
      "0460 - Loss: 0.4418447017669678\n",
      "0470 - Loss: 0.43975701928138733\n",
      "0480 - Loss: 0.433180570602417\n",
      "0490 - Loss: 0.4239517152309418\n",
      "0500 - Loss: 0.4329058527946472\n",
      "0510 - Loss: 0.47536635398864746\n",
      "0520 - Loss: 0.43475016951560974\n",
      "0530 - Loss: 0.4283088445663452\n",
      "0540 - Loss: 0.41954606771469116\n",
      "0550 - Loss: 0.4154641032218933\n",
      "0560 - Loss: 0.41477224230766296\n",
      "0570 - Loss: 0.4085661768913269\n",
      "0580 - Loss: 0.4177614450454712\n",
      "0590 - Loss: 0.4143577218055725\n",
      "0600 - Loss: 0.40836888551712036\n",
      "0610 - Loss: 0.4096531867980957\n",
      "0620 - Loss: 0.39315277338027954\n",
      "0630 - Loss: 0.40950965881347656\n",
      "0640 - Loss: 0.40531420707702637\n",
      "0650 - Loss: 0.4017884135246277\n",
      "0660 - Loss: 0.43936121463775635\n",
      "0670 - Loss: 0.49557560682296753\n",
      "0680 - Loss: 0.397777259349823\n",
      "0690 - Loss: 0.3965666890144348\n",
      "0700 - Loss: 0.4095098376274109\n",
      "0710 - Loss: 0.38445550203323364\n",
      "0720 - Loss: 0.3972117602825165\n",
      "0730 - Loss: 0.43228891491889954\n",
      "0740 - Loss: 0.3903532028198242\n",
      "0750 - Loss: 0.3760213255882263\n",
      "0760 - Loss: 0.36874449253082275\n",
      "0770 - Loss: 0.379517138004303\n",
      "0780 - Loss: 0.4094378352165222\n",
      "0790 - Loss: 0.45794713497161865\n",
      "0800 - Loss: 0.5202594995498657\n",
      "0810 - Loss: 0.43102163076400757\n",
      "0820 - Loss: 0.3971520960330963\n",
      "0830 - Loss: 0.39470168948173523\n",
      "0840 - Loss: 0.3820301294326782\n",
      "0850 - Loss: 0.3817592263221741\n",
      "0860 - Loss: 0.37992632389068604\n",
      "0870 - Loss: 0.38198256492614746\n",
      "0880 - Loss: 0.3758191466331482\n",
      "0890 - Loss: 0.3714645802974701\n",
      "0900 - Loss: 0.3672058880329132\n",
      "0910 - Loss: 0.37186524271965027\n",
      "0920 - Loss: 0.36381858587265015\n",
      "0930 - Loss: 0.36185580492019653\n",
      "0940 - Loss: 0.3653238117694855\n",
      "0950 - Loss: 0.36415350437164307\n",
      "0960 - Loss: 0.36166590452194214\n",
      "0970 - Loss: 0.3582944869995117\n",
      "0980 - Loss: 0.3554859161376953\n",
      "0990 - Loss: 0.3503420948982239\n",
      "1000 - Loss: 0.3479558229446411\n",
      "1010 - Loss: 0.35760805010795593\n",
      "1020 - Loss: 0.3843478858470917\n",
      "1030 - Loss: 0.3623810112476349\n",
      "1040 - Loss: 0.37925004959106445\n",
      "1050 - Loss: 0.36053991317749023\n",
      "1060 - Loss: 0.3605903387069702\n",
      "1070 - Loss: 0.34835925698280334\n",
      "1080 - Loss: 0.3460042476654053\n",
      "1090 - Loss: 0.3471289873123169\n",
      "1100 - Loss: 0.34388530254364014\n",
      "1110 - Loss: 0.33855271339416504\n",
      "1120 - Loss: 0.3272441327571869\n",
      "1130 - Loss: 0.3535275459289551\n",
      "1140 - Loss: 0.4268798530101776\n",
      "1150 - Loss: 0.786354660987854\n",
      "1160 - Loss: 0.45801421999931335\n",
      "1170 - Loss: 0.3804999589920044\n",
      "1180 - Loss: 0.37080562114715576\n",
      "1190 - Loss: 0.35221561789512634\n",
      "1200 - Loss: 0.35728442668914795\n",
      "1210 - Loss: 0.33596718311309814\n",
      "1220 - Loss: 0.3246210813522339\n",
      "1230 - Loss: 0.320067822933197\n",
      "1240 - Loss: 0.32515478134155273\n",
      "1250 - Loss: 0.317676842212677\n",
      "1260 - Loss: 0.321499764919281\n",
      "1270 - Loss: 0.3501582145690918\n",
      "1280 - Loss: 0.482030987739563\n",
      "1290 - Loss: 0.41860347986221313\n",
      "1300 - Loss: 0.4036889970302582\n",
      "1310 - Loss: 0.35840046405792236\n",
      "1320 - Loss: 0.35166996717453003\n",
      "1330 - Loss: 0.3041723072528839\n",
      "1340 - Loss: 0.3024291694164276\n",
      "1350 - Loss: 0.2953403890132904\n",
      "1360 - Loss: 0.29653605818748474\n",
      "1370 - Loss: 0.29028260707855225\n",
      "1380 - Loss: 0.2863118350505829\n",
      "1390 - Loss: 0.28699177503585815\n",
      "1400 - Loss: 0.2911299467086792\n",
      "1410 - Loss: 0.47527575492858887\n",
      "1420 - Loss: 0.5697687268257141\n",
      "1430 - Loss: 0.4515374004840851\n",
      "1440 - Loss: 0.3836773633956909\n",
      "1450 - Loss: 0.3147704005241394\n",
      "1460 - Loss: 0.31921279430389404\n",
      "1470 - Loss: 0.29894953966140747\n",
      "1480 - Loss: 0.27889442443847656\n",
      "1490 - Loss: 0.2713841199874878\n",
      "1500 - Loss: 0.2671002745628357\n",
      "1510 - Loss: 0.26243335008621216\n",
      "1520 - Loss: 0.2754591405391693\n",
      "1530 - Loss: 0.9605039358139038\n",
      "1540 - Loss: 0.575641393661499\n",
      "1550 - Loss: 0.45533448457717896\n",
      "1560 - Loss: 0.4147539734840393\n",
      "1570 - Loss: 0.38096654415130615\n",
      "1580 - Loss: 0.3620416522026062\n",
      "1590 - Loss: 0.3495665192604065\n",
      "1600 - Loss: 0.3491649627685547\n",
      "1610 - Loss: 0.3441759943962097\n",
      "1620 - Loss: 0.3446859121322632\n",
      "1630 - Loss: 0.3453200161457062\n",
      "1640 - Loss: 0.33958983421325684\n",
      "1650 - Loss: 0.3325132429599762\n",
      "1660 - Loss: 0.3290445804595947\n",
      "1670 - Loss: 0.32897740602493286\n",
      "1680 - Loss: 0.3265949487686157\n",
      "1690 - Loss: 0.3235025405883789\n",
      "1700 - Loss: 0.327253520488739\n",
      "1710 - Loss: 0.32471978664398193\n",
      "1720 - Loss: 0.3173462748527527\n",
      "1730 - Loss: 0.3190310001373291\n",
      "1740 - Loss: 0.3678900897502899\n",
      "1750 - Loss: 0.4569413661956787\n",
      "1760 - Loss: 0.3920944333076477\n",
      "1770 - Loss: 0.33024340867996216\n",
      "1780 - Loss: 0.32104188203811646\n",
      "1790 - Loss: 0.3113563060760498\n",
      "1800 - Loss: 0.30954301357269287\n",
      "1810 - Loss: 0.29833677411079407\n",
      "1820 - Loss: 0.29751691222190857\n",
      "1830 - Loss: 0.2953561544418335\n",
      "1840 - Loss: 0.2947322726249695\n",
      "1850 - Loss: 0.28794583678245544\n",
      "1860 - Loss: 0.28639140725135803\n",
      "1870 - Loss: 0.2867339849472046\n",
      "1880 - Loss: 0.28654104471206665\n",
      "1890 - Loss: 0.491834431886673\n",
      "1900 - Loss: 0.39282315969467163\n",
      "1910 - Loss: 0.809828519821167\n",
      "1920 - Loss: 0.48914340138435364\n",
      "1930 - Loss: 0.3953118622303009\n",
      "1940 - Loss: 0.3715170621871948\n",
      "1950 - Loss: 0.36181068420410156\n",
      "1960 - Loss: 0.3608437478542328\n",
      "1970 - Loss: 0.35358425974845886\n",
      "1980 - Loss: 0.35001665353775024\n",
      "1990 - Loss: 0.35237056016921997\n",
      "2000 - Loss: 0.34790194034576416\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>Label</th>\n",
       "      <th>Label_tvt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.070751</td>\n",
       "      <td>0.059966</td>\n",
       "      <td>0.117903</td>\n",
       "      <td>0.092193</td>\n",
       "      <td>0.103957</td>\n",
       "      <td>0.031937</td>\n",
       "      <td>0.042294</td>\n",
       "      <td>-0.009799</td>\n",
       "      <td>0.137479</td>\n",
       "      <td>0.037918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020440</td>\n",
       "      <td>0.015250</td>\n",
       "      <td>0.118184</td>\n",
       "      <td>0.086401</td>\n",
       "      <td>0.158853</td>\n",
       "      <td>-0.072365</td>\n",
       "      <td>0.033541</td>\n",
       "      <td>0.145198</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.288239</td>\n",
       "      <td>2.741110</td>\n",
       "      <td>17.763975</td>\n",
       "      <td>11.258263</td>\n",
       "      <td>12.583649</td>\n",
       "      <td>14.251354</td>\n",
       "      <td>-9.991842</td>\n",
       "      <td>7.534120</td>\n",
       "      <td>19.482954</td>\n",
       "      <td>-6.228168</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.467793</td>\n",
       "      <td>-0.990781</td>\n",
       "      <td>5.942996</td>\n",
       "      <td>5.320913</td>\n",
       "      <td>-0.375661</td>\n",
       "      <td>-1.611554</td>\n",
       "      <td>-0.498233</td>\n",
       "      <td>11.223248</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.464679</td>\n",
       "      <td>1.025936</td>\n",
       "      <td>4.189820</td>\n",
       "      <td>2.832623</td>\n",
       "      <td>2.644827</td>\n",
       "      <td>1.555814</td>\n",
       "      <td>-1.594677</td>\n",
       "      <td>0.803284</td>\n",
       "      <td>3.757948</td>\n",
       "      <td>-1.412666</td>\n",
       "      <td>...</td>\n",
       "      <td>1.800846</td>\n",
       "      <td>0.095253</td>\n",
       "      <td>2.071327</td>\n",
       "      <td>-0.003280</td>\n",
       "      <td>0.012625</td>\n",
       "      <td>-0.557700</td>\n",
       "      <td>-0.537777</td>\n",
       "      <td>3.511494</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.464679</td>\n",
       "      <td>1.025936</td>\n",
       "      <td>4.189820</td>\n",
       "      <td>2.832623</td>\n",
       "      <td>2.644827</td>\n",
       "      <td>1.555814</td>\n",
       "      <td>-1.594677</td>\n",
       "      <td>0.803284</td>\n",
       "      <td>3.757948</td>\n",
       "      <td>-1.412666</td>\n",
       "      <td>...</td>\n",
       "      <td>1.800846</td>\n",
       "      <td>0.095253</td>\n",
       "      <td>2.071327</td>\n",
       "      <td>-0.003280</td>\n",
       "      <td>0.012625</td>\n",
       "      <td>-0.557700</td>\n",
       "      <td>-0.537777</td>\n",
       "      <td>3.511494</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.164935</td>\n",
       "      <td>0.312530</td>\n",
       "      <td>0.827401</td>\n",
       "      <td>0.517086</td>\n",
       "      <td>0.430917</td>\n",
       "      <td>0.350457</td>\n",
       "      <td>-0.162918</td>\n",
       "      <td>0.104214</td>\n",
       "      <td>0.824957</td>\n",
       "      <td>-0.267235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250668</td>\n",
       "      <td>0.066855</td>\n",
       "      <td>0.334417</td>\n",
       "      <td>0.086087</td>\n",
       "      <td>0.296122</td>\n",
       "      <td>-0.124058</td>\n",
       "      <td>-0.037529</td>\n",
       "      <td>0.608901</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1          2          3          4          5         6  \\\n",
       "0 -0.070751  0.059966   0.117903   0.092193   0.103957   0.031937  0.042294   \n",
       "1  2.288239  2.741110  17.763975  11.258263  12.583649  14.251354 -9.991842   \n",
       "2  0.464679  1.025936   4.189820   2.832623   2.644827   1.555814 -1.594677   \n",
       "3  0.464679  1.025936   4.189820   2.832623   2.644827   1.555814 -1.594677   \n",
       "4  0.164935  0.312530   0.827401   0.517086   0.430917   0.350457 -0.162918   \n",
       "\n",
       "          7          8         9  ...       120       121       122       123  \\\n",
       "0 -0.009799   0.137479  0.037918  ...  0.020440  0.015250  0.118184  0.086401   \n",
       "1  7.534120  19.482954 -6.228168  ... -5.467793 -0.990781  5.942996  5.320913   \n",
       "2  0.803284   3.757948 -1.412666  ...  1.800846  0.095253  2.071327 -0.003280   \n",
       "3  0.803284   3.757948 -1.412666  ...  1.800846  0.095253  2.071327 -0.003280   \n",
       "4  0.104214   0.824957 -0.267235  ...  0.250668  0.066855  0.334417  0.086087   \n",
       "\n",
       "        124       125       126        127  Label  Label_tvt  \n",
       "0  0.158853 -0.072365  0.033541   0.145198      0      train  \n",
       "1 -0.375661 -1.611554 -0.498233  11.223248      1      train  \n",
       "2  0.012625 -0.557700 -0.537777   3.511494      0      train  \n",
       "3  0.012625 -0.557700 -0.537777   3.511494      0        val  \n",
       "4  0.296122 -0.124058 -0.037529   0.608901      0      train  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save: ../output_emb/AnomalE_nf_bot_binary_cv3.pkl\n",
      "Fold: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/category_encoders/target_encoder.py:92: FutureWarning: Default parameter min_samples_leaf will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter min_samples_leaf will change in version 2.6.\"\n",
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/category_encoders/target_encoder.py:97: FutureWarning: Default parameter smoothing will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter smoothing will change in version 2.6.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: (480080, 12) (480080,)\n",
      "['IN_PKTS', 'OUT_PKTS', 'PROTOCOL', 'L7_PROTO', 'FLOW_DURATION_MILLISECONDS', 'TCP_FLAGS', 'OUT_BYTES', 'IN_BYTES']\n",
      "Convert NX graph to DGL\n",
      "Number of samples: (120020, 12) (120020,)\n",
      "['IN_PKTS', 'OUT_PKTS', 'PROTOCOL', 'L7_PROTO', 'FLOW_DURATION_MILLISECONDS', 'TCP_FLAGS', 'OUT_BYTES', 'IN_BYTES']\n",
      "Convert NX graph to DGL\n",
      "To device\n",
      "Start training\n",
      "0010 - Loss: 1.7416284084320068\n",
      "0020 - Loss: 1.29060697555542\n",
      "0030 - Loss: 1.240566611289978\n",
      "0040 - Loss: 1.0975866317749023\n",
      "0050 - Loss: 0.8897351026535034\n",
      "0060 - Loss: 0.6774301528930664\n",
      "0070 - Loss: 0.5737987756729126\n",
      "0080 - Loss: 0.549710750579834\n",
      "0090 - Loss: 0.5388028621673584\n",
      "0100 - Loss: 0.5341207385063171\n",
      "0110 - Loss: 0.5322606563568115\n",
      "0120 - Loss: 0.5294433236122131\n",
      "0130 - Loss: 0.5198702812194824\n",
      "0140 - Loss: 0.5119867324829102\n",
      "0150 - Loss: 0.5067940950393677\n",
      "0160 - Loss: 0.5036683082580566\n",
      "0170 - Loss: 0.49765485525131226\n",
      "0180 - Loss: 0.49693334102630615\n",
      "0190 - Loss: 0.49330925941467285\n",
      "0200 - Loss: 0.4864025413990021\n",
      "0210 - Loss: 0.47800230979919434\n",
      "0220 - Loss: 0.4871464967727661\n",
      "0230 - Loss: 0.4822673201560974\n",
      "0240 - Loss: 0.4651343822479248\n",
      "0250 - Loss: 0.45998671650886536\n",
      "0260 - Loss: 0.45726820826530457\n",
      "0270 - Loss: 0.4712173342704773\n",
      "0280 - Loss: 0.4542797803878784\n",
      "0290 - Loss: 0.4525827467441559\n",
      "0300 - Loss: 0.45822572708129883\n",
      "0310 - Loss: 0.4475230276584625\n",
      "0320 - Loss: 0.445096492767334\n",
      "0330 - Loss: 0.445944607257843\n",
      "0340 - Loss: 0.44997483491897583\n",
      "0350 - Loss: 0.43999046087265015\n",
      "0360 - Loss: 0.46273475885391235\n",
      "0370 - Loss: 0.44009023904800415\n",
      "0380 - Loss: 0.43532389402389526\n",
      "0390 - Loss: 0.436056911945343\n",
      "0400 - Loss: 0.44539910554885864\n",
      "0410 - Loss: 0.4337279200553894\n",
      "0420 - Loss: 0.44132930040359497\n",
      "0430 - Loss: 0.43900513648986816\n",
      "0440 - Loss: 0.43052244186401367\n",
      "0450 - Loss: 0.45747607946395874\n",
      "0460 - Loss: 0.43457916378974915\n",
      "0470 - Loss: 0.429856538772583\n",
      "0480 - Loss: 0.4210636019706726\n",
      "0490 - Loss: 0.4213263988494873\n",
      "0500 - Loss: 0.4163472652435303\n",
      "0510 - Loss: 0.42327266931533813\n",
      "0520 - Loss: 0.4121937155723572\n",
      "0530 - Loss: 0.4330601096153259\n",
      "0540 - Loss: 0.4161164164543152\n",
      "0550 - Loss: 0.4138372540473938\n",
      "0560 - Loss: 0.4310545027256012\n",
      "0570 - Loss: 0.45504307746887207\n",
      "0580 - Loss: 0.42416131496429443\n",
      "0590 - Loss: 0.40869009494781494\n",
      "0600 - Loss: 0.40753254294395447\n",
      "0610 - Loss: 0.4034666419029236\n",
      "0620 - Loss: 0.39957159757614136\n",
      "0630 - Loss: 0.4035574197769165\n",
      "0640 - Loss: 0.40286147594451904\n",
      "0650 - Loss: 0.40307343006134033\n",
      "0660 - Loss: 0.3935703635215759\n",
      "0670 - Loss: 0.4040619432926178\n",
      "0680 - Loss: 0.39453813433647156\n",
      "0690 - Loss: 0.4120767414569855\n",
      "0700 - Loss: 0.4927349090576172\n",
      "0710 - Loss: 0.432145357131958\n",
      "0720 - Loss: 0.6064308881759644\n",
      "0730 - Loss: 0.44137680530548096\n",
      "0740 - Loss: 0.4164090156555176\n",
      "0750 - Loss: 0.39971041679382324\n",
      "0760 - Loss: 0.3933240473270416\n",
      "0770 - Loss: 0.3838137984275818\n",
      "0780 - Loss: 0.3858208656311035\n",
      "0790 - Loss: 0.37833669781684875\n",
      "0800 - Loss: 0.37896063923835754\n",
      "0810 - Loss: 0.3714212477207184\n",
      "0820 - Loss: 0.3809482157230377\n",
      "0830 - Loss: 0.36788588762283325\n",
      "0840 - Loss: 0.36506277322769165\n",
      "0850 - Loss: 0.36903315782546997\n",
      "0860 - Loss: 0.4140385687351227\n",
      "0870 - Loss: 0.35997048020362854\n",
      "0880 - Loss: 0.3628641366958618\n",
      "0890 - Loss: 0.5117011070251465\n",
      "0900 - Loss: 0.4060673117637634\n",
      "0910 - Loss: 0.37285006046295166\n",
      "0920 - Loss: 0.3599441647529602\n",
      "0930 - Loss: 0.3612719178199768\n",
      "0940 - Loss: 0.3537291884422302\n",
      "0950 - Loss: 0.352593332529068\n",
      "0960 - Loss: 0.34723609685897827\n",
      "0970 - Loss: 0.3454151749610901\n",
      "0980 - Loss: 0.3420403003692627\n",
      "0990 - Loss: 0.398914098739624\n",
      "1000 - Loss: 0.34934714436531067\n",
      "1010 - Loss: 0.340312659740448\n",
      "1020 - Loss: 0.33198344707489014\n",
      "1030 - Loss: 0.3776645064353943\n",
      "1040 - Loss: 0.4317798912525177\n",
      "1050 - Loss: 0.45958036184310913\n",
      "1060 - Loss: 0.4029865264892578\n",
      "1070 - Loss: 0.37353575229644775\n",
      "1080 - Loss: 0.36567145586013794\n",
      "1090 - Loss: 0.3601394295692444\n",
      "1100 - Loss: 0.3602807819843292\n",
      "1110 - Loss: 0.3556056022644043\n",
      "1120 - Loss: 0.35324931144714355\n",
      "1130 - Loss: 0.3476482629776001\n",
      "1140 - Loss: 0.34248682856559753\n",
      "1150 - Loss: 0.34025323390960693\n",
      "1160 - Loss: 0.33847862482070923\n",
      "1170 - Loss: 0.3371473252773285\n",
      "1180 - Loss: 0.3383805751800537\n",
      "1190 - Loss: 0.3449002504348755\n",
      "1200 - Loss: 0.3346037268638611\n",
      "1210 - Loss: 0.32841917872428894\n",
      "1220 - Loss: 0.33076804876327515\n",
      "1230 - Loss: 0.321128785610199\n",
      "1240 - Loss: 0.3215721845626831\n",
      "1250 - Loss: 0.4185374081134796\n",
      "1260 - Loss: 0.7085433006286621\n",
      "1270 - Loss: 1.3700248003005981\n",
      "1280 - Loss: 0.6814882755279541\n",
      "1290 - Loss: 0.45376718044281006\n",
      "1300 - Loss: 0.4227173328399658\n",
      "1310 - Loss: 0.3995448648929596\n",
      "1320 - Loss: 0.3898654282093048\n",
      "1330 - Loss: 0.37905973196029663\n",
      "1340 - Loss: 0.37990424036979675\n",
      "1350 - Loss: 0.3824602961540222\n",
      "1360 - Loss: 0.3811512887477875\n",
      "1370 - Loss: 0.378166139125824\n",
      "1380 - Loss: 0.37230026721954346\n",
      "1390 - Loss: 0.3752027750015259\n",
      "1400 - Loss: 0.3730425238609314\n",
      "1410 - Loss: 0.37217235565185547\n",
      "1420 - Loss: 0.367694228887558\n",
      "1430 - Loss: 0.36660391092300415\n",
      "1440 - Loss: 0.3643494248390198\n",
      "1450 - Loss: 0.36342406272888184\n",
      "1460 - Loss: 0.357026606798172\n",
      "1470 - Loss: 0.36439642310142517\n",
      "1480 - Loss: 0.3578013777732849\n",
      "1490 - Loss: 0.3553314208984375\n",
      "1500 - Loss: 0.3578535318374634\n",
      "1510 - Loss: 0.3580211400985718\n",
      "1520 - Loss: 0.3551064133644104\n",
      "1530 - Loss: 0.3527265787124634\n",
      "1540 - Loss: 0.3504074811935425\n",
      "1550 - Loss: 0.351146399974823\n",
      "1560 - Loss: 0.3519817590713501\n",
      "1570 - Loss: 0.3529544472694397\n",
      "1580 - Loss: 0.33460569381713867\n",
      "1590 - Loss: 0.33999311923980713\n",
      "1600 - Loss: 0.3320707678794861\n",
      "1610 - Loss: 0.33972471952438354\n",
      "1620 - Loss: 0.33380958437919617\n",
      "1630 - Loss: 0.3316175043582916\n",
      "1640 - Loss: 0.3276241719722748\n",
      "1650 - Loss: 0.32963693141937256\n",
      "1660 - Loss: 0.3697218894958496\n",
      "1670 - Loss: 0.32036951184272766\n",
      "1680 - Loss: 0.3083210587501526\n",
      "1690 - Loss: 0.3101634383201599\n",
      "1700 - Loss: 0.2972431778907776\n",
      "1710 - Loss: 0.3345179259777069\n",
      "1720 - Loss: 0.31463998556137085\n",
      "1730 - Loss: 0.3136531710624695\n",
      "1740 - Loss: 0.30480098724365234\n",
      "1750 - Loss: 0.30298280715942383\n",
      "1760 - Loss: 0.30667874217033386\n",
      "1770 - Loss: 0.37606218457221985\n",
      "1780 - Loss: 0.868970513343811\n",
      "1790 - Loss: 0.4701637625694275\n",
      "1800 - Loss: 0.38119590282440186\n",
      "1810 - Loss: 0.3617064952850342\n",
      "1820 - Loss: 0.353468120098114\n",
      "1830 - Loss: 0.3522706627845764\n",
      "1840 - Loss: 0.33859944343566895\n",
      "1850 - Loss: 0.3294505774974823\n",
      "1860 - Loss: 0.31070831418037415\n",
      "1870 - Loss: 0.30045822262763977\n",
      "1880 - Loss: 0.2936469614505768\n",
      "1890 - Loss: 0.28866153955459595\n",
      "1900 - Loss: 0.28931349515914917\n",
      "1910 - Loss: 0.28550976514816284\n",
      "1920 - Loss: 0.28118467330932617\n",
      "1930 - Loss: 0.27974045276641846\n",
      "1940 - Loss: 0.2801990509033203\n",
      "1950 - Loss: 0.2741195559501648\n",
      "1960 - Loss: 0.27067163586616516\n",
      "1970 - Loss: 0.26357728242874146\n",
      "1980 - Loss: 0.26838332414627075\n",
      "1990 - Loss: 0.2707623243331909\n",
      "2000 - Loss: 0.27190929651260376\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>Label</th>\n",
       "      <th>Label_tvt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.278213</td>\n",
       "      <td>2.145815</td>\n",
       "      <td>9.485803</td>\n",
       "      <td>9.526907</td>\n",
       "      <td>2.578449</td>\n",
       "      <td>-5.064191</td>\n",
       "      <td>1.922569</td>\n",
       "      <td>9.912421</td>\n",
       "      <td>2.245402</td>\n",
       "      <td>2.089078</td>\n",
       "      <td>...</td>\n",
       "      <td>7.780299</td>\n",
       "      <td>2.782974</td>\n",
       "      <td>2.810694</td>\n",
       "      <td>-7.082822</td>\n",
       "      <td>15.051437</td>\n",
       "      <td>11.517078</td>\n",
       "      <td>-6.343623</td>\n",
       "      <td>7.581882</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.313287</td>\n",
       "      <td>3.654418</td>\n",
       "      <td>0.955213</td>\n",
       "      <td>1.034643</td>\n",
       "      <td>0.563504</td>\n",
       "      <td>-2.005035</td>\n",
       "      <td>-0.168802</td>\n",
       "      <td>3.947410</td>\n",
       "      <td>0.440415</td>\n",
       "      <td>1.390412</td>\n",
       "      <td>...</td>\n",
       "      <td>1.952508</td>\n",
       "      <td>-0.414132</td>\n",
       "      <td>0.235292</td>\n",
       "      <td>-0.156026</td>\n",
       "      <td>6.459072</td>\n",
       "      <td>2.273144</td>\n",
       "      <td>-1.584096</td>\n",
       "      <td>2.570495</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.379795</td>\n",
       "      <td>5.364019</td>\n",
       "      <td>0.794791</td>\n",
       "      <td>1.534493</td>\n",
       "      <td>0.011945</td>\n",
       "      <td>-3.167106</td>\n",
       "      <td>0.267060</td>\n",
       "      <td>4.953243</td>\n",
       "      <td>1.240804</td>\n",
       "      <td>2.543075</td>\n",
       "      <td>...</td>\n",
       "      <td>1.579578</td>\n",
       "      <td>-0.000748</td>\n",
       "      <td>0.495656</td>\n",
       "      <td>-0.386586</td>\n",
       "      <td>8.804118</td>\n",
       "      <td>2.888632</td>\n",
       "      <td>-2.481511</td>\n",
       "      <td>3.651071</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.313287</td>\n",
       "      <td>3.654418</td>\n",
       "      <td>0.955213</td>\n",
       "      <td>1.034643</td>\n",
       "      <td>0.563504</td>\n",
       "      <td>-2.005035</td>\n",
       "      <td>-0.168802</td>\n",
       "      <td>3.947410</td>\n",
       "      <td>0.440415</td>\n",
       "      <td>1.390412</td>\n",
       "      <td>...</td>\n",
       "      <td>1.952508</td>\n",
       "      <td>-0.414132</td>\n",
       "      <td>0.235292</td>\n",
       "      <td>-0.156026</td>\n",
       "      <td>6.459072</td>\n",
       "      <td>2.273144</td>\n",
       "      <td>-1.584096</td>\n",
       "      <td>2.570495</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.238033</td>\n",
       "      <td>0.740559</td>\n",
       "      <td>0.355658</td>\n",
       "      <td>0.146589</td>\n",
       "      <td>0.138142</td>\n",
       "      <td>-0.472020</td>\n",
       "      <td>-0.110256</td>\n",
       "      <td>0.862269</td>\n",
       "      <td>-0.057378</td>\n",
       "      <td>0.304482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.449086</td>\n",
       "      <td>-0.053351</td>\n",
       "      <td>0.013390</td>\n",
       "      <td>-0.083122</td>\n",
       "      <td>1.292170</td>\n",
       "      <td>0.406874</td>\n",
       "      <td>-0.280358</td>\n",
       "      <td>0.379724</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  9.278213  2.145815  9.485803  9.526907  2.578449 -5.064191  1.922569   \n",
       "1  1.313287  3.654418  0.955213  1.034643  0.563504 -2.005035 -0.168802   \n",
       "2  1.379795  5.364019  0.794791  1.534493  0.011945 -3.167106  0.267060   \n",
       "3  1.313287  3.654418  0.955213  1.034643  0.563504 -2.005035 -0.168802   \n",
       "4  0.238033  0.740559  0.355658  0.146589  0.138142 -0.472020 -0.110256   \n",
       "\n",
       "          7         8         9  ...       120       121       122       123  \\\n",
       "0  9.912421  2.245402  2.089078  ...  7.780299  2.782974  2.810694 -7.082822   \n",
       "1  3.947410  0.440415  1.390412  ...  1.952508 -0.414132  0.235292 -0.156026   \n",
       "2  4.953243  1.240804  2.543075  ...  1.579578 -0.000748  0.495656 -0.386586   \n",
       "3  3.947410  0.440415  1.390412  ...  1.952508 -0.414132  0.235292 -0.156026   \n",
       "4  0.862269 -0.057378  0.304482  ...  0.449086 -0.053351  0.013390 -0.083122   \n",
       "\n",
       "         124        125       126       127  Label  Label_tvt  \n",
       "0  15.051437  11.517078 -6.343623  7.581882      1      train  \n",
       "1   6.459072   2.273144 -1.584096  2.570495      0        val  \n",
       "2   8.804118   2.888632 -2.481511  3.651071      0      train  \n",
       "3   6.459072   2.273144 -1.584096  2.570495      0      train  \n",
       "4   1.292170   0.406874 -0.280358  0.379724      0        val  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save: ../output_emb/AnomalE_nf_bot_binary_cv4.pkl\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2000\n",
    "cname_label = 'Label'\n",
    "ds_name = 'NF-BoT-IoT_cv'\n",
    "g_name = 'NF-BoT-IoT_cv0_graph_binary'\n",
    "for fold in range(1, n_folds):\n",
    "    print('Fold:', fold)\n",
    "    cname_tvt = f'{cname_label}_tvt_fold_{fold}'\n",
    "    df_result = run_baseline(\n",
    "        ds_name,\n",
    "        g_name,\n",
    "        cname_label,\n",
    "        cname_tvt,\n",
    "        n_epochs\n",
    "    )\n",
    "    display(df_result.head())\n",
    "    if flag_save:\n",
    "        out_path = f'../output_emb/AnomalE_nf_bot_binary_cv{fold}.pkl'\n",
    "        print('Save:', out_path)\n",
    "        df_result.to_pickle(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "410417c8",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/xgboost/core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_val</th>\n",
       "      <th>n_test</th>\n",
       "      <th>n_tree</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>360060</td>\n",
       "      <td>120020</td>\n",
       "      <td>120020</td>\n",
       "      <td>76</td>\n",
       "      <td>0.983966</td>\n",
       "      <td>0.987385</td>\n",
       "      <td>0.982286</td>\n",
       "      <td>0.987394</td>\n",
       "      <td>0.979043</td>\n",
       "      <td>0.979687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_features  n_train   n_val  n_test  n_tree  train_auc  train_acc  \\\n",
       "0         128   360060  120020  120020      76   0.983966   0.987385   \n",
       "\n",
       "    val_auc   val_acc  test_auc  test_acc  \n",
       "0  0.982286  0.987394  0.979043  0.979687  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save: ../output_cv/AnomalE_nf_bot_binary_cv0.csv\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/xgboost/core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_val</th>\n",
       "      <th>n_test</th>\n",
       "      <th>n_tree</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>360060</td>\n",
       "      <td>120020</td>\n",
       "      <td>120020</td>\n",
       "      <td>36</td>\n",
       "      <td>0.983895</td>\n",
       "      <td>0.987474</td>\n",
       "      <td>0.982386</td>\n",
       "      <td>0.987144</td>\n",
       "      <td>0.972799</td>\n",
       "      <td>0.98192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_features  n_train   n_val  n_test  n_tree  train_auc  train_acc  \\\n",
       "0         128   360060  120020  120020      36   0.983895   0.987474   \n",
       "\n",
       "    val_auc   val_acc  test_auc  test_acc  \n",
       "0  0.982386  0.987144  0.972799   0.98192  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save: ../output_cv/AnomalE_nf_bot_binary_cv1.csv\n",
      "Fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/xgboost/core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_val</th>\n",
       "      <th>n_test</th>\n",
       "      <th>n_tree</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>360060</td>\n",
       "      <td>120020</td>\n",
       "      <td>120020</td>\n",
       "      <td>46</td>\n",
       "      <td>0.983542</td>\n",
       "      <td>0.987233</td>\n",
       "      <td>0.982364</td>\n",
       "      <td>0.987577</td>\n",
       "      <td>0.979148</td>\n",
       "      <td>0.985477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_features  n_train   n_val  n_test  n_tree  train_auc  train_acc  \\\n",
       "0         128   360060  120020  120020      46   0.983542   0.987233   \n",
       "\n",
       "    val_auc   val_acc  test_auc  test_acc  \n",
       "0  0.982364  0.987577  0.979148  0.985477  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save: ../output_cv/AnomalE_nf_bot_binary_cv2.csv\n",
      "Fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/xgboost/core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_val</th>\n",
       "      <th>n_test</th>\n",
       "      <th>n_tree</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>360060</td>\n",
       "      <td>120020</td>\n",
       "      <td>120020</td>\n",
       "      <td>88</td>\n",
       "      <td>0.983889</td>\n",
       "      <td>0.987363</td>\n",
       "      <td>0.982752</td>\n",
       "      <td>0.987452</td>\n",
       "      <td>0.974097</td>\n",
       "      <td>0.985869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_features  n_train   n_val  n_test  n_tree  train_auc  train_acc  \\\n",
       "0         128   360060  120020  120020      88   0.983889   0.987363   \n",
       "\n",
       "    val_auc   val_acc  test_auc  test_acc  \n",
       "0  0.982752  0.987452  0.974097  0.985869  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save: ../output_cv/AnomalE_nf_bot_binary_cv3.csv\n",
      "Fold: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/xgboost/core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_val</th>\n",
       "      <th>n_test</th>\n",
       "      <th>n_tree</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>360060</td>\n",
       "      <td>120020</td>\n",
       "      <td>120020</td>\n",
       "      <td>32</td>\n",
       "      <td>0.98407</td>\n",
       "      <td>0.987488</td>\n",
       "      <td>0.981528</td>\n",
       "      <td>0.987019</td>\n",
       "      <td>0.974635</td>\n",
       "      <td>0.984353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_features  n_train   n_val  n_test  n_tree  train_auc  train_acc  \\\n",
       "0         128   360060  120020  120020      32    0.98407   0.987488   \n",
       "\n",
       "    val_auc   val_acc  test_auc  test_acc  \n",
       "0  0.981528  0.987019  0.974635  0.984353  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save: ../output_cv/AnomalE_nf_bot_binary_cv4.csv\n"
     ]
    }
   ],
   "source": [
    "cname_target = 'Label'\n",
    "cname_tvt = f'{cname_target}_tvt'\n",
    "flag_save = True\n",
    "for fold in range(n_folds):\n",
    "    print('Fold:', fold)\n",
    "    cname_feats = [str(i) for i in range(128)]\n",
    "    dfXY = pd.read_pickle(f'../output_emb/AnomalE_nf_bot_binary_cv{fold}.pkl')\n",
    "    \n",
    "    f_model = train_xgb(\n",
    "        dfXY, cname_feats, cname_target, cname_tvt, option_init={}, option_fit={})\n",
    "    df = predict(f_model, dfXY)\n",
    "    # df.to_csv(f'../output_cv/xgb_nf_bot_binary_cv{fold}.csv', index=False)\n",
    "    if flag_save:\n",
    "        out_path = f'../output_cv/AnomalE_nf_bot_binary_cv{fold}.csv'\n",
    "        print('Save:', out_path)\n",
    "        df.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3abb362",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7b1846d",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/category_encoders/target_encoder.py:92: FutureWarning: Default parameter min_samples_leaf will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter min_samples_leaf will change in version 2.6.\"\n",
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/category_encoders/target_encoder.py:97: FutureWarning: Default parameter smoothing will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter smoothing will change in version 2.6.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: (480080, 12) (480080,)\n",
      "['OUT_PKTS', 'L7_PROTO', 'FLOW_DURATION_MILLISECONDS', 'IN_PKTS', 'IN_BYTES', 'OUT_BYTES', 'PROTOCOL', 'TCP_FLAGS']\n",
      "Convert NX graph to DGL\n",
      "Number of samples: (120020, 12) (120020,)\n",
      "['OUT_PKTS', 'L7_PROTO', 'FLOW_DURATION_MILLISECONDS', 'IN_PKTS', 'IN_BYTES', 'OUT_BYTES', 'PROTOCOL', 'TCP_FLAGS']\n",
      "Convert NX graph to DGL\n",
      "To device\n",
      "Start training\n",
      "0010 - Loss: 1.608283281326294\n",
      "0020 - Loss: 1.2825309038162231\n",
      "0030 - Loss: 1.2088931798934937\n",
      "0040 - Loss: 1.0182335376739502\n",
      "0050 - Loss: 0.7642197608947754\n",
      "0060 - Loss: 0.5966204404830933\n",
      "0070 - Loss: 0.5455110669136047\n",
      "0080 - Loss: 0.5268533229827881\n",
      "0090 - Loss: 0.5131720304489136\n",
      "0100 - Loss: 0.5008375644683838\n",
      "0110 - Loss: 0.48518484830856323\n",
      "0120 - Loss: 0.47545698285102844\n",
      "0130 - Loss: 0.4578186869621277\n",
      "0140 - Loss: 0.44783729314804077\n",
      "0150 - Loss: 0.43593689799308777\n",
      "0160 - Loss: 0.4510277807712555\n",
      "0170 - Loss: 0.4213714897632599\n",
      "0180 - Loss: 0.4194221794605255\n",
      "0190 - Loss: 0.4128879904747009\n",
      "0200 - Loss: 0.4009925127029419\n",
      "0210 - Loss: 0.3910728394985199\n",
      "0220 - Loss: 0.38488510251045227\n",
      "0230 - Loss: 0.3822421133518219\n",
      "0240 - Loss: 0.3772393465042114\n",
      "0250 - Loss: 0.41811347007751465\n",
      "0260 - Loss: 0.45171865820884705\n",
      "0270 - Loss: 0.3779066205024719\n",
      "0280 - Loss: 0.36906397342681885\n",
      "0290 - Loss: 0.3545667827129364\n",
      "0300 - Loss: 0.34671860933303833\n",
      "0310 - Loss: 0.3392883539199829\n",
      "0320 - Loss: 0.3292125463485718\n",
      "0330 - Loss: 0.3214368522167206\n",
      "0340 - Loss: 0.3375322222709656\n",
      "0350 - Loss: 0.5570650100708008\n",
      "0360 - Loss: 0.4059416353702545\n",
      "0370 - Loss: 0.3235313296318054\n",
      "0380 - Loss: 0.3348022699356079\n",
      "0390 - Loss: 0.3063207268714905\n",
      "0400 - Loss: 0.30173259973526\n",
      "0410 - Loss: 0.29091206192970276\n",
      "0420 - Loss: 0.28576329350471497\n",
      "0430 - Loss: 0.2774350047111511\n",
      "0440 - Loss: 0.3068411350250244\n",
      "0450 - Loss: 0.32575365900993347\n",
      "0460 - Loss: 0.28048622608184814\n",
      "0470 - Loss: 0.2747204303741455\n",
      "0480 - Loss: 0.2646128535270691\n",
      "0490 - Loss: 0.24752196669578552\n",
      "0500 - Loss: 0.28883862495422363\n",
      "0510 - Loss: 0.27745577692985535\n",
      "0520 - Loss: 0.2369295060634613\n",
      "0530 - Loss: 0.25064966082572937\n",
      "0540 - Loss: 0.22869646549224854\n",
      "0550 - Loss: 0.26211661100387573\n",
      "0560 - Loss: 0.38009124994277954\n",
      "0570 - Loss: 0.5480439066886902\n",
      "0580 - Loss: 0.3024967908859253\n",
      "0590 - Loss: 0.2757008671760559\n",
      "0600 - Loss: 0.25795888900756836\n",
      "0610 - Loss: 0.2527215778827667\n",
      "0620 - Loss: 0.24593228101730347\n",
      "0630 - Loss: 0.24695387482643127\n",
      "0640 - Loss: 0.24425086379051208\n",
      "0650 - Loss: 0.23222985863685608\n",
      "0660 - Loss: 0.22745496034622192\n",
      "0670 - Loss: 0.22750842571258545\n",
      "0680 - Loss: 0.22419174015522003\n",
      "0690 - Loss: 0.22123689949512482\n",
      "0700 - Loss: 0.21572157740592957\n",
      "0710 - Loss: 0.21127040684223175\n",
      "0720 - Loss: 0.209200918674469\n",
      "0730 - Loss: 0.21147741377353668\n",
      "0740 - Loss: 0.4166255593299866\n",
      "0750 - Loss: 0.2630155682563782\n",
      "0760 - Loss: 0.23269876837730408\n",
      "0770 - Loss: 0.2149081528186798\n",
      "0780 - Loss: 0.206194669008255\n",
      "0790 - Loss: 0.19525405764579773\n",
      "0800 - Loss: 0.19877150654792786\n",
      "0810 - Loss: 0.1898728609085083\n",
      "0820 - Loss: 0.1863124966621399\n",
      "0830 - Loss: 0.17951948940753937\n",
      "0840 - Loss: 0.17579714953899384\n",
      "0850 - Loss: 0.1753324270248413\n",
      "0860 - Loss: 0.17109239101409912\n",
      "0870 - Loss: 0.17097362875938416\n",
      "0880 - Loss: 0.1690257489681244\n",
      "0890 - Loss: 0.16257937252521515\n",
      "0900 - Loss: 0.2731456160545349\n",
      "0910 - Loss: 0.22235289216041565\n",
      "0920 - Loss: 0.21038365364074707\n",
      "0930 - Loss: 0.906025767326355\n",
      "0940 - Loss: 0.6755363345146179\n",
      "0950 - Loss: 0.3993491232395172\n",
      "0960 - Loss: 0.27002596855163574\n",
      "0970 - Loss: 0.23328152298927307\n",
      "0980 - Loss: 0.23172295093536377\n",
      "0990 - Loss: 0.2223050743341446\n",
      "1000 - Loss: 0.21980763971805573\n",
      "1010 - Loss: 0.21910247206687927\n",
      "1020 - Loss: 0.21721512079238892\n",
      "1030 - Loss: 0.21513578295707703\n",
      "1040 - Loss: 0.21257427334785461\n",
      "1050 - Loss: 0.21275141835212708\n",
      "1060 - Loss: 0.21215060353279114\n",
      "1070 - Loss: 0.21156534552574158\n",
      "1080 - Loss: 0.2119176983833313\n",
      "1090 - Loss: 0.20285539329051971\n",
      "1100 - Loss: 0.20336508750915527\n",
      "1110 - Loss: 0.20016640424728394\n",
      "1120 - Loss: 0.19570015370845795\n",
      "1130 - Loss: 0.19434088468551636\n",
      "1140 - Loss: 0.19086235761642456\n",
      "1150 - Loss: 0.18322411179542542\n",
      "1160 - Loss: 0.18326491117477417\n",
      "1170 - Loss: 0.17027071118354797\n",
      "1180 - Loss: 0.1822742521762848\n",
      "1190 - Loss: 0.17109337449073792\n",
      "1200 - Loss: 0.16242562234401703\n",
      "1210 - Loss: 0.15509256720542908\n",
      "1220 - Loss: 0.15447360277175903\n",
      "1230 - Loss: 0.15121880173683167\n",
      "1240 - Loss: 0.14947295188903809\n",
      "1250 - Loss: 0.1474873572587967\n",
      "1260 - Loss: 0.1451966017484665\n",
      "1270 - Loss: 0.1450081169605255\n",
      "1280 - Loss: 0.145920068025589\n",
      "1290 - Loss: 0.14973247051239014\n",
      "1300 - Loss: 0.17753133177757263\n",
      "1310 - Loss: 0.15468448400497437\n",
      "1320 - Loss: 0.14352752268314362\n",
      "1330 - Loss: 0.13562028110027313\n",
      "1340 - Loss: 0.13011087477207184\n",
      "1350 - Loss: 0.1476086527109146\n",
      "1360 - Loss: 0.1317143440246582\n",
      "1370 - Loss: 0.140727698802948\n",
      "1380 - Loss: 0.14526987075805664\n",
      "1390 - Loss: 0.1302408128976822\n",
      "1400 - Loss: 0.2865632176399231\n",
      "1410 - Loss: 1.3901102542877197\n",
      "1420 - Loss: 0.8781569004058838\n",
      "1430 - Loss: 0.6147124767303467\n",
      "1440 - Loss: 0.3370753526687622\n",
      "1450 - Loss: 0.26064538955688477\n",
      "1460 - Loss: 0.21179187297821045\n",
      "1470 - Loss: 0.2060108482837677\n",
      "1480 - Loss: 0.1969049721956253\n",
      "1490 - Loss: 0.195389062166214\n",
      "1500 - Loss: 0.19059771299362183\n",
      "1510 - Loss: 0.18966266512870789\n",
      "1520 - Loss: 0.18879437446594238\n",
      "1530 - Loss: 0.18417012691497803\n",
      "1540 - Loss: 0.18410590291023254\n",
      "1550 - Loss: 0.18392297625541687\n",
      "1560 - Loss: 0.17903682589530945\n",
      "1570 - Loss: 0.1797069013118744\n",
      "1580 - Loss: 0.17647702991962433\n",
      "1590 - Loss: 0.17417770624160767\n",
      "1600 - Loss: 0.17444080114364624\n",
      "1610 - Loss: 0.17117902636528015\n",
      "1620 - Loss: 0.17033779621124268\n",
      "1630 - Loss: 0.17220041155815125\n",
      "1640 - Loss: 0.16952237486839294\n",
      "1650 - Loss: 0.16749827563762665\n",
      "1660 - Loss: 0.1654629111289978\n",
      "1670 - Loss: 0.16561079025268555\n",
      "1680 - Loss: 0.16198717057704926\n",
      "1690 - Loss: 0.16111987829208374\n",
      "1700 - Loss: 0.16347046196460724\n",
      "1710 - Loss: 0.16015586256980896\n",
      "1720 - Loss: 0.16042578220367432\n",
      "1730 - Loss: 0.15893509984016418\n",
      "1740 - Loss: 0.15829698741436005\n",
      "1750 - Loss: 0.15627962350845337\n",
      "1760 - Loss: 0.15811499953269958\n",
      "1770 - Loss: 0.15490269660949707\n",
      "1780 - Loss: 0.1541289985179901\n",
      "1790 - Loss: 0.15017729997634888\n",
      "1800 - Loss: 0.1506538689136505\n",
      "1810 - Loss: 0.14896805584430695\n",
      "1820 - Loss: 0.14949876070022583\n",
      "1830 - Loss: 0.1476498246192932\n",
      "1840 - Loss: 0.14859171211719513\n",
      "1850 - Loss: 0.14406317472457886\n",
      "1860 - Loss: 0.14310410618782043\n",
      "1870 - Loss: 0.1450907289981842\n",
      "1880 - Loss: 0.14372551441192627\n",
      "1890 - Loss: 0.14392434060573578\n",
      "1900 - Loss: 0.14031367003917694\n",
      "1910 - Loss: 0.14274175465106964\n",
      "1920 - Loss: 0.13852006196975708\n",
      "1930 - Loss: 0.1393483579158783\n",
      "1940 - Loss: 0.14044660329818726\n",
      "1950 - Loss: 0.13691328465938568\n",
      "1960 - Loss: 0.1348889023065567\n",
      "1970 - Loss: 0.13987597823143005\n",
      "1980 - Loss: 0.13691046833992004\n",
      "1990 - Loss: 0.14519965648651123\n",
      "2000 - Loss: 0.13424405455589294\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Attack_tvt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.049649</td>\n",
       "      <td>0.016933</td>\n",
       "      <td>0.111899</td>\n",
       "      <td>0.031260</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.195302</td>\n",
       "      <td>0.451293</td>\n",
       "      <td>0.242270</td>\n",
       "      <td>0.389275</td>\n",
       "      <td>0.063263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402145</td>\n",
       "      <td>-0.011338</td>\n",
       "      <td>0.031974</td>\n",
       "      <td>0.075711</td>\n",
       "      <td>0.157718</td>\n",
       "      <td>0.224275</td>\n",
       "      <td>0.186393</td>\n",
       "      <td>-0.059726</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.417537</td>\n",
       "      <td>0.602608</td>\n",
       "      <td>1.205747</td>\n",
       "      <td>4.688486</td>\n",
       "      <td>0.749040</td>\n",
       "      <td>1.270898</td>\n",
       "      <td>7.161662</td>\n",
       "      <td>5.174139</td>\n",
       "      <td>2.682396</td>\n",
       "      <td>-2.646943</td>\n",
       "      <td>...</td>\n",
       "      <td>3.497228</td>\n",
       "      <td>-1.169678</td>\n",
       "      <td>-0.457631</td>\n",
       "      <td>-0.082949</td>\n",
       "      <td>1.436263</td>\n",
       "      <td>2.668970</td>\n",
       "      <td>3.934399</td>\n",
       "      <td>1.270787</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.209163</td>\n",
       "      <td>2.034337</td>\n",
       "      <td>1.231138</td>\n",
       "      <td>5.421963</td>\n",
       "      <td>2.021488</td>\n",
       "      <td>1.537319</td>\n",
       "      <td>9.004616</td>\n",
       "      <td>5.985013</td>\n",
       "      <td>2.162567</td>\n",
       "      <td>-3.181685</td>\n",
       "      <td>...</td>\n",
       "      <td>3.239772</td>\n",
       "      <td>-0.921208</td>\n",
       "      <td>0.260931</td>\n",
       "      <td>0.116396</td>\n",
       "      <td>2.275891</td>\n",
       "      <td>2.755877</td>\n",
       "      <td>4.180099</td>\n",
       "      <td>1.765700</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.417537</td>\n",
       "      <td>0.602608</td>\n",
       "      <td>1.205747</td>\n",
       "      <td>4.688486</td>\n",
       "      <td>0.749040</td>\n",
       "      <td>1.270898</td>\n",
       "      <td>7.161662</td>\n",
       "      <td>5.174139</td>\n",
       "      <td>2.682396</td>\n",
       "      <td>-2.646943</td>\n",
       "      <td>...</td>\n",
       "      <td>3.497228</td>\n",
       "      <td>-1.169678</td>\n",
       "      <td>-0.457631</td>\n",
       "      <td>-0.082949</td>\n",
       "      <td>1.436263</td>\n",
       "      <td>2.668970</td>\n",
       "      <td>3.934399</td>\n",
       "      <td>1.270787</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.249439</td>\n",
       "      <td>0.159942</td>\n",
       "      <td>0.304622</td>\n",
       "      <td>0.779711</td>\n",
       "      <td>0.235869</td>\n",
       "      <td>0.268761</td>\n",
       "      <td>1.507465</td>\n",
       "      <td>0.838555</td>\n",
       "      <td>0.612913</td>\n",
       "      <td>-0.417979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791147</td>\n",
       "      <td>-0.205647</td>\n",
       "      <td>0.110764</td>\n",
       "      <td>0.138706</td>\n",
       "      <td>0.232681</td>\n",
       "      <td>0.451751</td>\n",
       "      <td>0.814445</td>\n",
       "      <td>0.008145</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.049649  0.016933  0.111899  0.031260  0.000094  0.195302  0.451293   \n",
       "1  2.417537  0.602608  1.205747  4.688486  0.749040  1.270898  7.161662   \n",
       "2  3.209163  2.034337  1.231138  5.421963  2.021488  1.537319  9.004616   \n",
       "3  2.417537  0.602608  1.205747  4.688486  0.749040  1.270898  7.161662   \n",
       "4  0.249439  0.159942  0.304622  0.779711  0.235869  0.268761  1.507465   \n",
       "\n",
       "          7         8         9  ...       120       121       122       123  \\\n",
       "0  0.242270  0.389275  0.063263  ...  0.402145 -0.011338  0.031974  0.075711   \n",
       "1  5.174139  2.682396 -2.646943  ...  3.497228 -1.169678 -0.457631 -0.082949   \n",
       "2  5.985013  2.162567 -3.181685  ...  3.239772 -0.921208  0.260931  0.116396   \n",
       "3  5.174139  2.682396 -2.646943  ...  3.497228 -1.169678 -0.457631 -0.082949   \n",
       "4  0.838555  0.612913 -0.417979  ...  0.791147 -0.205647  0.110764  0.138706   \n",
       "\n",
       "        124       125       126       127  Attack  Attack_tvt  \n",
       "0  0.157718  0.224275  0.186393 -0.059726       0       train  \n",
       "1  1.436263  2.668970  3.934399  1.270787       0       train  \n",
       "2  2.275891  2.755877  4.180099  1.765700       0       train  \n",
       "3  1.436263  2.668970  3.934399  1.270787       0       train  \n",
       "4  0.232681  0.451751  0.814445  0.008145       0       train  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save: ../output_emb/AnomalE_nf_bot_multi_cv0.pkl\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/category_encoders/target_encoder.py:92: FutureWarning: Default parameter min_samples_leaf will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter min_samples_leaf will change in version 2.6.\"\n",
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/category_encoders/target_encoder.py:97: FutureWarning: Default parameter smoothing will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter smoothing will change in version 2.6.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: (480080, 12) (480080,)\n",
      "['OUT_PKTS', 'L7_PROTO', 'FLOW_DURATION_MILLISECONDS', 'IN_PKTS', 'IN_BYTES', 'OUT_BYTES', 'PROTOCOL', 'TCP_FLAGS']\n",
      "Convert NX graph to DGL\n",
      "Number of samples: (120020, 12) (120020,)\n",
      "['OUT_PKTS', 'L7_PROTO', 'FLOW_DURATION_MILLISECONDS', 'IN_PKTS', 'IN_BYTES', 'OUT_BYTES', 'PROTOCOL', 'TCP_FLAGS']\n",
      "Convert NX graph to DGL\n",
      "To device\n",
      "Start training\n",
      "0010 - Loss: 1.4116002321243286\n",
      "0020 - Loss: 1.2473639249801636\n",
      "0030 - Loss: 0.9968037605285645\n",
      "0040 - Loss: 0.714645504951477\n",
      "0050 - Loss: 0.5675256252288818\n",
      "0060 - Loss: 0.5289593935012817\n",
      "0070 - Loss: 0.5169270634651184\n",
      "0080 - Loss: 0.4995276927947998\n",
      "0090 - Loss: 0.4957360625267029\n",
      "0100 - Loss: 0.4730433523654938\n",
      "0110 - Loss: 0.4599887728691101\n",
      "0120 - Loss: 0.45892781019210815\n",
      "0130 - Loss: 0.43304604291915894\n",
      "0140 - Loss: 0.42770272493362427\n",
      "0150 - Loss: 0.4302581548690796\n",
      "0160 - Loss: 0.4046557545661926\n",
      "0170 - Loss: 0.392721563577652\n",
      "0180 - Loss: 0.40443044900894165\n",
      "0190 - Loss: 0.38461023569107056\n",
      "0200 - Loss: 0.38301610946655273\n",
      "0210 - Loss: 0.36815738677978516\n",
      "0220 - Loss: 0.39750275015830994\n",
      "0230 - Loss: 0.39029914140701294\n",
      "0240 - Loss: 0.35431063175201416\n",
      "0250 - Loss: 0.3504003882408142\n",
      "0260 - Loss: 0.3459487855434418\n",
      "0270 - Loss: 0.3745974898338318\n",
      "0280 - Loss: 0.5477591753005981\n",
      "0290 - Loss: 0.49882078170776367\n",
      "0300 - Loss: 0.4043083190917969\n",
      "0310 - Loss: 0.3749525547027588\n",
      "0320 - Loss: 0.36561262607574463\n",
      "0330 - Loss: 0.3537042737007141\n",
      "0340 - Loss: 0.3545660376548767\n",
      "0350 - Loss: 0.3461017906665802\n",
      "0360 - Loss: 0.34560906887054443\n",
      "0370 - Loss: 0.3366028666496277\n",
      "0380 - Loss: 0.3317358195781708\n",
      "0390 - Loss: 0.3258403241634369\n",
      "0400 - Loss: 0.3202744126319885\n",
      "0410 - Loss: 0.31941479444503784\n",
      "0420 - Loss: 0.3150404989719391\n",
      "0430 - Loss: 0.31147706508636475\n",
      "0440 - Loss: 0.3057713806629181\n",
      "0450 - Loss: 0.2991945743560791\n",
      "0460 - Loss: 0.29371845722198486\n",
      "0470 - Loss: 0.301961213350296\n",
      "0480 - Loss: 0.35564762353897095\n",
      "0490 - Loss: 0.31162047386169434\n",
      "0500 - Loss: 0.284908652305603\n",
      "0510 - Loss: 0.29542869329452515\n",
      "0520 - Loss: 0.295324444770813\n",
      "0530 - Loss: 0.2992668151855469\n",
      "0540 - Loss: 0.26890528202056885\n",
      "0550 - Loss: 0.27090513706207275\n",
      "0560 - Loss: 0.2601882219314575\n",
      "0570 - Loss: 0.2736629247665405\n",
      "0580 - Loss: 0.28526198863983154\n",
      "0590 - Loss: 0.2933260500431061\n",
      "0600 - Loss: 0.2568693459033966\n",
      "0610 - Loss: 0.25216683745384216\n",
      "0620 - Loss: 0.24036115407943726\n",
      "0630 - Loss: 0.2561669945716858\n",
      "0640 - Loss: 0.2405376136302948\n",
      "0650 - Loss: 0.9834505319595337\n",
      "0660 - Loss: 0.49453118443489075\n",
      "0670 - Loss: 0.4777490496635437\n",
      "0680 - Loss: 0.34031859040260315\n",
      "0690 - Loss: 0.30708566308021545\n",
      "0700 - Loss: 0.29865530133247375\n",
      "0710 - Loss: 0.2945302426815033\n",
      "0720 - Loss: 0.2918204367160797\n",
      "0730 - Loss: 0.2907836437225342\n",
      "0740 - Loss: 0.2911946475505829\n",
      "0750 - Loss: 0.2861871123313904\n",
      "0760 - Loss: 0.28392866253852844\n",
      "0770 - Loss: 0.2800372242927551\n",
      "0780 - Loss: 0.27455294132232666\n",
      "0790 - Loss: 0.27537286281585693\n",
      "0800 - Loss: 0.2577592432498932\n",
      "0810 - Loss: 0.25476813316345215\n",
      "0820 - Loss: 0.252055823802948\n",
      "0830 - Loss: 0.24555858969688416\n",
      "0840 - Loss: 0.23947609961032867\n",
      "0850 - Loss: 0.23717167973518372\n",
      "0860 - Loss: 0.23329466581344604\n",
      "0870 - Loss: 0.22657166421413422\n",
      "0880 - Loss: 0.22689417004585266\n",
      "0890 - Loss: 0.22678424417972565\n",
      "0900 - Loss: 0.22056664526462555\n",
      "0910 - Loss: 0.22247236967086792\n",
      "0920 - Loss: 0.22086355090141296\n",
      "0930 - Loss: 0.2917138338088989\n",
      "0940 - Loss: 0.2448473870754242\n",
      "0950 - Loss: 1.1823872327804565\n",
      "0960 - Loss: 0.4376366138458252\n",
      "0970 - Loss: 0.3602534234523773\n",
      "0980 - Loss: 0.33603066205978394\n",
      "0990 - Loss: 0.29787778854370117\n",
      "1000 - Loss: 0.2875523865222931\n",
      "1010 - Loss: 0.2810601592063904\n",
      "1020 - Loss: 0.2778937816619873\n",
      "1030 - Loss: 0.2731603980064392\n",
      "1040 - Loss: 0.27164608240127563\n",
      "1050 - Loss: 0.26828548312187195\n",
      "1060 - Loss: 0.26848867535591125\n",
      "1070 - Loss: 0.2688516080379486\n",
      "1080 - Loss: 0.26840677857398987\n",
      "1090 - Loss: 0.2671262323856354\n",
      "1100 - Loss: 0.2653553783893585\n",
      "1110 - Loss: 0.26061293482780457\n",
      "1120 - Loss: 0.24267932772636414\n",
      "1130 - Loss: 0.2305203676223755\n",
      "1140 - Loss: 0.2263348400592804\n",
      "1150 - Loss: 0.22380074858665466\n",
      "1160 - Loss: 0.22510752081871033\n",
      "1170 - Loss: 0.21908365190029144\n",
      "1180 - Loss: 0.21530883014202118\n",
      "1190 - Loss: 0.2128954827785492\n",
      "1200 - Loss: 0.21215426921844482\n",
      "1210 - Loss: 0.20801988244056702\n",
      "1220 - Loss: 0.20683929324150085\n",
      "1230 - Loss: 0.20295023918151855\n",
      "1240 - Loss: 0.19919699430465698\n",
      "1250 - Loss: 0.20092608034610748\n",
      "1260 - Loss: 0.1987476646900177\n",
      "1270 - Loss: 0.19243325293064117\n",
      "1280 - Loss: 0.1932818591594696\n",
      "1290 - Loss: 0.18960002064704895\n",
      "1300 - Loss: 0.18902868032455444\n",
      "1310 - Loss: 0.18500615656375885\n",
      "1320 - Loss: 0.19143089652061462\n",
      "1330 - Loss: 0.1853436827659607\n",
      "1340 - Loss: 0.1833440363407135\n",
      "1350 - Loss: 0.1794995367527008\n",
      "1360 - Loss: 0.18022948503494263\n",
      "1370 - Loss: 0.17732085287570953\n",
      "1380 - Loss: 0.17705179750919342\n",
      "1390 - Loss: 0.17475411295890808\n",
      "1400 - Loss: 0.17169559001922607\n",
      "1410 - Loss: 0.1695263832807541\n",
      "1420 - Loss: 0.17331115901470184\n",
      "1430 - Loss: 0.1738472729921341\n",
      "1440 - Loss: 0.18508610129356384\n",
      "1450 - Loss: 0.16703547537326813\n",
      "1460 - Loss: 0.17949268221855164\n",
      "1470 - Loss: 0.3233798146247864\n",
      "1480 - Loss: 4.0312652587890625\n",
      "1490 - Loss: 1.1722053289413452\n",
      "1500 - Loss: 0.7421740293502808\n",
      "1510 - Loss: 0.41125401854515076\n",
      "1520 - Loss: 0.3535655736923218\n",
      "1530 - Loss: 0.3011626899242401\n",
      "1540 - Loss: 0.29053813219070435\n",
      "1550 - Loss: 0.2800801694393158\n",
      "1560 - Loss: 0.276058167219162\n",
      "1570 - Loss: 0.2649776041507721\n",
      "1580 - Loss: 0.256089448928833\n",
      "1590 - Loss: 0.24576009809970856\n",
      "1600 - Loss: 0.24302887916564941\n",
      "1610 - Loss: 0.2351352870464325\n",
      "1620 - Loss: 0.2285669445991516\n",
      "1630 - Loss: 0.22542020678520203\n",
      "1640 - Loss: 0.22153601050376892\n",
      "1650 - Loss: 0.218072772026062\n",
      "1660 - Loss: 0.21678143739700317\n",
      "1670 - Loss: 0.21142151951789856\n",
      "1680 - Loss: 0.20935137569904327\n",
      "1690 - Loss: 0.20752805471420288\n",
      "1700 - Loss: 0.204971045255661\n",
      "1710 - Loss: 0.20109233260154724\n",
      "1720 - Loss: 0.20081332325935364\n",
      "1730 - Loss: 0.19962649047374725\n",
      "1740 - Loss: 0.19640421867370605\n",
      "1750 - Loss: 0.1919502317905426\n",
      "1760 - Loss: 0.19083817303180695\n",
      "1770 - Loss: 0.19070959091186523\n",
      "1780 - Loss: 0.18755239248275757\n",
      "1790 - Loss: 0.18614545464515686\n",
      "1800 - Loss: 0.18877002596855164\n",
      "1810 - Loss: 0.1835666298866272\n",
      "1820 - Loss: 0.18084539473056793\n",
      "1830 - Loss: 0.18094629049301147\n",
      "1840 - Loss: 0.17830507457256317\n",
      "1850 - Loss: 0.17647016048431396\n",
      "1860 - Loss: 0.17579856514930725\n",
      "1870 - Loss: 0.17276307940483093\n",
      "1880 - Loss: 0.17118073999881744\n",
      "1890 - Loss: 0.17159630358219147\n",
      "1900 - Loss: 0.1674051582813263\n",
      "1910 - Loss: 0.16594599187374115\n",
      "1920 - Loss: 0.1658974140882492\n",
      "1930 - Loss: 0.1667376607656479\n",
      "1940 - Loss: 0.16486172378063202\n",
      "1950 - Loss: 0.1624162495136261\n",
      "1960 - Loss: 0.16227561235427856\n",
      "1970 - Loss: 0.15854616463184357\n",
      "1980 - Loss: 0.15703824162483215\n",
      "1990 - Loss: 0.15868785977363586\n",
      "2000 - Loss: 0.1560705155134201\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Attack_tvt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.988852</td>\n",
       "      <td>17.490372</td>\n",
       "      <td>4.483373</td>\n",
       "      <td>10.509126</td>\n",
       "      <td>5.397744</td>\n",
       "      <td>-0.926823</td>\n",
       "      <td>3.355568</td>\n",
       "      <td>8.757118</td>\n",
       "      <td>4.470564</td>\n",
       "      <td>-2.814009</td>\n",
       "      <td>...</td>\n",
       "      <td>3.334058</td>\n",
       "      <td>-6.393062</td>\n",
       "      <td>0.072684</td>\n",
       "      <td>4.186450</td>\n",
       "      <td>-1.494370</td>\n",
       "      <td>3.811220</td>\n",
       "      <td>-0.573833</td>\n",
       "      <td>8.586548</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.884548</td>\n",
       "      <td>5.748482</td>\n",
       "      <td>0.403125</td>\n",
       "      <td>1.404040</td>\n",
       "      <td>0.653220</td>\n",
       "      <td>1.257143</td>\n",
       "      <td>-0.593541</td>\n",
       "      <td>2.184529</td>\n",
       "      <td>-0.704112</td>\n",
       "      <td>-1.652778</td>\n",
       "      <td>...</td>\n",
       "      <td>2.461198</td>\n",
       "      <td>-1.745446</td>\n",
       "      <td>2.362890</td>\n",
       "      <td>1.442992</td>\n",
       "      <td>-0.611457</td>\n",
       "      <td>0.822156</td>\n",
       "      <td>-1.776823</td>\n",
       "      <td>2.040227</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.121422</td>\n",
       "      <td>2.480523</td>\n",
       "      <td>0.404007</td>\n",
       "      <td>0.250735</td>\n",
       "      <td>0.482196</td>\n",
       "      <td>0.335659</td>\n",
       "      <td>0.472907</td>\n",
       "      <td>0.459064</td>\n",
       "      <td>0.495564</td>\n",
       "      <td>0.292008</td>\n",
       "      <td>...</td>\n",
       "      <td>1.581233</td>\n",
       "      <td>-0.229335</td>\n",
       "      <td>0.574020</td>\n",
       "      <td>0.871957</td>\n",
       "      <td>0.245003</td>\n",
       "      <td>0.645052</td>\n",
       "      <td>0.121356</td>\n",
       "      <td>0.293409</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.781711</td>\n",
       "      <td>4.500030</td>\n",
       "      <td>0.547421</td>\n",
       "      <td>1.054502</td>\n",
       "      <td>0.525633</td>\n",
       "      <td>0.789035</td>\n",
       "      <td>0.103779</td>\n",
       "      <td>1.189162</td>\n",
       "      <td>0.177748</td>\n",
       "      <td>-0.602985</td>\n",
       "      <td>...</td>\n",
       "      <td>2.223367</td>\n",
       "      <td>-1.218611</td>\n",
       "      <td>1.466509</td>\n",
       "      <td>1.397878</td>\n",
       "      <td>-0.115091</td>\n",
       "      <td>0.659171</td>\n",
       "      <td>-0.984125</td>\n",
       "      <td>1.209394</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.524147</td>\n",
       "      <td>0.209694</td>\n",
       "      <td>-0.005608</td>\n",
       "      <td>-0.063170</td>\n",
       "      <td>-0.004228</td>\n",
       "      <td>-0.078369</td>\n",
       "      <td>-0.054491</td>\n",
       "      <td>0.191618</td>\n",
       "      <td>0.049581</td>\n",
       "      <td>-0.006723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093082</td>\n",
       "      <td>-0.005747</td>\n",
       "      <td>0.015671</td>\n",
       "      <td>0.100194</td>\n",
       "      <td>-0.135161</td>\n",
       "      <td>0.177163</td>\n",
       "      <td>0.031842</td>\n",
       "      <td>0.076852</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1         2          3         4         5         6  \\\n",
       "0  28.988852  17.490372  4.483373  10.509126  5.397744 -0.926823  3.355568   \n",
       "1   7.884548   5.748482  0.403125   1.404040  0.653220  1.257143 -0.593541   \n",
       "2   4.121422   2.480523  0.404007   0.250735  0.482196  0.335659  0.472907   \n",
       "3   6.781711   4.500030  0.547421   1.054502  0.525633  0.789035  0.103779   \n",
       "4   0.524147   0.209694 -0.005608  -0.063170 -0.004228 -0.078369 -0.054491   \n",
       "\n",
       "          7         8         9  ...       120       121       122       123  \\\n",
       "0  8.757118  4.470564 -2.814009  ...  3.334058 -6.393062  0.072684  4.186450   \n",
       "1  2.184529 -0.704112 -1.652778  ...  2.461198 -1.745446  2.362890  1.442992   \n",
       "2  0.459064  0.495564  0.292008  ...  1.581233 -0.229335  0.574020  0.871957   \n",
       "3  1.189162  0.177748 -0.602985  ...  2.223367 -1.218611  1.466509  1.397878   \n",
       "4  0.191618  0.049581 -0.006723  ...  0.093082 -0.005747  0.015671  0.100194   \n",
       "\n",
       "        124       125       126       127  Attack  Attack_tvt  \n",
       "0 -1.494370  3.811220 -0.573833  8.586548       4       train  \n",
       "1 -0.611457  0.822156 -1.776823  2.040227       0         val  \n",
       "2  0.245003  0.645052  0.121356  0.293409       0         val  \n",
       "3 -0.115091  0.659171 -0.984125  1.209394       0       train  \n",
       "4 -0.135161  0.177163  0.031842  0.076852       0         val  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save: ../output_emb/AnomalE_nf_bot_multi_cv1.pkl\n",
      "Fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/category_encoders/target_encoder.py:92: FutureWarning: Default parameter min_samples_leaf will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter min_samples_leaf will change in version 2.6.\"\n",
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/category_encoders/target_encoder.py:97: FutureWarning: Default parameter smoothing will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter smoothing will change in version 2.6.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: (480080, 12) (480080,)\n",
      "['OUT_PKTS', 'L7_PROTO', 'FLOW_DURATION_MILLISECONDS', 'IN_PKTS', 'IN_BYTES', 'OUT_BYTES', 'PROTOCOL', 'TCP_FLAGS']\n",
      "Convert NX graph to DGL\n",
      "Number of samples: (120020, 12) (120020,)\n",
      "['OUT_PKTS', 'L7_PROTO', 'FLOW_DURATION_MILLISECONDS', 'IN_PKTS', 'IN_BYTES', 'OUT_BYTES', 'PROTOCOL', 'TCP_FLAGS']\n",
      "Convert NX graph to DGL\n",
      "To device\n",
      "Start training\n",
      "0010 - Loss: 1.6085435152053833\n",
      "0020 - Loss: 1.3136672973632812\n",
      "0030 - Loss: 1.211733102798462\n",
      "0040 - Loss: 1.0541478395462036\n",
      "0050 - Loss: 0.8296260237693787\n",
      "0060 - Loss: 0.6504720449447632\n",
      "0070 - Loss: 0.5811723470687866\n",
      "0080 - Loss: 0.561342716217041\n",
      "0090 - Loss: 0.5544930696487427\n",
      "0100 - Loss: 0.5374630689620972\n",
      "0110 - Loss: 0.526496171951294\n",
      "0120 - Loss: 0.5204838514328003\n",
      "0130 - Loss: 0.5086454153060913\n",
      "0140 - Loss: 0.49657952785491943\n",
      "0150 - Loss: 0.5006409287452698\n",
      "0160 - Loss: 0.4846552312374115\n",
      "0170 - Loss: 0.4653604030609131\n",
      "0180 - Loss: 0.45228976011276245\n",
      "0190 - Loss: 0.4486609101295471\n",
      "0200 - Loss: 0.4385201930999756\n",
      "0210 - Loss: 0.4412359297275543\n",
      "0220 - Loss: 0.43046247959136963\n",
      "0230 - Loss: 0.4322946071624756\n",
      "0240 - Loss: 0.42073190212249756\n",
      "0250 - Loss: 0.47458067536354065\n",
      "0260 - Loss: 0.4145185649394989\n",
      "0270 - Loss: 0.4087843894958496\n",
      "0280 - Loss: 0.41356492042541504\n",
      "0290 - Loss: 0.39853382110595703\n",
      "0300 - Loss: 0.40118759870529175\n",
      "0310 - Loss: 0.3886358439922333\n",
      "0320 - Loss: 0.38739749789237976\n",
      "0330 - Loss: 0.4355732798576355\n",
      "0340 - Loss: 0.4614758789539337\n",
      "0350 - Loss: 0.4138033092021942\n",
      "0360 - Loss: 0.38353636860847473\n",
      "0370 - Loss: 0.3781191110610962\n",
      "0380 - Loss: 0.3781387507915497\n",
      "0390 - Loss: 0.3705693185329437\n",
      "0400 - Loss: 0.3684580326080322\n",
      "0410 - Loss: 0.3637228012084961\n",
      "0420 - Loss: 0.35358893871307373\n",
      "0430 - Loss: 0.35327404737472534\n",
      "0440 - Loss: 0.3445001244544983\n",
      "0450 - Loss: 0.339627206325531\n",
      "0460 - Loss: 0.34082725644111633\n",
      "0470 - Loss: 0.4716038703918457\n",
      "0480 - Loss: 0.3563634157180786\n",
      "0490 - Loss: 0.4013591408729553\n",
      "0500 - Loss: 0.33843308687210083\n",
      "0510 - Loss: 0.3337259590625763\n",
      "0520 - Loss: 0.32732105255126953\n",
      "0530 - Loss: 0.3166947066783905\n",
      "0540 - Loss: 0.32006171345710754\n",
      "0550 - Loss: 0.3099838197231293\n",
      "0560 - Loss: 0.3061021864414215\n",
      "0570 - Loss: 0.3100736737251282\n",
      "0580 - Loss: 0.5789924263954163\n",
      "0590 - Loss: 0.6164458394050598\n",
      "0600 - Loss: 0.40799903869628906\n",
      "0610 - Loss: 0.3519718050956726\n",
      "0620 - Loss: 0.31808778643608093\n",
      "0630 - Loss: 0.30710047483444214\n",
      "0640 - Loss: 0.3039233088493347\n",
      "0650 - Loss: 0.3015129566192627\n",
      "0660 - Loss: 0.29447492957115173\n",
      "0670 - Loss: 0.29184117913246155\n",
      "0680 - Loss: 0.2935478687286377\n",
      "0690 - Loss: 0.2879568636417389\n",
      "0700 - Loss: 0.28381943702697754\n",
      "0710 - Loss: 0.2860942482948303\n",
      "0720 - Loss: 0.277768611907959\n",
      "0730 - Loss: 0.27046263217926025\n",
      "0740 - Loss: 0.2653025984764099\n",
      "0750 - Loss: 0.26281511783599854\n",
      "0760 - Loss: 0.26178598403930664\n",
      "0770 - Loss: 0.2575598359107971\n",
      "0780 - Loss: 0.2938767671585083\n",
      "0790 - Loss: 0.32131972908973694\n",
      "0800 - Loss: 0.28601646423339844\n",
      "0810 - Loss: 0.2682593762874603\n",
      "0820 - Loss: 0.26094695925712585\n",
      "0830 - Loss: 0.256105899810791\n",
      "0840 - Loss: 0.25055402517318726\n",
      "0850 - Loss: 0.2477996051311493\n",
      "0860 - Loss: 0.24256576597690582\n",
      "0870 - Loss: 0.46830299496650696\n",
      "0880 - Loss: 1.0996748208999634\n",
      "0890 - Loss: 0.7323786616325378\n",
      "0900 - Loss: 0.3363874554634094\n",
      "0910 - Loss: 0.2942214012145996\n",
      "0920 - Loss: 0.27647578716278076\n",
      "0930 - Loss: 0.2626981735229492\n",
      "0940 - Loss: 0.26362261176109314\n",
      "0950 - Loss: 0.25562161207199097\n",
      "0960 - Loss: 0.2539106011390686\n",
      "0970 - Loss: 0.25110000371932983\n",
      "0980 - Loss: 0.2500799000263214\n",
      "0990 - Loss: 0.2467835545539856\n",
      "1000 - Loss: 0.24803602695465088\n",
      "1010 - Loss: 0.24314886331558228\n",
      "1020 - Loss: 0.23768240213394165\n",
      "1030 - Loss: 0.23986265063285828\n",
      "1040 - Loss: 0.23926052451133728\n",
      "1050 - Loss: 0.23358143866062164\n",
      "1060 - Loss: 0.230703204870224\n",
      "1070 - Loss: 0.23334573209285736\n",
      "1080 - Loss: 0.22678761184215546\n",
      "1090 - Loss: 0.218654602766037\n",
      "1100 - Loss: 0.21802961826324463\n",
      "1110 - Loss: 0.22324658930301666\n",
      "1120 - Loss: 0.22602225840091705\n",
      "1130 - Loss: 0.2151944637298584\n",
      "1140 - Loss: 0.22470130026340485\n",
      "1150 - Loss: 1.2742195129394531\n",
      "1160 - Loss: 0.8143317103385925\n",
      "1170 - Loss: 0.36622560024261475\n",
      "1180 - Loss: 0.2997710108757019\n",
      "1190 - Loss: 0.2788142263889313\n",
      "1200 - Loss: 0.27282264828681946\n",
      "1210 - Loss: 0.258412629365921\n",
      "1220 - Loss: 0.2556324899196625\n",
      "1230 - Loss: 0.2513304352760315\n",
      "1240 - Loss: 0.24968355894088745\n",
      "1250 - Loss: 0.24524907767772675\n",
      "1260 - Loss: 0.24227800965309143\n",
      "1270 - Loss: 0.2401975840330124\n",
      "1280 - Loss: 0.23622402548789978\n",
      "1290 - Loss: 0.2349507361650467\n",
      "1300 - Loss: 0.23087990283966064\n",
      "1310 - Loss: 0.22888760268688202\n",
      "1320 - Loss: 0.22945687174797058\n",
      "1330 - Loss: 0.22689999639987946\n",
      "1340 - Loss: 0.22474488615989685\n",
      "1350 - Loss: 0.22387559711933136\n",
      "1360 - Loss: 0.21919026970863342\n",
      "1370 - Loss: 0.22098307311534882\n",
      "1380 - Loss: 0.21716782450675964\n",
      "1390 - Loss: 0.2155311107635498\n",
      "1400 - Loss: 0.21536818146705627\n",
      "1410 - Loss: 0.21568459272384644\n",
      "1420 - Loss: 0.289522647857666\n",
      "1430 - Loss: 0.21890980005264282\n",
      "1440 - Loss: 0.211591899394989\n",
      "1450 - Loss: 0.21369120478630066\n",
      "1460 - Loss: 0.20590287446975708\n",
      "1470 - Loss: 0.21267136931419373\n",
      "1480 - Loss: 0.20361328125\n",
      "1490 - Loss: 0.2354542315006256\n",
      "1500 - Loss: 0.21502836048603058\n",
      "1510 - Loss: 0.23158931732177734\n",
      "1520 - Loss: 0.22613951563835144\n",
      "1530 - Loss: 0.21448737382888794\n",
      "1540 - Loss: 0.19673049449920654\n",
      "1550 - Loss: 0.19440330564975739\n",
      "1560 - Loss: 0.19278880953788757\n",
      "1570 - Loss: 0.5268488526344299\n",
      "1580 - Loss: 1.1230990886688232\n",
      "1590 - Loss: 1.1855652332305908\n",
      "1600 - Loss: 0.5390788912773132\n",
      "1610 - Loss: 0.4175974726676941\n",
      "1620 - Loss: 0.3324836492538452\n",
      "1630 - Loss: 0.30264613032341003\n",
      "1640 - Loss: 0.2883583903312683\n",
      "1650 - Loss: 0.2775123417377472\n",
      "1660 - Loss: 0.2709182798862457\n",
      "1670 - Loss: 0.2684552073478699\n",
      "1680 - Loss: 0.2667802572250366\n",
      "1690 - Loss: 0.2669735848903656\n",
      "1700 - Loss: 0.2650276720523834\n",
      "1710 - Loss: 0.2606598734855652\n",
      "1720 - Loss: 0.26056569814682007\n",
      "1730 - Loss: 0.26267677545547485\n",
      "1740 - Loss: 0.2589960992336273\n",
      "1750 - Loss: 0.25763455033302307\n",
      "1760 - Loss: 0.2525597810745239\n",
      "1770 - Loss: 0.2540813088417053\n",
      "1780 - Loss: 0.2511880397796631\n",
      "1790 - Loss: 0.25104987621307373\n",
      "1800 - Loss: 0.2485755831003189\n",
      "1810 - Loss: 0.25090503692626953\n",
      "1820 - Loss: 0.24392087757587433\n",
      "1830 - Loss: 0.2416684925556183\n",
      "1840 - Loss: 0.2431432455778122\n",
      "1850 - Loss: 0.23836898803710938\n",
      "1860 - Loss: 0.2356116771697998\n",
      "1870 - Loss: 0.23273389041423798\n",
      "1880 - Loss: 0.23774169385433197\n",
      "1890 - Loss: 0.23250460624694824\n",
      "1900 - Loss: 0.22643236815929413\n",
      "1910 - Loss: 0.22990065813064575\n",
      "1920 - Loss: 0.22745931148529053\n",
      "1930 - Loss: 0.22401046752929688\n",
      "1940 - Loss: 0.22555230557918549\n",
      "1950 - Loss: 0.221822589635849\n",
      "1960 - Loss: 0.21691107749938965\n",
      "1970 - Loss: 0.2207604944705963\n",
      "1980 - Loss: 0.21763849258422852\n",
      "1990 - Loss: 0.21289609372615814\n",
      "2000 - Loss: 0.21339870989322662\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Attack_tvt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.053724</td>\n",
       "      <td>0.055671</td>\n",
       "      <td>0.122328</td>\n",
       "      <td>0.020789</td>\n",
       "      <td>0.152847</td>\n",
       "      <td>0.014215</td>\n",
       "      <td>0.129281</td>\n",
       "      <td>0.011974</td>\n",
       "      <td>0.102001</td>\n",
       "      <td>-0.006122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008323</td>\n",
       "      <td>0.020187</td>\n",
       "      <td>0.154942</td>\n",
       "      <td>-0.013180</td>\n",
       "      <td>0.029683</td>\n",
       "      <td>0.091296</td>\n",
       "      <td>0.119536</td>\n",
       "      <td>0.045170</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.445944</td>\n",
       "      <td>0.404989</td>\n",
       "      <td>10.664376</td>\n",
       "      <td>-10.314894</td>\n",
       "      <td>2.830842</td>\n",
       "      <td>22.498606</td>\n",
       "      <td>1.334156</td>\n",
       "      <td>7.196707</td>\n",
       "      <td>15.806669</td>\n",
       "      <td>0.311824</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.407197</td>\n",
       "      <td>-2.896572</td>\n",
       "      <td>13.561170</td>\n",
       "      <td>9.723530</td>\n",
       "      <td>2.532262</td>\n",
       "      <td>16.235571</td>\n",
       "      <td>0.511161</td>\n",
       "      <td>11.122770</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.475341</td>\n",
       "      <td>0.668582</td>\n",
       "      <td>2.650001</td>\n",
       "      <td>-1.005129</td>\n",
       "      <td>0.413942</td>\n",
       "      <td>2.353671</td>\n",
       "      <td>-0.345030</td>\n",
       "      <td>0.386677</td>\n",
       "      <td>2.091810</td>\n",
       "      <td>-0.656011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962305</td>\n",
       "      <td>0.444945</td>\n",
       "      <td>2.555262</td>\n",
       "      <td>0.655033</td>\n",
       "      <td>1.525870</td>\n",
       "      <td>2.915280</td>\n",
       "      <td>2.858174</td>\n",
       "      <td>1.486351</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.669859</td>\n",
       "      <td>1.572931</td>\n",
       "      <td>3.542829</td>\n",
       "      <td>-2.425849</td>\n",
       "      <td>0.757295</td>\n",
       "      <td>3.078577</td>\n",
       "      <td>-1.363463</td>\n",
       "      <td>0.788575</td>\n",
       "      <td>2.855751</td>\n",
       "      <td>-1.535230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884767</td>\n",
       "      <td>-0.068048</td>\n",
       "      <td>4.749258</td>\n",
       "      <td>0.978374</td>\n",
       "      <td>1.629967</td>\n",
       "      <td>4.266332</td>\n",
       "      <td>4.550956</td>\n",
       "      <td>2.493099</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.475341</td>\n",
       "      <td>0.668582</td>\n",
       "      <td>2.650001</td>\n",
       "      <td>-1.005129</td>\n",
       "      <td>0.413942</td>\n",
       "      <td>2.353671</td>\n",
       "      <td>-0.345030</td>\n",
       "      <td>0.386677</td>\n",
       "      <td>2.091810</td>\n",
       "      <td>-0.656011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962305</td>\n",
       "      <td>0.444945</td>\n",
       "      <td>2.555262</td>\n",
       "      <td>0.655033</td>\n",
       "      <td>1.525870</td>\n",
       "      <td>2.915280</td>\n",
       "      <td>2.858174</td>\n",
       "      <td>1.486351</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1          2          3         4          5         6  \\\n",
       "0 -0.053724  0.055671   0.122328   0.020789  0.152847   0.014215  0.129281   \n",
       "1  9.445944  0.404989  10.664376 -10.314894  2.830842  22.498606  1.334156   \n",
       "2  2.475341  0.668582   2.650001  -1.005129  0.413942   2.353671 -0.345030   \n",
       "3  4.669859  1.572931   3.542829  -2.425849  0.757295   3.078577 -1.363463   \n",
       "4  2.475341  0.668582   2.650001  -1.005129  0.413942   2.353671 -0.345030   \n",
       "\n",
       "          7          8         9  ...       120       121        122  \\\n",
       "0  0.011974   0.102001 -0.006122  ...  0.008323  0.020187   0.154942   \n",
       "1  7.196707  15.806669  0.311824  ... -1.407197 -2.896572  13.561170   \n",
       "2  0.386677   2.091810 -0.656011  ...  0.962305  0.444945   2.555262   \n",
       "3  0.788575   2.855751 -1.535230  ...  0.884767 -0.068048   4.749258   \n",
       "4  0.386677   2.091810 -0.656011  ...  0.962305  0.444945   2.555262   \n",
       "\n",
       "        123       124        125       126        127  Attack  Attack_tvt  \n",
       "0 -0.013180  0.029683   0.091296  0.119536   0.045170       0       train  \n",
       "1  9.723530  2.532262  16.235571  0.511161  11.122770       4       train  \n",
       "2  0.655033  1.525870   2.915280  2.858174   1.486351       0       train  \n",
       "3  0.978374  1.629967   4.266332  4.550956   2.493099       0       train  \n",
       "4  0.655033  1.525870   2.915280  2.858174   1.486351       0       train  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save: ../output_emb/AnomalE_nf_bot_multi_cv2.pkl\n",
      "Fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/category_encoders/target_encoder.py:92: FutureWarning: Default parameter min_samples_leaf will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter min_samples_leaf will change in version 2.6.\"\n",
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/category_encoders/target_encoder.py:97: FutureWarning: Default parameter smoothing will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter smoothing will change in version 2.6.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: (480080, 12) (480080,)\n",
      "['OUT_PKTS', 'L7_PROTO', 'FLOW_DURATION_MILLISECONDS', 'IN_PKTS', 'IN_BYTES', 'OUT_BYTES', 'PROTOCOL', 'TCP_FLAGS']\n",
      "Convert NX graph to DGL\n",
      "Number of samples: (120020, 12) (120020,)\n",
      "['OUT_PKTS', 'L7_PROTO', 'FLOW_DURATION_MILLISECONDS', 'IN_PKTS', 'IN_BYTES', 'OUT_BYTES', 'PROTOCOL', 'TCP_FLAGS']\n",
      "Convert NX graph to DGL\n",
      "To device\n",
      "Start training\n",
      "0010 - Loss: 1.7135640382766724\n",
      "0020 - Loss: 1.310429573059082\n",
      "0030 - Loss: 1.2382841110229492\n",
      "0040 - Loss: 1.0735101699829102\n",
      "0050 - Loss: 0.834894061088562\n",
      "0060 - Loss: 0.6210454106330872\n",
      "0070 - Loss: 0.5485843420028687\n",
      "0080 - Loss: 0.525503933429718\n",
      "0090 - Loss: 0.5069828033447266\n",
      "0100 - Loss: 0.49468228220939636\n",
      "0110 - Loss: 0.4764484763145447\n",
      "0120 - Loss: 0.4664996862411499\n",
      "0130 - Loss: 0.4534280300140381\n",
      "0140 - Loss: 0.4401567280292511\n",
      "0150 - Loss: 0.43233269453048706\n",
      "0160 - Loss: 0.4311213493347168\n",
      "0170 - Loss: 0.4391110837459564\n",
      "0180 - Loss: 0.41409701108932495\n",
      "0190 - Loss: 0.40797221660614014\n",
      "0200 - Loss: 0.4081347584724426\n",
      "0210 - Loss: 0.39650046825408936\n",
      "0220 - Loss: 0.39073821902275085\n",
      "0230 - Loss: 0.4010283946990967\n",
      "0240 - Loss: 0.46920597553253174\n",
      "0250 - Loss: 0.3877769708633423\n",
      "0260 - Loss: 0.3919180631637573\n",
      "0270 - Loss: 0.3768119812011719\n",
      "0280 - Loss: 0.3727114796638489\n",
      "0290 - Loss: 0.3601122498512268\n",
      "0300 - Loss: 0.3535161018371582\n",
      "0310 - Loss: 0.35031813383102417\n",
      "0320 - Loss: 0.3439890742301941\n",
      "0330 - Loss: 0.34040290117263794\n",
      "0340 - Loss: 0.3405054211616516\n",
      "0350 - Loss: 0.3998605012893677\n",
      "0360 - Loss: 0.3530811071395874\n",
      "0370 - Loss: 0.3301696181297302\n",
      "0380 - Loss: 0.33247631788253784\n",
      "0390 - Loss: 0.31000229716300964\n",
      "0400 - Loss: 0.30732738971710205\n",
      "0410 - Loss: 0.3027127981185913\n",
      "0420 - Loss: 0.29531970620155334\n",
      "0430 - Loss: 0.5491090416908264\n",
      "0440 - Loss: 0.35340702533721924\n",
      "0450 - Loss: 0.35821765661239624\n",
      "0460 - Loss: 0.3006020486354828\n",
      "0470 - Loss: 0.2991555333137512\n",
      "0480 - Loss: 0.28405889868736267\n",
      "0490 - Loss: 0.2778759300708771\n",
      "0500 - Loss: 0.27291181683540344\n",
      "0510 - Loss: 0.2706741690635681\n",
      "0520 - Loss: 0.2792210280895233\n",
      "0530 - Loss: 0.28753533959388733\n",
      "0540 - Loss: 0.3096790611743927\n",
      "0550 - Loss: 0.267492413520813\n",
      "0560 - Loss: 0.24813959002494812\n",
      "0570 - Loss: 0.24442672729492188\n",
      "0580 - Loss: 0.24217632412910461\n",
      "0590 - Loss: 0.30929088592529297\n",
      "0600 - Loss: 0.2609679698944092\n",
      "0610 - Loss: 0.41329875588417053\n",
      "0620 - Loss: 0.2632691264152527\n",
      "0630 - Loss: 0.2872055172920227\n",
      "0640 - Loss: 0.23451271653175354\n",
      "0650 - Loss: 0.22778776288032532\n",
      "0660 - Loss: 0.21819156408309937\n",
      "0670 - Loss: 0.2181684672832489\n",
      "0680 - Loss: 0.2115475833415985\n",
      "0690 - Loss: 0.2137594223022461\n",
      "0700 - Loss: 0.20126581192016602\n",
      "0710 - Loss: 0.20115356147289276\n",
      "0720 - Loss: 0.21656475961208344\n",
      "0730 - Loss: 0.6345313191413879\n",
      "0740 - Loss: 0.6613070368766785\n",
      "0750 - Loss: 0.39456480741500854\n",
      "0760 - Loss: 0.3394724428653717\n",
      "0770 - Loss: 0.32636699080467224\n",
      "0780 - Loss: 0.3227927088737488\n",
      "0790 - Loss: 0.31356483697891235\n",
      "0800 - Loss: 0.3126088082790375\n",
      "0810 - Loss: 0.3057810068130493\n",
      "0820 - Loss: 0.30414560437202454\n",
      "0830 - Loss: 0.30212128162384033\n",
      "0840 - Loss: 0.30234646797180176\n",
      "0850 - Loss: 0.29378655552864075\n",
      "0860 - Loss: 0.29614800214767456\n",
      "0870 - Loss: 0.29058927297592163\n",
      "0880 - Loss: 0.28763309121131897\n",
      "0890 - Loss: 0.2843819260597229\n",
      "0900 - Loss: 0.28393110632896423\n",
      "0910 - Loss: 0.2830488979816437\n",
      "0920 - Loss: 0.2797764837741852\n",
      "0930 - Loss: 0.27777594327926636\n",
      "0940 - Loss: 0.27369225025177\n",
      "0950 - Loss: 0.27436280250549316\n",
      "0960 - Loss: 0.2711484134197235\n",
      "0970 - Loss: 0.26792213320732117\n",
      "0980 - Loss: 0.2697412073612213\n",
      "0990 - Loss: 0.264493465423584\n",
      "1000 - Loss: 0.2622852921485901\n",
      "1010 - Loss: 0.26095929741859436\n",
      "1020 - Loss: 0.2579769492149353\n",
      "1030 - Loss: 0.25551024079322815\n",
      "1040 - Loss: 0.25120002031326294\n",
      "1050 - Loss: 0.25340938568115234\n",
      "1060 - Loss: 0.2512354850769043\n",
      "1070 - Loss: 0.24807700514793396\n",
      "1080 - Loss: 0.2468891441822052\n",
      "1090 - Loss: 0.2423492670059204\n",
      "1100 - Loss: 0.23879508674144745\n",
      "1110 - Loss: 0.23415453732013702\n",
      "1120 - Loss: 0.23270642757415771\n",
      "1130 - Loss: 0.23247793316841125\n",
      "1140 - Loss: 0.2309274971485138\n",
      "1150 - Loss: 0.22794243693351746\n",
      "1160 - Loss: 0.23713801801204681\n",
      "1170 - Loss: 0.22208264470100403\n",
      "1180 - Loss: 0.21732275187969208\n",
      "1190 - Loss: 0.22328007221221924\n",
      "1200 - Loss: 0.21732479333877563\n",
      "1210 - Loss: 0.2139955759048462\n",
      "1220 - Loss: 0.2769005596637726\n",
      "1230 - Loss: 0.23181012272834778\n",
      "1240 - Loss: 0.23019666969776154\n",
      "1250 - Loss: 0.2544226050376892\n",
      "1260 - Loss: 0.23376548290252686\n",
      "1270 - Loss: 0.2531668543815613\n",
      "1280 - Loss: 0.276004821062088\n",
      "1290 - Loss: 0.21032217144966125\n",
      "1300 - Loss: 0.21048831939697266\n",
      "1310 - Loss: 0.20205840468406677\n",
      "1320 - Loss: 0.1999502032995224\n",
      "1330 - Loss: 0.21796441078186035\n",
      "1340 - Loss: 0.2148311734199524\n",
      "1350 - Loss: 0.5536088347434998\n",
      "1360 - Loss: 1.1276246309280396\n",
      "1370 - Loss: 0.5573717355728149\n",
      "1380 - Loss: 0.3788006007671356\n",
      "1390 - Loss: 0.3237716853618622\n",
      "1400 - Loss: 0.2619374096393585\n",
      "1410 - Loss: 0.2556021809577942\n",
      "1420 - Loss: 0.25073739886283875\n",
      "1430 - Loss: 0.24032291769981384\n",
      "1440 - Loss: 0.237859308719635\n",
      "1450 - Loss: 0.2357279360294342\n",
      "1460 - Loss: 0.23224827647209167\n",
      "1470 - Loss: 0.23034991323947906\n",
      "1480 - Loss: 0.2297786921262741\n",
      "1490 - Loss: 0.22757069766521454\n",
      "1500 - Loss: 0.22431254386901855\n",
      "1510 - Loss: 0.22325779497623444\n",
      "1520 - Loss: 0.2217334806919098\n",
      "1530 - Loss: 0.22172796726226807\n",
      "1540 - Loss: 0.2184353768825531\n",
      "1550 - Loss: 0.21727067232131958\n",
      "1560 - Loss: 0.21416038274765015\n",
      "1570 - Loss: 0.2143651843070984\n",
      "1580 - Loss: 0.2138373851776123\n",
      "1590 - Loss: 0.2118578404188156\n",
      "1600 - Loss: 0.20746327936649323\n",
      "1610 - Loss: 0.20560677349567413\n",
      "1620 - Loss: 0.2043388932943344\n",
      "1630 - Loss: 0.20416605472564697\n",
      "1640 - Loss: 0.20067840814590454\n",
      "1650 - Loss: 0.2011323869228363\n",
      "1660 - Loss: 0.19950082898139954\n",
      "1670 - Loss: 0.1947232186794281\n",
      "1680 - Loss: 0.19668525457382202\n",
      "1690 - Loss: 0.1947750598192215\n",
      "1700 - Loss: 0.19562315940856934\n",
      "1710 - Loss: 0.18989130854606628\n",
      "1720 - Loss: 0.18884339928627014\n",
      "1730 - Loss: 0.18782824277877808\n",
      "1740 - Loss: 0.18741881847381592\n",
      "1750 - Loss: 0.1862361878156662\n",
      "1760 - Loss: 0.18654026091098785\n",
      "1770 - Loss: 0.18335551023483276\n",
      "1780 - Loss: 0.18117660284042358\n",
      "1790 - Loss: 0.18160364031791687\n",
      "1800 - Loss: 0.1819041520357132\n",
      "1810 - Loss: 0.17888247966766357\n",
      "1820 - Loss: 0.18088668584823608\n",
      "1830 - Loss: 0.20195534825325012\n",
      "1840 - Loss: 0.18854953348636627\n",
      "1850 - Loss: 0.187074214220047\n",
      "1860 - Loss: 0.17789968848228455\n",
      "1870 - Loss: 0.17288416624069214\n",
      "1880 - Loss: 0.2478417456150055\n",
      "1890 - Loss: 1.781822919845581\n",
      "1900 - Loss: 0.8833156824111938\n",
      "1910 - Loss: 0.5001052618026733\n",
      "1920 - Loss: 0.28400325775146484\n",
      "1930 - Loss: 0.24212509393692017\n",
      "1940 - Loss: 0.21459068357944489\n",
      "1950 - Loss: 0.20767802000045776\n",
      "1960 - Loss: 0.20142889022827148\n",
      "1970 - Loss: 0.20004644989967346\n",
      "1980 - Loss: 0.19235344231128693\n",
      "1990 - Loss: 0.1926741749048233\n",
      "2000 - Loss: 0.19141295552253723\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Attack_tvt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.005459</td>\n",
       "      <td>0.056402</td>\n",
       "      <td>0.160437</td>\n",
       "      <td>0.092969</td>\n",
       "      <td>0.037350</td>\n",
       "      <td>0.060870</td>\n",
       "      <td>0.087790</td>\n",
       "      <td>-0.011695</td>\n",
       "      <td>0.017384</td>\n",
       "      <td>0.132252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125594</td>\n",
       "      <td>0.158441</td>\n",
       "      <td>0.056155</td>\n",
       "      <td>0.110055</td>\n",
       "      <td>0.043090</td>\n",
       "      <td>0.047860</td>\n",
       "      <td>0.198315</td>\n",
       "      <td>-0.010529</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-10.789020</td>\n",
       "      <td>-0.684547</td>\n",
       "      <td>0.736268</td>\n",
       "      <td>11.548258</td>\n",
       "      <td>3.680820</td>\n",
       "      <td>-0.346116</td>\n",
       "      <td>6.007852</td>\n",
       "      <td>6.319572</td>\n",
       "      <td>-6.894775</td>\n",
       "      <td>12.862212</td>\n",
       "      <td>...</td>\n",
       "      <td>2.619545</td>\n",
       "      <td>13.565704</td>\n",
       "      <td>-2.580909</td>\n",
       "      <td>14.010063</td>\n",
       "      <td>1.347686</td>\n",
       "      <td>3.276218</td>\n",
       "      <td>15.448701</td>\n",
       "      <td>0.709198</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.771369</td>\n",
       "      <td>1.680122</td>\n",
       "      <td>0.003228</td>\n",
       "      <td>2.023825</td>\n",
       "      <td>-0.334287</td>\n",
       "      <td>1.091513</td>\n",
       "      <td>0.871815</td>\n",
       "      <td>0.936393</td>\n",
       "      <td>-0.435344</td>\n",
       "      <td>2.929645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071037</td>\n",
       "      <td>3.605663</td>\n",
       "      <td>2.477155</td>\n",
       "      <td>2.321013</td>\n",
       "      <td>1.452110</td>\n",
       "      <td>-1.043931</td>\n",
       "      <td>2.956440</td>\n",
       "      <td>1.294322</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.771369</td>\n",
       "      <td>1.680122</td>\n",
       "      <td>0.003228</td>\n",
       "      <td>2.023825</td>\n",
       "      <td>-0.334287</td>\n",
       "      <td>1.091513</td>\n",
       "      <td>0.871815</td>\n",
       "      <td>0.936393</td>\n",
       "      <td>-0.435344</td>\n",
       "      <td>2.929645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071037</td>\n",
       "      <td>3.605663</td>\n",
       "      <td>2.477155</td>\n",
       "      <td>2.321013</td>\n",
       "      <td>1.452110</td>\n",
       "      <td>-1.043931</td>\n",
       "      <td>2.956440</td>\n",
       "      <td>1.294322</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.228120</td>\n",
       "      <td>0.159319</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.158878</td>\n",
       "      <td>-0.021930</td>\n",
       "      <td>0.093691</td>\n",
       "      <td>0.218024</td>\n",
       "      <td>0.218714</td>\n",
       "      <td>0.043308</td>\n",
       "      <td>0.672588</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020125</td>\n",
       "      <td>0.693883</td>\n",
       "      <td>0.646654</td>\n",
       "      <td>0.309379</td>\n",
       "      <td>0.271068</td>\n",
       "      <td>-0.208817</td>\n",
       "      <td>0.695550</td>\n",
       "      <td>0.175448</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2          3         4         5         6  \\\n",
       "0  -0.005459  0.056402  0.160437   0.092969  0.037350  0.060870  0.087790   \n",
       "1 -10.789020 -0.684547  0.736268  11.548258  3.680820 -0.346116  6.007852   \n",
       "2  -1.771369  1.680122  0.003228   2.023825 -0.334287  1.091513  0.871815   \n",
       "3  -1.771369  1.680122  0.003228   2.023825 -0.334287  1.091513  0.871815   \n",
       "4  -0.228120  0.159319  0.027300   0.158878 -0.021930  0.093691  0.218024   \n",
       "\n",
       "          7         8          9  ...       120        121       122  \\\n",
       "0 -0.011695  0.017384   0.132252  ...  0.125594   0.158441  0.056155   \n",
       "1  6.319572 -6.894775  12.862212  ...  2.619545  13.565704 -2.580909   \n",
       "2  0.936393 -0.435344   2.929645  ... -0.071037   3.605663  2.477155   \n",
       "3  0.936393 -0.435344   2.929645  ... -0.071037   3.605663  2.477155   \n",
       "4  0.218714  0.043308   0.672588  ... -0.020125   0.693883  0.646654   \n",
       "\n",
       "         123       124       125        126       127  Attack  Attack_tvt  \n",
       "0   0.110055  0.043090  0.047860   0.198315 -0.010529       0       train  \n",
       "1  14.010063  1.347686  3.276218  15.448701  0.709198       4       train  \n",
       "2   2.321013  1.452110 -1.043931   2.956440  1.294322       0       train  \n",
       "3   2.321013  1.452110 -1.043931   2.956440  1.294322       0         val  \n",
       "4   0.309379  0.271068 -0.208817   0.695550  0.175448       0       train  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save: ../output_emb/AnomalE_nf_bot_multi_cv3.pkl\n",
      "Fold: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/category_encoders/target_encoder.py:92: FutureWarning: Default parameter min_samples_leaf will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter min_samples_leaf will change in version 2.6.\"\n",
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/category_encoders/target_encoder.py:97: FutureWarning: Default parameter smoothing will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter smoothing will change in version 2.6.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: (480080, 12) (480080,)\n",
      "['OUT_PKTS', 'L7_PROTO', 'FLOW_DURATION_MILLISECONDS', 'IN_PKTS', 'IN_BYTES', 'OUT_BYTES', 'PROTOCOL', 'TCP_FLAGS']\n",
      "Convert NX graph to DGL\n",
      "Number of samples: (120020, 12) (120020,)\n",
      "['OUT_PKTS', 'L7_PROTO', 'FLOW_DURATION_MILLISECONDS', 'IN_PKTS', 'IN_BYTES', 'OUT_BYTES', 'PROTOCOL', 'TCP_FLAGS']\n",
      "Convert NX graph to DGL\n",
      "To device\n",
      "Start training\n",
      "0010 - Loss: 1.5647516250610352\n",
      "0020 - Loss: 1.261464238166809\n",
      "0030 - Loss: 1.1617000102996826\n",
      "0040 - Loss: 0.953518271446228\n",
      "0050 - Loss: 0.6998889446258545\n",
      "0060 - Loss: 0.5567739605903625\n",
      "0070 - Loss: 0.5264344215393066\n",
      "0080 - Loss: 0.5071387887001038\n",
      "0090 - Loss: 0.4941825866699219\n",
      "0100 - Loss: 0.47535306215286255\n",
      "0110 - Loss: 0.45869332551956177\n",
      "0120 - Loss: 0.45292240381240845\n",
      "0130 - Loss: 0.4481305778026581\n",
      "0140 - Loss: 0.43823832273483276\n",
      "0150 - Loss: 0.42938223481178284\n",
      "0160 - Loss: 0.43346092104911804\n",
      "0170 - Loss: 0.4212878346443176\n",
      "0180 - Loss: 0.4199526309967041\n",
      "0190 - Loss: 0.4098898768424988\n",
      "0200 - Loss: 0.4097779393196106\n",
      "0210 - Loss: 0.4077640175819397\n",
      "0220 - Loss: 0.3972599506378174\n",
      "0230 - Loss: 0.46045982837677\n",
      "0240 - Loss: 0.39009636640548706\n",
      "0250 - Loss: 0.3896052837371826\n",
      "0260 - Loss: 0.3807068467140198\n",
      "0270 - Loss: 0.3756733238697052\n",
      "0280 - Loss: 0.3708557188510895\n",
      "0290 - Loss: 0.3650277554988861\n",
      "0300 - Loss: 0.4102221727371216\n",
      "0310 - Loss: 0.35661065578460693\n",
      "0320 - Loss: 0.36640411615371704\n",
      "0330 - Loss: 0.35911205410957336\n",
      "0340 - Loss: 0.34507229924201965\n",
      "0350 - Loss: 0.3410736322402954\n",
      "0360 - Loss: 0.3359326124191284\n",
      "0370 - Loss: 0.3392523527145386\n",
      "0380 - Loss: 0.36608070135116577\n",
      "0390 - Loss: 0.3360119163990021\n",
      "0400 - Loss: 0.3319651782512665\n",
      "0410 - Loss: 0.32864993810653687\n",
      "0420 - Loss: 0.31578510999679565\n",
      "0430 - Loss: 0.3148108422756195\n",
      "0440 - Loss: 0.30771535634994507\n",
      "0450 - Loss: 0.3001752197742462\n",
      "0460 - Loss: 0.6813355684280396\n",
      "0470 - Loss: 0.5363969206809998\n",
      "0480 - Loss: 0.41673940420150757\n",
      "0490 - Loss: 0.3485666513442993\n",
      "0500 - Loss: 0.33563125133514404\n",
      "0510 - Loss: 0.3238471746444702\n",
      "0520 - Loss: 0.3204162120819092\n",
      "0530 - Loss: 0.31168854236602783\n",
      "0540 - Loss: 0.31012508273124695\n",
      "0550 - Loss: 0.3037063181400299\n",
      "0560 - Loss: 0.3020825684070587\n",
      "0570 - Loss: 0.2992076277732849\n",
      "0580 - Loss: 0.2973555028438568\n",
      "0590 - Loss: 0.2935102880001068\n",
      "0600 - Loss: 0.28997543454170227\n",
      "0610 - Loss: 0.28334271907806396\n",
      "0620 - Loss: 0.2769557237625122\n",
      "0630 - Loss: 0.26669225096702576\n",
      "0640 - Loss: 0.26637157797813416\n",
      "0650 - Loss: 0.26045745611190796\n",
      "0660 - Loss: 0.2615577280521393\n",
      "0670 - Loss: 0.25174587965011597\n",
      "0680 - Loss: 0.277809739112854\n",
      "0690 - Loss: 0.2802574932575226\n",
      "0700 - Loss: 0.2739224433898926\n",
      "0710 - Loss: 0.24981072545051575\n",
      "0720 - Loss: 0.2479870319366455\n",
      "0730 - Loss: 0.24026907980442047\n",
      "0740 - Loss: 0.2319192886352539\n",
      "0750 - Loss: 0.22675859928131104\n",
      "0760 - Loss: 0.22552797198295593\n",
      "0770 - Loss: 0.2202213704586029\n",
      "0780 - Loss: 0.21750067174434662\n",
      "0790 - Loss: 0.22768144309520721\n",
      "0800 - Loss: 0.30733346939086914\n",
      "0810 - Loss: 0.42598211765289307\n",
      "0820 - Loss: 0.3720238506793976\n",
      "0830 - Loss: 0.2802945077419281\n",
      "0840 - Loss: 0.25357502698898315\n",
      "0850 - Loss: 0.23946508765220642\n",
      "0860 - Loss: 0.23222297430038452\n",
      "0870 - Loss: 0.23192737996578217\n",
      "0880 - Loss: 0.22395305335521698\n",
      "0890 - Loss: 0.21907593309879303\n",
      "0900 - Loss: 0.21346111595630646\n",
      "0910 - Loss: 0.21317003667354584\n",
      "0920 - Loss: 0.2111627459526062\n",
      "0930 - Loss: 0.20146578550338745\n",
      "0940 - Loss: 0.19867780804634094\n",
      "0950 - Loss: 0.4935608208179474\n",
      "0960 - Loss: 0.5181545615196228\n",
      "0970 - Loss: 0.30213144421577454\n",
      "0980 - Loss: 0.2941347360610962\n",
      "0990 - Loss: 0.2663078308105469\n",
      "1000 - Loss: 0.26545703411102295\n",
      "1010 - Loss: 0.2597886919975281\n",
      "1020 - Loss: 0.2524653375148773\n",
      "1030 - Loss: 0.2540094554424286\n",
      "1040 - Loss: 0.2504691481590271\n",
      "1050 - Loss: 0.25010228157043457\n",
      "1060 - Loss: 0.24766215682029724\n",
      "1070 - Loss: 0.24647149443626404\n",
      "1080 - Loss: 0.24687232077121735\n",
      "1090 - Loss: 0.24631235003471375\n",
      "1100 - Loss: 0.24183377623558044\n",
      "1110 - Loss: 0.23086115717887878\n",
      "1120 - Loss: 0.22055570781230927\n",
      "1130 - Loss: 0.21042758226394653\n",
      "1140 - Loss: 0.20983314514160156\n",
      "1150 - Loss: 0.20767879486083984\n",
      "1160 - Loss: 0.2056179940700531\n",
      "1170 - Loss: 0.2010851502418518\n",
      "1180 - Loss: 0.20158520340919495\n",
      "1190 - Loss: 0.19882947206497192\n",
      "1200 - Loss: 0.1985219269990921\n",
      "1210 - Loss: 0.20089033246040344\n",
      "1220 - Loss: 0.2001877725124359\n",
      "1230 - Loss: 0.1936434507369995\n",
      "1240 - Loss: 0.2453703135251999\n",
      "1250 - Loss: 0.8755704164505005\n",
      "1260 - Loss: 0.8248500823974609\n",
      "1270 - Loss: 0.5067095160484314\n",
      "1280 - Loss: 0.3704674243927002\n",
      "1290 - Loss: 0.33367279171943665\n",
      "1300 - Loss: 0.30912578105926514\n",
      "1310 - Loss: 0.29018670320510864\n",
      "1320 - Loss: 0.28749340772628784\n",
      "1330 - Loss: 0.2819482684135437\n",
      "1340 - Loss: 0.27985304594039917\n",
      "1350 - Loss: 0.2757197916507721\n",
      "1360 - Loss: 0.2741835415363312\n",
      "1370 - Loss: 0.27129650115966797\n",
      "1380 - Loss: 0.26733076572418213\n",
      "1390 - Loss: 0.25304293632507324\n",
      "1400 - Loss: 0.24350900948047638\n",
      "1410 - Loss: 0.24251721799373627\n",
      "1420 - Loss: 0.2325252890586853\n",
      "1430 - Loss: 0.22744768857955933\n",
      "1440 - Loss: 0.22518807649612427\n",
      "1450 - Loss: 0.21972361207008362\n",
      "1460 - Loss: 0.21911534667015076\n",
      "1470 - Loss: 0.2156384289264679\n",
      "1480 - Loss: 0.21116867661476135\n",
      "1490 - Loss: 0.2087717205286026\n",
      "1500 - Loss: 0.20484678447246552\n",
      "1510 - Loss: 0.2009480595588684\n",
      "1520 - Loss: 0.19913384318351746\n",
      "1530 - Loss: 0.19965754449367523\n",
      "1540 - Loss: 0.19678404927253723\n",
      "1550 - Loss: 0.1917402446269989\n",
      "1560 - Loss: 0.19029656052589417\n",
      "1570 - Loss: 0.1895068883895874\n",
      "1580 - Loss: 0.19095435738563538\n",
      "1590 - Loss: 0.18594035506248474\n",
      "1600 - Loss: 0.18417981266975403\n",
      "1610 - Loss: 0.18302211165428162\n",
      "1620 - Loss: 0.1800888180732727\n",
      "1630 - Loss: 0.17911717295646667\n",
      "1640 - Loss: 0.17798367142677307\n",
      "1650 - Loss: 0.17953363060951233\n",
      "1660 - Loss: 0.17886555194854736\n",
      "1670 - Loss: 0.17482413351535797\n",
      "1680 - Loss: 0.1761823147535324\n",
      "1690 - Loss: 0.1710510551929474\n",
      "1700 - Loss: 0.1688581109046936\n",
      "1710 - Loss: 0.1691952794790268\n",
      "1720 - Loss: 0.163802832365036\n",
      "1730 - Loss: 0.16475453972816467\n",
      "1740 - Loss: 0.16322565078735352\n",
      "1750 - Loss: 0.16121020913124084\n",
      "1760 - Loss: 0.15980029106140137\n",
      "1770 - Loss: 0.16380491852760315\n",
      "1780 - Loss: 0.16029907763004303\n",
      "1790 - Loss: 0.15900905430316925\n",
      "1800 - Loss: 0.1730566918849945\n",
      "1810 - Loss: 2.371912717819214\n",
      "1820 - Loss: 1.2303471565246582\n",
      "1830 - Loss: 0.8731772899627686\n",
      "1840 - Loss: 0.5078611373901367\n",
      "1850 - Loss: 0.38902851939201355\n",
      "1860 - Loss: 0.34891533851623535\n",
      "1870 - Loss: 0.3261769711971283\n",
      "1880 - Loss: 0.3212665319442749\n",
      "1890 - Loss: 0.32030802965164185\n",
      "1900 - Loss: 0.3175532817840576\n",
      "1910 - Loss: 0.30909258127212524\n",
      "1920 - Loss: 0.30821937322616577\n",
      "1930 - Loss: 0.3025400638580322\n",
      "1940 - Loss: 0.3021922707557678\n",
      "1950 - Loss: 0.2924193739891052\n",
      "1960 - Loss: 0.2938271760940552\n",
      "1970 - Loss: 0.2897774577140808\n",
      "1980 - Loss: 0.28808873891830444\n",
      "1990 - Loss: 0.2823813557624817\n",
      "2000 - Loss: 0.28155744075775146\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Attack_tvt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.238457</td>\n",
       "      <td>-1.841131</td>\n",
       "      <td>3.461085</td>\n",
       "      <td>6.890592</td>\n",
       "      <td>12.349005</td>\n",
       "      <td>6.761558</td>\n",
       "      <td>10.531001</td>\n",
       "      <td>2.586161</td>\n",
       "      <td>14.825981</td>\n",
       "      <td>-6.510933</td>\n",
       "      <td>...</td>\n",
       "      <td>17.769934</td>\n",
       "      <td>-4.022481</td>\n",
       "      <td>1.120273</td>\n",
       "      <td>-3.257091</td>\n",
       "      <td>-10.214943</td>\n",
       "      <td>1.668622</td>\n",
       "      <td>-5.462571</td>\n",
       "      <td>6.278130</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.875972</td>\n",
       "      <td>-0.238168</td>\n",
       "      <td>1.012785</td>\n",
       "      <td>0.610468</td>\n",
       "      <td>2.556398</td>\n",
       "      <td>1.391983</td>\n",
       "      <td>2.583323</td>\n",
       "      <td>1.207111</td>\n",
       "      <td>1.733117</td>\n",
       "      <td>-1.618011</td>\n",
       "      <td>...</td>\n",
       "      <td>1.710366</td>\n",
       "      <td>-1.294729</td>\n",
       "      <td>0.297484</td>\n",
       "      <td>1.015489</td>\n",
       "      <td>-1.686576</td>\n",
       "      <td>0.371870</td>\n",
       "      <td>-0.022600</td>\n",
       "      <td>0.361506</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.888017</td>\n",
       "      <td>-0.433161</td>\n",
       "      <td>1.915892</td>\n",
       "      <td>0.356167</td>\n",
       "      <td>2.921270</td>\n",
       "      <td>2.506774</td>\n",
       "      <td>3.180284</td>\n",
       "      <td>1.861716</td>\n",
       "      <td>2.166063</td>\n",
       "      <td>-2.291450</td>\n",
       "      <td>...</td>\n",
       "      <td>2.166724</td>\n",
       "      <td>-2.729713</td>\n",
       "      <td>0.758631</td>\n",
       "      <td>1.828482</td>\n",
       "      <td>-2.891664</td>\n",
       "      <td>0.240087</td>\n",
       "      <td>-0.129191</td>\n",
       "      <td>0.851800</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.875972</td>\n",
       "      <td>-0.238168</td>\n",
       "      <td>1.012785</td>\n",
       "      <td>0.610468</td>\n",
       "      <td>2.556398</td>\n",
       "      <td>1.391983</td>\n",
       "      <td>2.583323</td>\n",
       "      <td>1.207111</td>\n",
       "      <td>1.733117</td>\n",
       "      <td>-1.618011</td>\n",
       "      <td>...</td>\n",
       "      <td>1.710366</td>\n",
       "      <td>-1.294729</td>\n",
       "      <td>0.297484</td>\n",
       "      <td>1.015489</td>\n",
       "      <td>-1.686576</td>\n",
       "      <td>0.371870</td>\n",
       "      <td>-0.022600</td>\n",
       "      <td>0.361506</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.250624</td>\n",
       "      <td>-0.038113</td>\n",
       "      <td>0.137072</td>\n",
       "      <td>0.295339</td>\n",
       "      <td>0.493120</td>\n",
       "      <td>0.033824</td>\n",
       "      <td>0.464758</td>\n",
       "      <td>0.166967</td>\n",
       "      <td>0.208423</td>\n",
       "      <td>-0.224813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403563</td>\n",
       "      <td>-0.094993</td>\n",
       "      <td>0.041968</td>\n",
       "      <td>0.149544</td>\n",
       "      <td>-0.171112</td>\n",
       "      <td>-0.032183</td>\n",
       "      <td>0.034245</td>\n",
       "      <td>0.081795</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3          4         5          6  \\\n",
       "0 -1.238457 -1.841131  3.461085  6.890592  12.349005  6.761558  10.531001   \n",
       "1 -0.875972 -0.238168  1.012785  0.610468   2.556398  1.391983   2.583323   \n",
       "2 -0.888017 -0.433161  1.915892  0.356167   2.921270  2.506774   3.180284   \n",
       "3 -0.875972 -0.238168  1.012785  0.610468   2.556398  1.391983   2.583323   \n",
       "4 -0.250624 -0.038113  0.137072  0.295339   0.493120  0.033824   0.464758   \n",
       "\n",
       "          7          8         9  ...        120       121       122  \\\n",
       "0  2.586161  14.825981 -6.510933  ...  17.769934 -4.022481  1.120273   \n",
       "1  1.207111   1.733117 -1.618011  ...   1.710366 -1.294729  0.297484   \n",
       "2  1.861716   2.166063 -2.291450  ...   2.166724 -2.729713  0.758631   \n",
       "3  1.207111   1.733117 -1.618011  ...   1.710366 -1.294729  0.297484   \n",
       "4  0.166967   0.208423 -0.224813  ...   0.403563 -0.094993  0.041968   \n",
       "\n",
       "        123        124       125       126       127  Attack  Attack_tvt  \n",
       "0 -3.257091 -10.214943  1.668622 -5.462571  6.278130       4       train  \n",
       "1  1.015489  -1.686576  0.371870 -0.022600  0.361506       0         val  \n",
       "2  1.828482  -2.891664  0.240087 -0.129191  0.851800       0       train  \n",
       "3  1.015489  -1.686576  0.371870 -0.022600  0.361506       0       train  \n",
       "4  0.149544  -0.171112 -0.032183  0.034245  0.081795       0         val  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save: ../output_emb/AnomalE_nf_bot_multi_cv4.pkl\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2000\n",
    "cname_label = 'Attack'\n",
    "ds_name = 'NF-BoT-IoT_cv'\n",
    "g_name = 'NF-BoT-IoT_cv0_graph_multi'\n",
    "for fold in range(n_folds):\n",
    "    print('Fold:', fold)\n",
    "    cname_tvt = f'{cname_label}_tvt_fold_{fold}'\n",
    "    df_result = run_baseline(\n",
    "        ds_name,\n",
    "        g_name,\n",
    "        cname_label,\n",
    "        cname_tvt,\n",
    "        n_epochs\n",
    "    )\n",
    "    display(df_result.head())\n",
    "    if flag_save:\n",
    "        out_path = f'../output_emb/AnomalE_nf_bot_multi_cv{fold}.pkl'\n",
    "        print('Save:', out_path)\n",
    "        df_result.to_pickle(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "001a55b1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/xgboost/core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_val</th>\n",
       "      <th>n_test</th>\n",
       "      <th>n_tree</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>360060</td>\n",
       "      <td>120020</td>\n",
       "      <td>120020</td>\n",
       "      <td>28</td>\n",
       "      <td>0.93855</td>\n",
       "      <td>0.838571</td>\n",
       "      <td>0.937753</td>\n",
       "      <td>0.837985</td>\n",
       "      <td>0.838591</td>\n",
       "      <td>0.837394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_features  n_train   n_val  n_test  n_tree  train_auc  train_acc  \\\n",
       "0         128   360060  120020  120020      28    0.93855   0.838571   \n",
       "\n",
       "    val_auc   val_acc  test_auc  test_acc  \n",
       "0  0.937753  0.837985  0.838591  0.837394  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save: ../output_cv/AnomalE_nf_bot_multi_cv0.csv\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/xgboost/core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_val</th>\n",
       "      <th>n_test</th>\n",
       "      <th>n_tree</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>360060</td>\n",
       "      <td>120020</td>\n",
       "      <td>120020</td>\n",
       "      <td>35</td>\n",
       "      <td>0.938578</td>\n",
       "      <td>0.839049</td>\n",
       "      <td>0.937196</td>\n",
       "      <td>0.838719</td>\n",
       "      <td>0.918899</td>\n",
       "      <td>0.829695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_features  n_train   n_val  n_test  n_tree  train_auc  train_acc  \\\n",
       "0         128   360060  120020  120020      35   0.938578   0.839049   \n",
       "\n",
       "    val_auc   val_acc  test_auc  test_acc  \n",
       "0  0.937196  0.838719  0.918899  0.829695  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save: ../output_cv/AnomalE_nf_bot_multi_cv1.csv\n",
      "Fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/xgboost/core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_val</th>\n",
       "      <th>n_test</th>\n",
       "      <th>n_tree</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>360060</td>\n",
       "      <td>120020</td>\n",
       "      <td>120020</td>\n",
       "      <td>48</td>\n",
       "      <td>0.938168</td>\n",
       "      <td>0.83843</td>\n",
       "      <td>0.936964</td>\n",
       "      <td>0.837794</td>\n",
       "      <td>0.899103</td>\n",
       "      <td>0.825554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_features  n_train   n_val  n_test  n_tree  train_auc  train_acc  \\\n",
       "0         128   360060  120020  120020      48   0.938168    0.83843   \n",
       "\n",
       "    val_auc   val_acc  test_auc  test_acc  \n",
       "0  0.936964  0.837794  0.899103  0.825554  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save: ../output_cv/AnomalE_nf_bot_multi_cv2.csv\n",
      "Fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/xgboost/core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_val</th>\n",
       "      <th>n_test</th>\n",
       "      <th>n_tree</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>360060</td>\n",
       "      <td>120020</td>\n",
       "      <td>120020</td>\n",
       "      <td>43</td>\n",
       "      <td>0.938579</td>\n",
       "      <td>0.839177</td>\n",
       "      <td>0.938335</td>\n",
       "      <td>0.837927</td>\n",
       "      <td>0.8264</td>\n",
       "      <td>0.825112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_features  n_train   n_val  n_test  n_tree  train_auc  train_acc  \\\n",
       "0         128   360060  120020  120020      43   0.938579   0.839177   \n",
       "\n",
       "    val_auc   val_acc  test_auc  test_acc  \n",
       "0  0.938335  0.837927    0.8264  0.825112  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save: ../output_cv/AnomalE_nf_bot_multi_cv3.csv\n",
      "Fold: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/xgboost/core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_val</th>\n",
       "      <th>n_test</th>\n",
       "      <th>n_tree</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>360060</td>\n",
       "      <td>120020</td>\n",
       "      <td>120020</td>\n",
       "      <td>20</td>\n",
       "      <td>0.937925</td>\n",
       "      <td>0.838546</td>\n",
       "      <td>0.937825</td>\n",
       "      <td>0.838427</td>\n",
       "      <td>0.776469</td>\n",
       "      <td>0.790135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_features  n_train   n_val  n_test  n_tree  train_auc  train_acc  \\\n",
       "0         128   360060  120020  120020      20   0.937925   0.838546   \n",
       "\n",
       "    val_auc   val_acc  test_auc  test_acc  \n",
       "0  0.937825  0.838427  0.776469  0.790135  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save: ../output_cv/AnomalE_nf_bot_multi_cv4.csv\n"
     ]
    }
   ],
   "source": [
    "cname_target = 'Attack'\n",
    "cname_tvt = f'{cname_target}_tvt'\n",
    "flag_save = True\n",
    "for fold in range(n_folds):\n",
    "    print('Fold:', fold)\n",
    "    cname_feats = [str(i) for i in range(128)]\n",
    "    dfXY = pd.read_pickle(f'../output_emb/AnomalE_nf_bot_multi_cv{fold}.pkl')\n",
    "    \n",
    "    f_model = train_xgb(\n",
    "        dfXY, cname_feats, cname_target, cname_tvt, option_init={}, option_fit={})\n",
    "    df = predict(f_model, dfXY)\n",
    "    if flag_save:\n",
    "        out_path = f'../output_cv/AnomalE_nf_bot_multi_cv{fold}.csv'\n",
    "        print('Save:', out_path)\n",
    "        df.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386bd5d9",
   "metadata": {},
   "source": [
    "## ToN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "353363c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:1'\n",
    "n_folds = 5\n",
    "flag_save = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eabef38",
   "metadata": {},
   "source": [
    "### Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdca443d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/category_encoders/target_encoder.py:92: FutureWarning: Default parameter min_samples_leaf will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter min_samples_leaf will change in version 2.6.\"\n",
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/category_encoders/target_encoder.py:97: FutureWarning: Default parameter smoothing will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter smoothing will change in version 2.6.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: (1103420, 12) (1103420,)\n",
      "['PROTOCOL', 'L7_PROTO', 'OUT_PKTS', 'OUT_BYTES', 'IN_PKTS', 'IN_BYTES', 'TCP_FLAGS', 'FLOW_DURATION_MILLISECONDS']\n",
      "Convert NX graph to DGL\n",
      "Number of samples: (275854, 12) (275854,)\n",
      "['PROTOCOL', 'L7_PROTO', 'OUT_PKTS', 'OUT_BYTES', 'IN_PKTS', 'IN_BYTES', 'TCP_FLAGS', 'FLOW_DURATION_MILLISECONDS']\n",
      "Convert NX graph to DGL\n",
      "To device\n",
      "Start training\n",
      "0010 - Loss: 1.571653127670288\n",
      "0020 - Loss: 1.3802754878997803\n",
      "0030 - Loss: 1.385054111480713\n",
      "0040 - Loss: 1.3775782585144043\n",
      "0050 - Loss: 1.3665988445281982\n",
      "0060 - Loss: 1.3559730052947998\n",
      "0070 - Loss: 1.3369929790496826\n",
      "0080 - Loss: 1.3023241758346558\n",
      "0090 - Loss: 1.2468059062957764\n",
      "0100 - Loss: 1.1504735946655273\n",
      "0110 - Loss: 1.106756329536438\n",
      "0120 - Loss: 0.9629880785942078\n",
      "0130 - Loss: 0.844119668006897\n",
      "0140 - Loss: 0.8694419860839844\n",
      "0150 - Loss: 0.7110531330108643\n",
      "0160 - Loss: 0.7023247480392456\n",
      "0170 - Loss: 0.6558488011360168\n",
      "0180 - Loss: 0.5979750156402588\n",
      "0190 - Loss: 0.5808843374252319\n",
      "0200 - Loss: 0.5520567893981934\n",
      "0210 - Loss: 0.5879257321357727\n",
      "0220 - Loss: 0.567249596118927\n",
      "0230 - Loss: 0.5496902465820312\n",
      "0240 - Loss: 0.626305878162384\n",
      "0250 - Loss: 0.5086421370506287\n",
      "0260 - Loss: 0.5078314542770386\n",
      "0270 - Loss: 0.49446651339530945\n",
      "0280 - Loss: 0.47806549072265625\n",
      "0290 - Loss: 0.4760347008705139\n",
      "0300 - Loss: 0.4654909074306488\n",
      "0310 - Loss: 0.46365904808044434\n",
      "0320 - Loss: 0.45901042222976685\n",
      "0330 - Loss: 0.45516788959503174\n",
      "0340 - Loss: 0.4460049271583557\n",
      "0350 - Loss: 0.44216325879096985\n",
      "0360 - Loss: 0.4345844089984894\n",
      "0370 - Loss: 0.46306222677230835\n",
      "0380 - Loss: 0.4328087866306305\n",
      "0390 - Loss: 0.42756152153015137\n",
      "0400 - Loss: 0.4319295287132263\n",
      "0410 - Loss: 0.4445340037345886\n",
      "0420 - Loss: 0.46214890480041504\n",
      "0430 - Loss: 0.6021332740783691\n",
      "0440 - Loss: 1.056879997253418\n",
      "0450 - Loss: 0.5249674916267395\n",
      "0460 - Loss: 0.4860277771949768\n",
      "0470 - Loss: 0.4446152448654175\n",
      "0480 - Loss: 0.43518558144569397\n",
      "0490 - Loss: 0.4254485070705414\n",
      "0500 - Loss: 0.4255886673927307\n",
      "0510 - Loss: 0.4180457592010498\n",
      "0520 - Loss: 0.41595447063446045\n",
      "0530 - Loss: 0.41481149196624756\n",
      "0540 - Loss: 0.40687990188598633\n",
      "0550 - Loss: 0.41061827540397644\n",
      "0560 - Loss: 0.4066760838031769\n",
      "0570 - Loss: 0.4027600884437561\n",
      "0580 - Loss: 0.3966730237007141\n",
      "0590 - Loss: 0.39866384863853455\n",
      "0600 - Loss: 0.4028993844985962\n",
      "0610 - Loss: 0.3892969489097595\n",
      "0620 - Loss: 0.41473841667175293\n",
      "0630 - Loss: 0.39862626791000366\n",
      "0640 - Loss: 0.4182872772216797\n",
      "0650 - Loss: 0.38418033719062805\n",
      "0660 - Loss: 0.3946915864944458\n",
      "0670 - Loss: 0.40549516677856445\n",
      "0680 - Loss: 0.38795191049575806\n",
      "0690 - Loss: 0.39034903049468994\n",
      "0700 - Loss: 0.38587886095046997\n",
      "0710 - Loss: 0.39985156059265137\n",
      "0720 - Loss: 0.3985283672809601\n",
      "0730 - Loss: 0.42035186290740967\n",
      "0740 - Loss: 0.3798331618309021\n",
      "0750 - Loss: 0.3722960352897644\n",
      "0760 - Loss: 0.3821248412132263\n",
      "0770 - Loss: 0.36940062046051025\n",
      "0780 - Loss: 0.38399288058280945\n",
      "0790 - Loss: 0.4030178189277649\n",
      "0800 - Loss: 0.43957698345184326\n",
      "0810 - Loss: 0.9098095297813416\n",
      "0820 - Loss: 0.6213743686676025\n",
      "0830 - Loss: 0.5020104646682739\n",
      "0840 - Loss: 0.48733729124069214\n",
      "0850 - Loss: 0.4708409607410431\n",
      "0860 - Loss: 0.46078115701675415\n",
      "0870 - Loss: 0.44561129808425903\n",
      "0880 - Loss: 0.4373137354850769\n",
      "0890 - Loss: 0.443952351808548\n",
      "0900 - Loss: 0.42741096019744873\n",
      "0910 - Loss: 0.4233039617538452\n",
      "0920 - Loss: 0.4255692660808563\n",
      "0930 - Loss: 0.42326951026916504\n",
      "0940 - Loss: 0.42032966017723083\n",
      "0950 - Loss: 0.4162605106830597\n",
      "0960 - Loss: 0.41726380586624146\n",
      "0970 - Loss: 0.41370493173599243\n",
      "0980 - Loss: 0.419547438621521\n",
      "0990 - Loss: 0.4155311584472656\n",
      "1000 - Loss: 0.40956708788871765\n",
      "1010 - Loss: 0.4157058596611023\n",
      "1020 - Loss: 0.4056774973869324\n",
      "1030 - Loss: 0.4098595380783081\n",
      "1040 - Loss: 0.40495145320892334\n",
      "1050 - Loss: 0.40035703778266907\n",
      "1060 - Loss: 0.40678685903549194\n",
      "1070 - Loss: 0.4085788130760193\n",
      "1080 - Loss: 0.3993452787399292\n",
      "1090 - Loss: 0.407373309135437\n",
      "1100 - Loss: 0.39852938055992126\n",
      "1110 - Loss: 0.39990973472595215\n",
      "1120 - Loss: 0.4034472703933716\n",
      "1130 - Loss: 0.4066380262374878\n",
      "1140 - Loss: 0.40040069818496704\n",
      "1150 - Loss: 0.39078617095947266\n",
      "1160 - Loss: 0.4045225977897644\n",
      "1170 - Loss: 0.3952639102935791\n",
      "1180 - Loss: 0.39009416103363037\n",
      "1190 - Loss: 0.39854732155799866\n",
      "1200 - Loss: 0.3880908787250519\n",
      "1210 - Loss: 0.3867962062358856\n",
      "1220 - Loss: 0.39439260959625244\n",
      "1230 - Loss: 0.387192964553833\n",
      "1240 - Loss: 0.40589678287506104\n",
      "1250 - Loss: 0.9755410552024841\n",
      "1260 - Loss: 0.7289189696311951\n",
      "1270 - Loss: 0.5473549365997314\n",
      "1280 - Loss: 0.48711729049682617\n",
      "1290 - Loss: 0.4742770195007324\n",
      "1300 - Loss: 0.476981520652771\n",
      "1310 - Loss: 0.4615471363067627\n",
      "1320 - Loss: 0.45193132758140564\n",
      "1330 - Loss: 0.44548988342285156\n",
      "1340 - Loss: 0.4461195468902588\n",
      "1350 - Loss: 0.43729084730148315\n",
      "1360 - Loss: 0.43203943967819214\n",
      "1370 - Loss: 0.4140690267086029\n",
      "1380 - Loss: 0.41028356552124023\n",
      "1390 - Loss: 0.40306639671325684\n",
      "1400 - Loss: 0.3936956524848938\n",
      "1410 - Loss: 0.39726486802101135\n",
      "1420 - Loss: 0.39189866185188293\n",
      "1430 - Loss: 0.39262932538986206\n",
      "1440 - Loss: 0.3841317296028137\n",
      "1450 - Loss: 0.39086031913757324\n",
      "1460 - Loss: 0.3795040249824524\n",
      "1470 - Loss: 0.38512101769447327\n",
      "1480 - Loss: 0.3963147699832916\n",
      "1490 - Loss: 0.376936137676239\n",
      "1500 - Loss: 0.396003395318985\n",
      "1510 - Loss: 0.391504168510437\n",
      "1520 - Loss: 0.37325921654701233\n",
      "1530 - Loss: 0.36745592951774597\n",
      "1540 - Loss: 0.3721480965614319\n",
      "1550 - Loss: 0.37576329708099365\n",
      "1560 - Loss: 0.3722531199455261\n",
      "1570 - Loss: 0.41274285316467285\n",
      "1580 - Loss: 0.37235987186431885\n",
      "1590 - Loss: 0.37151241302490234\n",
      "1600 - Loss: 0.37875181436538696\n",
      "1610 - Loss: 0.3787539005279541\n",
      "1620 - Loss: 0.37486153841018677\n",
      "1630 - Loss: 0.38292908668518066\n",
      "1640 - Loss: 0.362737238407135\n",
      "1650 - Loss: 0.36289992928504944\n",
      "1660 - Loss: 0.39485806226730347\n",
      "1670 - Loss: 0.39082032442092896\n",
      "1680 - Loss: 0.3761647343635559\n",
      "1690 - Loss: 0.4184139370918274\n",
      "1700 - Loss: 0.3636765480041504\n",
      "1710 - Loss: 0.3659672141075134\n",
      "1720 - Loss: 0.399320125579834\n",
      "1730 - Loss: 0.6495406627655029\n",
      "1740 - Loss: 1.1259419918060303\n",
      "1750 - Loss: 0.624796450138092\n",
      "1760 - Loss: 0.6029284000396729\n",
      "1770 - Loss: 0.577261745929718\n",
      "1780 - Loss: 0.5476411581039429\n",
      "1790 - Loss: 0.5208246111869812\n",
      "1800 - Loss: 0.49548596143722534\n",
      "1810 - Loss: 0.478644460439682\n",
      "1820 - Loss: 0.47483402490615845\n",
      "1830 - Loss: 0.4547303318977356\n",
      "1840 - Loss: 0.4462932348251343\n",
      "1850 - Loss: 0.4527137577533722\n",
      "1860 - Loss: 0.43873149156570435\n",
      "1870 - Loss: 0.4467303156852722\n",
      "1880 - Loss: 0.43896329402923584\n",
      "1890 - Loss: 0.43693453073501587\n",
      "1900 - Loss: 0.4280935525894165\n",
      "1910 - Loss: 0.42728114128112793\n",
      "1920 - Loss: 0.4269692897796631\n",
      "1930 - Loss: 0.42868658900260925\n",
      "1940 - Loss: 0.4180357754230499\n",
      "1950 - Loss: 0.41916215419769287\n",
      "1960 - Loss: 0.42721033096313477\n",
      "1970 - Loss: 0.4188917279243469\n",
      "1980 - Loss: 0.4153331518173218\n",
      "1990 - Loss: 0.41834306716918945\n",
      "2000 - Loss: 0.40963637828826904\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>Label</th>\n",
       "      <th>Label_tvt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.098757</td>\n",
       "      <td>0.061815</td>\n",
       "      <td>-0.072648</td>\n",
       "      <td>0.046304</td>\n",
       "      <td>-0.061086</td>\n",
       "      <td>0.133402</td>\n",
       "      <td>-0.002100</td>\n",
       "      <td>0.078948</td>\n",
       "      <td>-0.004074</td>\n",
       "      <td>0.083123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095319</td>\n",
       "      <td>0.026804</td>\n",
       "      <td>-0.024102</td>\n",
       "      <td>0.010573</td>\n",
       "      <td>0.057527</td>\n",
       "      <td>-0.010087</td>\n",
       "      <td>0.062209</td>\n",
       "      <td>0.098277</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.173724</td>\n",
       "      <td>0.640377</td>\n",
       "      <td>-0.344587</td>\n",
       "      <td>0.394448</td>\n",
       "      <td>-0.036219</td>\n",
       "      <td>0.675360</td>\n",
       "      <td>0.280551</td>\n",
       "      <td>-0.089965</td>\n",
       "      <td>0.076154</td>\n",
       "      <td>0.284850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050830</td>\n",
       "      <td>0.578202</td>\n",
       "      <td>0.295151</td>\n",
       "      <td>0.333243</td>\n",
       "      <td>0.341715</td>\n",
       "      <td>-0.063575</td>\n",
       "      <td>0.254221</td>\n",
       "      <td>0.312628</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.107301</td>\n",
       "      <td>0.055413</td>\n",
       "      <td>-0.067121</td>\n",
       "      <td>0.059845</td>\n",
       "      <td>-0.059322</td>\n",
       "      <td>0.144517</td>\n",
       "      <td>0.014243</td>\n",
       "      <td>0.071828</td>\n",
       "      <td>-0.013638</td>\n",
       "      <td>0.072646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089099</td>\n",
       "      <td>0.015234</td>\n",
       "      <td>-0.018859</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.045622</td>\n",
       "      <td>-0.004219</td>\n",
       "      <td>0.066143</td>\n",
       "      <td>0.103366</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.130040</td>\n",
       "      <td>0.192890</td>\n",
       "      <td>-0.119239</td>\n",
       "      <td>0.214464</td>\n",
       "      <td>-0.091033</td>\n",
       "      <td>0.319849</td>\n",
       "      <td>0.091386</td>\n",
       "      <td>-0.014514</td>\n",
       "      <td>-0.045745</td>\n",
       "      <td>0.077410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105167</td>\n",
       "      <td>0.111527</td>\n",
       "      <td>0.047029</td>\n",
       "      <td>0.082360</td>\n",
       "      <td>0.076323</td>\n",
       "      <td>-0.015642</td>\n",
       "      <td>0.122852</td>\n",
       "      <td>0.181686</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.164236</td>\n",
       "      <td>0.511135</td>\n",
       "      <td>-0.270675</td>\n",
       "      <td>0.354221</td>\n",
       "      <td>-0.061598</td>\n",
       "      <td>0.580225</td>\n",
       "      <td>0.227954</td>\n",
       "      <td>-0.069590</td>\n",
       "      <td>0.030690</td>\n",
       "      <td>0.215867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052132</td>\n",
       "      <td>0.435273</td>\n",
       "      <td>0.221920</td>\n",
       "      <td>0.251372</td>\n",
       "      <td>0.258832</td>\n",
       "      <td>-0.040793</td>\n",
       "      <td>0.209196</td>\n",
       "      <td>0.266315</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.098757  0.061815 -0.072648  0.046304 -0.061086  0.133402 -0.002100   \n",
       "1 -0.173724  0.640377 -0.344587  0.394448 -0.036219  0.675360  0.280551   \n",
       "2 -0.107301  0.055413 -0.067121  0.059845 -0.059322  0.144517  0.014243   \n",
       "3 -0.130040  0.192890 -0.119239  0.214464 -0.091033  0.319849  0.091386   \n",
       "4 -0.164236  0.511135 -0.270675  0.354221 -0.061598  0.580225  0.227954   \n",
       "\n",
       "          7         8         9  ...       120       121       122       123  \\\n",
       "0  0.078948 -0.004074  0.083123  ...  0.095319  0.026804 -0.024102  0.010573   \n",
       "1 -0.089965  0.076154  0.284850  ...  0.050830  0.578202  0.295151  0.333243   \n",
       "2  0.071828 -0.013638  0.072646  ...  0.089099  0.015234 -0.018859  0.003706   \n",
       "3 -0.014514 -0.045745  0.077410  ...  0.105167  0.111527  0.047029  0.082360   \n",
       "4 -0.069590  0.030690  0.215867  ...  0.052132  0.435273  0.221920  0.251372   \n",
       "\n",
       "        124       125       126       127  Label  Label_tvt  \n",
       "0  0.057527 -0.010087  0.062209  0.098277      0      train  \n",
       "1  0.341715 -0.063575  0.254221  0.312628      0      train  \n",
       "2  0.045622 -0.004219  0.066143  0.103366      0        val  \n",
       "3  0.076323 -0.015642  0.122852  0.181686      0        val  \n",
       "4  0.258832 -0.040793  0.209196  0.266315      0        val  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save: ../output_emb/AnomalE_nf_ton_binary_cv1.pkl\n",
      "Fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/category_encoders/target_encoder.py:92: FutureWarning: Default parameter min_samples_leaf will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter min_samples_leaf will change in version 2.6.\"\n",
      "/home/hoang/miniconda2/envs/iot/lib/python3.9/site-packages/category_encoders/target_encoder.py:97: FutureWarning: Default parameter smoothing will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter smoothing will change in version 2.6.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: (1103420, 12) (1103420,)\n",
      "['PROTOCOL', 'L7_PROTO', 'OUT_PKTS', 'OUT_BYTES', 'IN_PKTS', 'IN_BYTES', 'TCP_FLAGS', 'FLOW_DURATION_MILLISECONDS']\n",
      "Convert NX graph to DGL\n",
      "Number of samples: (275854, 12) (275854,)\n",
      "['PROTOCOL', 'L7_PROTO', 'OUT_PKTS', 'OUT_BYTES', 'IN_PKTS', 'IN_BYTES', 'TCP_FLAGS', 'FLOW_DURATION_MILLISECONDS']\n",
      "Convert NX graph to DGL\n",
      "To device\n",
      "Start training\n",
      "0010 - Loss: 1.698265790939331\n",
      "0020 - Loss: 1.3967959880828857\n",
      "0030 - Loss: 1.4075596332550049\n",
      "0040 - Loss: 1.3775558471679688\n",
      "0050 - Loss: 1.3695569038391113\n",
      "0060 - Loss: 1.3590104579925537\n",
      "0070 - Loss: 1.3442622423171997\n",
      "0080 - Loss: 1.319408655166626\n",
      "0090 - Loss: 1.2817859649658203\n",
      "0100 - Loss: 1.211519479751587\n",
      "0110 - Loss: 1.1222591400146484\n",
      "0120 - Loss: 1.01223886013031\n",
      "0130 - Loss: 0.9164758920669556\n",
      "0140 - Loss: 0.8886610865592957\n",
      "0150 - Loss: 0.724753201007843\n",
      "0160 - Loss: 0.6845396757125854\n",
      "0170 - Loss: 0.632996678352356\n",
      "0180 - Loss: 0.6502498388290405\n",
      "0190 - Loss: 0.5975292921066284\n",
      "0200 - Loss: 0.5628468990325928\n",
      "0210 - Loss: 0.6364639401435852\n",
      "0220 - Loss: 0.9055130481719971\n",
      "0230 - Loss: 0.5722020864486694\n",
      "0240 - Loss: 0.5484632849693298\n",
      "0250 - Loss: 0.5277609825134277\n",
      "0260 - Loss: 0.5208953619003296\n",
      "0270 - Loss: 0.5101982355117798\n",
      "0280 - Loss: 0.49217796325683594\n",
      "0290 - Loss: 0.48640745878219604\n",
      "0300 - Loss: 0.480659544467926\n",
      "0310 - Loss: 0.4715047776699066\n",
      "0320 - Loss: 0.47217798233032227\n",
      "0330 - Loss: 0.4647974669933319\n",
      "0340 - Loss: 0.46304890513420105\n",
      "0350 - Loss: 0.4527921676635742\n",
      "0360 - Loss: 1.0148777961730957\n",
      "0370 - Loss: 0.6135945916175842\n",
      "0380 - Loss: 0.5157803297042847\n",
      "0390 - Loss: 0.48186349868774414\n",
      "0400 - Loss: 0.46250027418136597\n",
      "0410 - Loss: 0.45883333683013916\n",
      "0420 - Loss: 0.4529372453689575\n",
      "0430 - Loss: 0.4497227072715759\n",
      "0440 - Loss: 0.44237467646598816\n",
      "0450 - Loss: 0.4396243691444397\n",
      "0460 - Loss: 0.43297404050827026\n",
      "0470 - Loss: 0.434573233127594\n",
      "0480 - Loss: 0.426197350025177\n",
      "0490 - Loss: 0.4275098443031311\n",
      "0500 - Loss: 0.4275158643722534\n",
      "0510 - Loss: 0.42077749967575073\n",
      "0520 - Loss: 0.42305728793144226\n",
      "0530 - Loss: 0.44601720571517944\n",
      "0540 - Loss: 1.1538231372833252\n",
      "0550 - Loss: 1.2317537069320679\n",
      "0560 - Loss: 0.6882537007331848\n",
      "0570 - Loss: 0.45398199558258057\n",
      "0580 - Loss: 0.4571816325187683\n",
      "0590 - Loss: 0.4379940629005432\n",
      "0600 - Loss: 0.43081820011138916\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2000\n",
    "cname_label = 'Label'\n",
    "ds_name = 'NF-ToN-IoT_cv'\n",
    "g_name = 'NF-ToN-IoT_cv0_graph_binary'\n",
    "for fold in range(1, n_folds):\n",
    "    print('Fold:', fold)\n",
    "    cname_tvt = f'{cname_label}_tvt_fold_{fold}'\n",
    "    df_result = run_baseline(\n",
    "        ds_name,\n",
    "        g_name,\n",
    "        cname_label,\n",
    "        cname_tvt,\n",
    "        n_epochs\n",
    "    )\n",
    "    display(df_result.head())\n",
    "    if flag_save:\n",
    "        out_path = f'../output_emb/AnomalE_nf_ton_binary_cv{fold}.pkl'\n",
    "        print('Save:', out_path)\n",
    "        df_result.to_pickle(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da47074",
   "metadata": {},
   "outputs": [],
   "source": [
    "cname_target = 'Label'\n",
    "cname_tvt = f'{cname_target}_tvt'\n",
    "flag_save = True\n",
    "for fold in range(n_folds):\n",
    "    print('Fold:', fold)\n",
    "    cname_feats = [str(i) for i in range(128)]\n",
    "    dfXY = pd.read_pickle(f'../output_emb/AnomalE_nf_ton_binary_cv{fold}.pkl')\n",
    "    \n",
    "    f_model = train_xgb(\n",
    "        dfXY, cname_feats, cname_target, cname_tvt, option_init={}, option_fit={})\n",
    "    df = predict(f_model, dfXY)\n",
    "    if flag_save:\n",
    "        out_path = f'../output_cv/AnomalE_nf_ton_binary_cv{fold}.csv'\n",
    "        print('Save:', out_path)\n",
    "        df.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88516ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64257a8d",
   "metadata": {},
   "source": [
    "### Multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f73bd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 2000\n",
    "cname_label = 'Attack'\n",
    "ds_name = 'NF-ToN-IoT_cv'\n",
    "g_name = 'NF-ToN-IoT_cv0_graph_multi'\n",
    "for fold in range(n_folds):\n",
    "    print('Fold:', fold)\n",
    "    cname_tvt = f'{cname_label}_tvt_fold_{fold}'\n",
    "    df_result = run_baseline(\n",
    "        ds_name,\n",
    "        g_name,\n",
    "        cname_label,\n",
    "        cname_tvt,\n",
    "        n_epochs\n",
    "    )\n",
    "    display(df_result.head())\n",
    "    if flag_save:\n",
    "        out_path = f'../output_emb/AnomalE_nf_ton_multi_cv{fold}.pkl'\n",
    "        print('Save:', out_path)\n",
    "        df_result.to_pickle(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e23d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cname_target = 'Attack'\n",
    "cname_tvt = f'{cname_target}_tvt'\n",
    "flag_save = True\n",
    "for fold in range(n_folds):\n",
    "    print('Fold:', fold)\n",
    "    cname_feats = [str(i) for i in range(128)]\n",
    "    dfXY = pd.read_pickle(f'../output_emb/AnomalE_nf_ton_multi_cv{fold}.pkl')\n",
    "    \n",
    "    f_model = train_xgb(\n",
    "        dfXY, cname_feats, cname_target, cname_tvt, option_init={}, option_fit={})\n",
    "    df = predict(f_model, dfXY)\n",
    "    # df.to_csv(f'../output_cv/xgb_nf_bot_binary_cv{fold}.csv', index=False)\n",
    "    if flag_save:\n",
    "        out_path = f'../output_cv/AnomalE_nf_ton_multi_cv{fold}.csv'\n",
    "        print('Save:', out_path)\n",
    "        df.to_csv(out_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
